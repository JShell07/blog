<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[人性的弱点]]></title>
    <url>%2F2019%2F09%2F05%2F%E4%BA%BA%E6%80%A7%E7%9A%84%E5%BC%B1%E7%82%B9%2F</url>
    <content type="text"><![CDATA[来源于美国著名人际关系学大师，美国现代成人教育之父，西方现代人际关系教育的奠基人，被誉为是20世纪最伟大的心灵导师和成功学大师–戴尔·卡耐基 1. 与人相处1.1. 待人接物 我们面对的不是理性动物，而是情感动物，他们充满执念并为自尊和虚荣所驱动。 让我们理解他人，而不是指责对方。努力弄清他们为什么这么做，这比批评更叫有益和诱人得多。 理解了一切，就能原谅一切。 本杰明.富兰克林： 成功秘诀何在？我只说自己知道每个人的优点! 1.2. 说话方式我总是急于称赞，迟于挑刺儿。当我喜欢一点，就会给予真诚的嘉许，我对赞扬从不吝啬。 激发大伙儿的热情的能力，是我拥有最大的资源，我激活每个人的潜能的方式，就是 欣赏和鼓励。 给予真诚的认可，毫不吝啬自己的赞扬。 弗洛伊德: 每个人都渴望感觉自己很重要，对伟大的渴望。 所以世界上唯一能影响他人的方法，就是谈论他们想要的东西，并告诉他们如何获得。 人们不在意你，也不在意我。人们在意他们自己，早上在意，中午在意，晚饭后在意。和人们聊他们自己，他们会听几个小时都不烦。 每个人都喜欢称赞，但表扬必须具体，否则就特别假，成了说好话哄骗人。 没有人喜欢虚假，所有人都讨厌奉承 1.2.1. 尊重对方观点尊重对方的观点，永远别说“你不对”。 很少有人特别理性，大部分人都带着偏见和成见，被先入为主的观念、猜疑、嫉妒和骄傲染色。 1.2.2. 出现争辩时 主动承认自己的错误 先说友善的话，在说其他的（改变氛围） 关注双方重合的地方，避免说意见相左的部分（强调追求的是统一个目标，不同的是方法而不是目的） 给建议，让对方自己得出结论（这比强制传递想法給他更让人深信不疑） 能让对方说很多个“对”，开启了一个心理过程，导向正确的方向。 回应一个“不”字，就增加了一堵难克服的墙。 1.3. 交友不走心交不到朋友，要为别人做些需要时间和精力的、无私的、体贴的事。 一个人脸上的表情，比她背上的皮革要值钱得多。 – 一笑值千金 以热情和高兴待人。 如果你想让别人喜欢你，如果你想获得真的朋友：真的喜欢别人,真诚。 1.3.1 让人乐意服诉诸高尚的情操，假设他就是真诚的好人。可以改变人的意志。（这其实给予了他心理暗示，大部分情况下做出对你有利的反应） 批评他人之前，不妨说说自己犯过的错，间接让他们注意到自己的错误。（拉近他人的距离，不招人狠。少用“但是/但”，用“而”，给予别人尊重） 总是用建议，而不是命令（给人留够自由做事的空间，让他们自己去做，让他们从错误中学习） 1.3.2. 期望朋友帮忙给人一个无法抗拒、无法辜负的好评。“你也可以假定对方已经拥有了你想要激活的美德，并公开宣布，让他不要辜负自己的美名。” 2. 自我内在2.1. 主动承认错误赢得争论的唯一方法就是避免争论。愚蠢的人则会努力寻找辩解的理由。 承认自己错了，你就绝对不会遇到麻烦。这能熄灭争论，启发对手像你一样公平、开放、有气量。这会让他想承认，其实自己也难免犯错。 2.2. 换角度思考努力从对方的视角看问题，要诚实。 不要指责，试着理解他们。找到他的道理，明白他的行为甚至人格。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[李开复自传]]></title>
    <url>%2F2019%2F08%2F28%2F%E6%9D%8E%E5%BC%80%E5%A4%8D%E8%87%AA%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[抓住一切去探寻生命的意义，总有一天，世界将因你不同。 人生中常被问到“我是谁”、“从哪里来”、“到哪里去”，其实就是认识自己，认识客观世界，寻找人生目的的过程，永远没有终点。 未来自己主宰。 做最好的自己、世界因你不同！我总是鞭策自己最求最有价值的人生，每时每刻都得好好善用，要让自己有限的生命发挥最大的效益。 来自父亲的教诲： 老牛明知夕阳短，不用扬鞭自奋蹄。 1. 自省，如果生命只剩100天如果觉察到自己沉溺于担心会失去某些东西时，“记住你即将死去”会是最好的解药。只留下真正重要的东西。 人到无求品自高，人生应为所当为。若将名利挂心头，编入苍蝇追逐腐肉，把人生的追求浪费在满足最低层级的欲望上。 成功的定义因人而异，没有一定的标准，不需要和别人竞赛。你竞赛的对象是自己，比昨天更好一点儿，更积极地面对挑战，面对不如意是，让内心更加平静。 有容德乃大，无求品自高。 必有忍,其乃有济;有容,德乃大。 –《尚书·君陈》 2. 授惑，与星云大师对谈 真正有益于世界的做法不是除恶，而是行善；不是打击负能量，而是弘扬正能量。 珍贵的生命旅程，应该抱着初学者的心态，对世界保持儿童般的好奇心，好好体验人生；让自己每天都比以前一天有进步、有成长，不必改变别人，只要做事问心无愧，对人真诚平等，这就足够了。 3. 生活每天都是最特殊的一天。 再也不要把好东西留到特别的日子才用，你或者的每一天都是特别的日子。 多交点正向的朋友，补充正能量。 从追求100分到只要80分，常将世间种种可爱放在心上。 成功的婚姻不是建立在安全、拥有的基础上，而是建立在平等、自由之上。 婚姻不是在制造罪恶感的义务，而是彼此互补，彼此互谅，彼此相互扶持的过程。 与自己最爱的人攻读生命之旅，分享权力，分担责任，才能沐浴在光辉中。就想交换的戒子：象征合一，而非占有；象征结合，而非限制；象征环抱，而非羁绊。 4. 学习&amp;&amp;工作生涯李开复哲学系老师： 知道什么是make a difference? 想象有两个世界，一个世界中有你，一个世界中没你，让两者的不同最大，最大化你的影响力，这就是你一生的意义。 只会思考而不会表达的人，与不会思考的人没什么两样。 瑞迪教授： 我不同意你，但是我支持你。这是一种真正的科学家精神。 卡内基.梅隆海博曼教授： 你从学校带走最有价值的不是论文，而是你分析和独立思考的能力、研究和发现真理的经验。 选择工作的标准：成长，兴趣和影响力。 作为领导，相信：架子最不值钱，而点子最值钱。 5. 总结，世界因你而不同最富有的人不是拥有最多的人，而是雪球最少的人。 不要盲目地跟随别人，不要被信条所惑，只有你的内心知道你真正想成为什么样的人，只有你能找到自己的价值。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[穷查理宝典]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%A9%B7%E6%9F%A5%E7%90%86%E5%AE%9D%E5%85%B8%2F</url>
    <content type="text"><![CDATA[查理·芒格， 沃伦·巴菲特的黄金搭档，伯克希尔·哈撒韦公司的副主席，同时也是被号称为移动的书屋。 无论在顺境，逆境，都保持客观积极的心态。 1. 核心原则在最开始当律师时，查理并没有顽疾祖父教导的铁律：专注于当前的任务，控制支出。 耐心是最伟大的美德。– 马尔库斯，罗马政治家 对付失望，那就是幽默。 2.芒格的生活、学习和决策方法凡事往简单处想，往认真处行。（笨人做加法，聪明人做减法，智者做除法） 以跨学科的方式思考 在头脑中拥有一些思维模型，并且愿意甚至渴望去证实和承认自己的错误，并从中吸取教训。否则手里只拿着铁锤的人看来，每个问题都像是钉子。 记住浅显的，而不是掌握深奥的。我们从来不去试图成为非常聪明的人，而是持续地试图别变成蠢货，久而久子，我们这种人便能获得非常大的优势。 3. 投资评估过程先弄清应该别做什么事情，然后才会考虑接下来采取的行动。 我只想知道我将来会是在什么地方，这样我就可以永远不去那里啦。 花在学习和思考上的时间，比花在行动上的时间要多。 查理在意的并不是他本人能否赢牌，而是是否能把手上的牌打好。 你要有浓厚的兴趣去弄明白正在发生的事情背后的原因。如果你能长期保持这种心态，你关注现实的能力将会逐渐得到提高。 弄清自己的优势在哪里，必须在自己的能力圈之内竞争。 一个人可以从书籍上或者人们身上培养眼光。 聪明人在发现机会之后就会狠狠下注，碰到好机会就下重注，其他时间则按兵不动。 投资清单： 随大流只会让你望平均值靠近，只能获得中等业绩 官方的阅读把自己培养成一个终生自学者，培养好奇心，每天努力让自己更聪明一点点 比求胜的意愿更重要的是做好准备的意愿 记住浅显的好过掌握深奥的 享受结果，也享受过程，因为你活在过程当中 认识和适应你身边的世界的真实本质，别指望它来适应你 最根本的人生哲学：准备、纪律、耐心、决心。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[挪威的森林]]></title>
    <url>%2F2019%2F08%2F27%2F%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97%2F</url>
    <content type="text"><![CDATA[来源于村上春树的挪威的森林。 挪威的森林最开始出自于披头士的演唱单曲 经典词句： 渡边看待直子的死： 死并非生的对立面，而作为生的一部分永存。 直子： 哪里会有人喜欢孤独，不过是不喜欢失望。 玲子对渡边劝说慢慢处理直子的心理问题时的态度： 急躁不得。及时事物在错综复杂，甚至叫人无计可施，也不能灰心丧气，不能急于求成强拉硬扯。要有打持久战的思想准备，必须一根根耐心清理。 玲子对有天赋的孩童看法： 尽管有卓越的天赋才华，去承受不住系统训练，而终归将才华支离破碎地挥霍掉。 渣男却能得到成功的永泽： 那不是努力，只是劳动。我所说的努力与这截然不同。所谓的努力，指的是主动而有目的的活动。 把人生当做饼干罐的绿子： 你把人生当做饼干罐就可以了。它装有各种各样的饼干，喜欢的和不喜欢的都在里面。如果一个劲儿挑你喜欢的吃，那么剩下的就全是不喜欢的，每次遇到麻烦我就总这样想：想把这个应付过去，往下就好办了。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_source_code_online]]></title>
    <url>%2F2019%2F08%2F23%2Fkernel-source-code-online%2F</url>
    <content type="text"><![CDATA[今天看到有几个非常优秀的在线浏览kernel source code 的网站。 kernel github kernel.org bootlin woboq 从功能上讲woboq 是最强的， bootlin 次之，但是胜在支持的kernel source 的版本比价多。 1. woboq这是官方给出的亮点, woboq benefit 我觉得比较有用的有： 类型，定义处，引用处表明 函数列表 宏展开 搜索功能 预处理 显示主题切换 行号显示toggle 1.1. functions list 1.2. defines and uses link 1.3. macro expansions 1.4. search 1.5. file in path and some code in which function 1.6. themes switch 1.7. line number toggle 2. bootlin 3. kernel.org 4. github repository]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel-zero-copy]]></title>
    <url>%2F2019%2F08%2F21%2Fkernel-zero-copy%2F</url>
    <content type="text"><![CDATA[在看openssl 1.1.1c 版本源码时，看到有一个zero copy 的字样。这里zero copy(零拷贝)主要指Kernel space 与user space 之间的拷贝过程。 1.Normal R/W1234567#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, const void *buf, size_t count);#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *addr, size_t length); 在read/write 时，需要将userspace 的数据copy 到kernel space。kerne 中用到的函数就有： copy_from_user()copy_to_user() mmap() 能减少read 的copy 动作，直接映射kernel空间到用户空间，但是在write时， 还是需要将write_data_buffer 拷贝到kernel space. 在拷贝文件时，我们可以这样减少copy 的次数。1234size_t filesize = stat_buf.st_size;source = mmap(0, filesize, PROT_READ, MAP_SHARED, f_in, 0);target = mmap(0, filesize, PROT_WRITE, MAP_SHARED, f_out, 0);memcpy(target, source, filesize); 2.zero copy常见的zero copy 涉及到的函数有： sendfile vmsplice, splice tee 除vmsplice（） 是映射函数外，其他借助管道实现，而管道有众所周知的空间限制问题，超过了限制就会hang住，所以每次写入管道的数据量好严格控制，保守的建议值是一个内存页大小，即PAGE_SIZE, 常见为4k。 splice用于在两个文件间移动数据，而无需内核态和用户态的内存拷贝，但需要借助管道（pipe）实现。大概原理就是通过pipe buffer实现一组内核内存页（pages of kernel memory）的引用计数指针（reference-counted pointers），数据拷贝过程中并不真正拷贝数据，而是创建一个新的指向内存页的指针。也就是说拷贝过程实质是指针的拷贝. 123456789101112131415#include &lt;sys/sendfile.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);#include &lt;fcntl.h&gt;#include &lt;sys/uio.h&gt;ssize_t vmsplice(int fd, const struct iovec *iov,unsigned long nr_segs, unsigned int flags);#include &lt;fcntl.h&gt;ssize_t splice(int fd_in, loff_t *off_in, int fd_out,loff_t *off_out, size_t len, unsigned int flags);#include &lt;fcntl.h&gt;ssize_t tee(int fd_in, int fd_out, size_t len, unsigned int flags); system api remarks sendfile() sendfile的in_fd必须指向支持mmap的文件，也就是真实存在的文件，而不能是socket、管道等文件 splice() splice()函数可以在两个文件描述符之间移动数据，且 其中一个描述符必须是管道描述符 tee() 仅支持在两个管道描述符之间复制数据 splice() 通过pipe 零拷贝文件的用例。 file_in -&gt; pipe[1] (write end) -&gt; pipe0 -&gt; file_out 123456789101112131415int pipefd[2], off_in = 0, off_out = 0;int file_in, file_out, size, flags;file_in = open("input_file", O_RDONLY);file_out = open("output_file", O_RDWR);pipe(pipefd);splice(file_in, &amp;off_in, pipefd[1], NULL, size, flags);splice(pipefd[0], NULL, file_out, &amp;off_out, size, flags);close(file_in);close(file_out);close(pipefd[0]);close(pipefd[1]); 参看资料零复制(zero copy)技术 linux网络编程：splice函数和tee( )函数高效的零拷贝 Linux 中的零拷贝技术 splice Linux下提高性能的系统调用sendfile，splice和tee splice and pipes]]></content>
      <categories>
        <category>memory</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_crypto_III]]></title>
    <url>%2F2019%2F08%2F07%2Fkernel-crypto-III%2F</url>
    <content type="text"><![CDATA[1. Method with cryptographic用户空间的方式有如下方式： netlink (AF_ALG) socket 的形式（kernel 已经merge进入主线） ioctl （OpenBSD 的形式， kenrel 没有merge此部分代码 ） openssl 我们常见的userspace 与kernel space 之间通信的方式有： IOCTL /proc /sys netlink 我们主张使用socket 的方式，更为优雅与灵活。有人在此基础上封装了lib， libkcapi 2. netlink(socket)2.1. data structure&lt;linux/if_alg.h&gt;1234567891011121314151617181920#include &lt;linux/types.h&gt;struct sockaddr_alg &#123; __u16 salg_family; __u8 salg_type[14]; __u32 salg_feat; __u32 salg_mask; __u8 salg_name[64];&#125;;struct af_alg_iv &#123; __u32 ivlen; __u8 iv[0];&#125;;/* Socket options */#define ALG_SET_KEY 1#define ALG_SET_IV 2#define ALG_SET_OP 3/* Operations */#define ALG_OP_DECRYPT 0#define ALG_OP_ENCRYPT 1 Currently, the following ciphers are accessible: Message digest including keyed message digest (HMAC, CMAC) Symmetric ciphers AEAD ciphers Random Number Generators 我们可以使用如下的sockaddr_alg 的实例联系到具体的算法上。 123456789101112/* salg_type support: - hash - skcipher - ahead - rnd*/struct sockaddr_alg sa = &#123; .salg_family = AF_ALG, .salg_type = "skcipher", /* this selects the symmetric cipher */ .salg_name = "cbc(aes)" /* this is the cipher name */&#125;; socket 中的family AF_ALG, setsockopt 使用 SOL_ALG。如果header 中没有申明，可以使用如下定义：123456#ifndef AF_ALG#define AF_ALG 38#endif#ifndef SOL_ALG#define SOL_ALG 279#endif 2.2. Kernel internal在kenrel 内部注册了AF_ALG family 类型的socket。在kernel/crypto/af_alg.c 1234567891011121314151617181920static struct proto alg_proto = &#123; .name = "ALG", .memory_allocated = &amp;alg_memory_allocated,&#125;;#define PF_ALG AF_ALGstatic const struct net_proto_family alg_family = &#123; .family = PF_ALG, .create = alg_create,&#125;;static int __init af_alg_init(void)&#123; int err = proto_register(&amp;alg_proto, 0); err = sock_register(&amp;alg_family); return err;&#125; 在kernel/crypto/algif_skcipher.c， 类似的algif_hash.c 注册了hash 类型的对象。1234567891011121314151617181920212223static struct proto_ops algif_skcipher_ops = &#123; .family = PF_ALG, .release = af_alg_release, .sendmsg = skcipher_sendmsg, .sendpage = skcipher_sendpage, .recvmsg = skcipher_recvmsg, .poll = skcipher_poll,&#125;;static const struct af_alg_type algif_type_skcipher = &#123; .bind = skcipher_bind, .release = skcipher_release, .setkey = skcipher_setkey, .accept = skcipher_accept_parent, .ops = &amp;algif_skcipher_ops, .name = "skcipher",&#125;;static int __init algif_skcipher_init(void)&#123; return af_alg_register_type(&amp;algif_type_skcipher);&#125; 2.3. usage flow我们使用如下流程进行使用： create socket with AF_ALG bind socket with sockaddr_alg addr. set key, setsocketopt() accept with socket. accept system call return new file descriptor. use new fd to sendmsg(), recvmsg() Setsockopt Interface我们可以是用setsockopt（） 系统调用进行设定。 1234567#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 2.4. usage123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;sys/socket.h&gt;#include &lt;linux/if_alg.h&gt;#ifndef AF_ALG#define AF_ALG 38#define SOL_ALG 279#endifextern errno;#define PRINT_ROW_LEN 15void print_hex_dump(char *src, int n)&#123; int i; for(i=0; i&lt;n; i++) &#123; printf("%02x ", src[i]); if (i % PRINT_ROW_LEN == 0 &amp;&amp; i != 0) printf("\n"); &#125; printf("\n");&#125;int setkey(int sockfd, char * key, int keylen)&#123; int err = setsockopt(sockfd, SOL_ALG, ALG_SET_KEY, key, keylen); if (err) &#123; perror("setsockopt err"); goto out; &#125; printf("setkey success\n");out: err = errno; return err; &#125;int sendmsg_to_cipher(int sockfd, int cmsg_type, int operation, char * src, int len)&#123; int err = 0; struct msghdr msg; struct iovec iov; struct cmsghdr* cmsg = malloc(CMSG_SPACE(sizeof(operation))); if (cmsg == NULL) &#123; perror("malloc setop_cmsg err"); goto out; &#125; cmsg-&gt;cmsg_len = CMSG_SPACE(sizeof(operation)); cmsg-&gt;cmsg_level = SOL_ALG; cmsg-&gt;cmsg_type = cmsg_type; memcpy(CMSG_DATA(cmsg), &amp;operation, sizeof(operation)); iov.iov_base = src; iov.iov_len = len; msg.msg_name = NULL; msg.msg_namelen = 0; msg.msg_iov = &amp;iov; msg.msg_iovlen = 1; msg.msg_control = cmsg; msg.msg_controllen = CMSG_SPACE(sizeof(unsigned int)); msg.msg_flags = 0; err = sendmsg(sockfd, &amp;msg, 0); if (err == -1) &#123; perror("sendmsg operation err"); goto send_msg_err; &#125; printf("sendmsg success\n");send_msg_err: free(cmsg);out: err = errno; return err;&#125;int recvmsg_from_cipher(int sockfd, char *src, int len)&#123; int err = 0; struct msghdr msg; struct iovec iov; iov.iov_base = src; iov.iov_len = len; msg.msg_name = NULL; msg.msg_namelen = 0; msg.msg_iov = &amp;iov; msg.msg_iovlen = 1; msg.msg_control = NULL; msg.msg_controllen = 0; msg.msg_flags = 0; err = recvmsg(sockfd, &amp;msg, 0); if (err == -1) &#123; perror("recvmsg operation err"); goto out; &#125; printf("recvmsg data: \n"); print_hex_dump(src, len);out: err = errno; return err;&#125;int main(void)&#123; int opfd, tfmfd, err =0; char plaintext_buf[] = &#123;0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0x00, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, 0x00, 0x11&#125;; char key_buf[] = &#123;0xff, 0xd7, 0x40, 0x57, 0x47, 0x68, 0x5e, 0xd6, 0xe0, 0x0b, 0xc6, 0x82, 0xa7, 0x72, 0x86, 0x09&#125;; char encrypt_buf[32]; char decrypt_buf[32]; struct sockaddr_alg sa = &#123; .salg_family = AF_ALG, .salg_type = "skcipher", .salg_name = "AES128_ECB_CLR_CLR" &#125;; tfmfd = socket(AF_ALG, SOCK_SEQPACKET, 0); if(tfmfd == -1) &#123; perror("socket err"); goto socket_err; &#125; err = bind(tfmfd, (struct sockaddr *)&amp;sa, sizeof(sa)); if(err) &#123; perror("bind error"); goto bind_err; &#125; printf("plaintext buf: \n"); print_hex_dump(plaintext_buf, sizeof(plaintext_buf)); /* setkey, we need to set key before connect */ err = setkey(tfmfd, key_buf, sizeof(key_buf)); if(err) goto setkey_err; opfd = accept(tfmfd, NULL, 0); if(opfd == -1) &#123; perror("accept err!"); goto accept_err; &#125; /* set iv */ /* set encryption */ err = sendmsg_to_cipher(opfd, ALG_SET_OP, ALG_OP_ENCRYPT, plaintext_buf, sizeof(plaintext_buf)); if(err) goto sendmsg_err; err = recvmsg_from_cipher(opfd, encrypt_buf, sizeof(plaintext_buf)); if (err) goto recvmsg_err; /* set decryption */ err = sendmsg_to_cipher(opfd, ALG_SET_OP, ALG_OP_DECRYPT, encrypt_buf, sizeof(plaintext_buf)); if (err) goto sendmsg_err; err = recvmsg_from_cipher(opfd, decrypt_buf, sizeof(plaintext_buf)); if (err) goto recvmsg_err;recvmsg_err:sendmsg_err: close(opfd);accept_err:setkey_err:bind_err: close(tfmfd);socket_err: return err;&#125; 3. openssl3.1. afalg engine我们再1.1.0 版本后的openssl/engines 可以找到e_afalg.c 模块。在1.1.1c 版本中支持的afalg 只有三种： aes_128_cbc aes_192_cbc aes_256_cbc 12345678910111213141516171819202122static int afalg_ciphers(ENGINE *e, const EVP_CIPHER **cipher, const int **nids, int nid)&#123; int r = 1; if (cipher == NULL) &#123; *nids = afalg_cipher_nids; return (sizeof(afalg_cipher_nids) / sizeof(afalg_cipher_nids[0])); &#125; switch (nid) &#123; case NID_aes_128_cbc: case NID_aes_192_cbc: case NID_aes_256_cbc: *cipher = afalg_aes_cbc(nid); break; default: *cipher = NULL; r = 0; &#125; return r;&#125; openssl 内部的afalg engine 其实与自己写的userspace code 类似，都是使用netlink AF_ALG family socket。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354static ossl_inline void afalg_set_op_sk(struct cmsghdr *cmsg, const ALG_OP_TYPE op)&#123; cmsg-&gt;cmsg_level = SOL_ALG; cmsg-&gt;cmsg_type = ALG_SET_OP; cmsg-&gt;cmsg_len = CMSG_LEN(ALG_OP_LEN); memcpy(CMSG_DATA(cmsg), &amp;op, ALG_OP_LEN);&#125;static void afalg_set_iv_sk(struct cmsghdr *cmsg, const unsigned char *iv, const unsigned int len)&#123; struct af_alg_iv *aiv; cmsg-&gt;cmsg_level = SOL_ALG; cmsg-&gt;cmsg_type = ALG_SET_IV; cmsg-&gt;cmsg_len = CMSG_LEN(ALG_IV_LEN(len)); aiv = (struct af_alg_iv *)CMSG_DATA(cmsg); aiv-&gt;ivlen = len; memcpy(aiv-&gt;iv, iv, len);&#125;static ossl_inline int afalg_set_key(afalg_ctx *actx, const unsigned char *key, const int klen)&#123; int ret; ret = setsockopt(actx-&gt;bfd, SOL_ALG, ALG_SET_KEY, key, klen); return 1;&#125;static int afalg_create_sk(afalg_ctx *actx, const char *ciphertype, const char *ciphername)&#123; struct sockaddr_alg sa; int r = -1; actx-&gt;bfd = actx-&gt;sfd = -1; memset(&amp;sa, 0, sizeof(sa)); sa.salg_family = AF_ALG; strncpy((char *) sa.salg_type, ciphertype, ALG_MAX_SALG_TYPE); sa.salg_type[ALG_MAX_SALG_TYPE-1] = '\0'; strncpy((char *) sa.salg_name, ciphername, ALG_MAX_SALG_NAME); sa.salg_name[ALG_MAX_SALG_NAME-1] = '\0'; actx-&gt;bfd = socket(AF_ALG, SOCK_SEQPACKET, 0); r = bind(actx-&gt;bfd, (struct sockaddr *)&amp;sa, sizeof(sa)); actx-&gt;sfd = accept(actx-&gt;bfd, NULL, 0); return 1;&#125; openssl 中体现的优点在于： 使用EVP 抽象统一all engines， 比如afalg, crypdev 等 使用async io 支持zero copy (vmsplice(), splice() 函数使用) 3.2. performance使用openssl speed 模块可以测试速度。 time openssl speed -evp aes-128-cbc -elapsedtime openssl speed -evp aes-128-cbc -elapsed -engine afalg Method Result Software Crypto type 16 bytes 64 bytes 256 bytes 1024 bytes 8192 bytes 16384 bytes aes-128-cbc 13681.29k 16959.06k 18170.71k 18484.91k 18590.38k 18573.99k real 0m 18.67s user 0m 18.10s sys 0m 0.19s Hardware Crypto type 16 bytes 64 bytes 256 bytes 1024 bytes 8192 bytes 16384 bytes aes-128-cbc 293.11k 1052.46k 4073.64k 11785.59k 27314.86k 30938.45k real 0m 18.24s user 0m 0.73s sys 0m 10.80s 参看资料User Space Interface Crypto API (Linux) userspace if_alg example code libkcapi, crypto user space library]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>cryptographic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_crypto_II]]></title>
    <url>%2F2019%2F08%2F06%2Fkernel-crypto-II%2F</url>
    <content type="text"><![CDATA[1. cipher 基础在Kernel crytographic 的cipher 还有如下几类： ablkcipher_tfm(asynchronous multi-block cipher transform) blkcipher_tfm(synchronous multi-block cipher transform) cipher_tfm(Single block cipher transform) 更为安全的是使用ahead 加密形式， 可以见此篇文章。什么是AEAD加密 在kernel中cipher 都为skcipher(Symmetric Key cipher, 对称性加密算法) 后面我们以kernel/drivers/crypto/atmel-aes.c 进行分析ablkcipher 的驱动。 2. cipher alg registeratmel aes 驱动初始流程可见下图： 12345678910111213141516171819202122232425262728293031323334353637383940414243static struct crypto_alg aes_algs[] = &#123;&#123; .cra_name = "ecb(aes)", .cra_driver_name = "atmel-ecb-aes", .cra_priority = 100, .cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC, .cra_blocksize = AES_BLOCK_SIZE, .cra_ctxsize = sizeof(struct atmel_aes_ctx), .cra_alignmask = 0xf, .cra_type = &amp;crypto_ablkcipher_type, .cra_module = THIS_MODULE, .cra_init = atmel_aes_cra_init, .cra_exit = atmel_aes_cra_exit, .cra_u.ablkcipher = &#123; .min_keysize = AES_MIN_KEY_SIZE, .max_keysize = AES_MAX_KEY_SIZE, .setkey = atmel_aes_setkey, .encrypt = atmel_aes_ecb_encrypt, .decrypt = atmel_aes_ecb_decrypt, &#125;&#125;,&#123; .cra_name = "cbc(aes)", .cra_driver_name = "atmel-cbc-aes", .cra_priority = 100, .cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC, .cra_blocksize = AES_BLOCK_SIZE, .cra_ctxsize = sizeof(struct atmel_aes_ctx), .cra_alignmask = 0xf, .cra_type = &amp;crypto_ablkcipher_type, .cra_module = THIS_MODULE, .cra_init = atmel_aes_cra_init, .cra_exit = atmel_aes_cra_exit, .cra_u.ablkcipher = &#123; .min_keysize = AES_MIN_KEY_SIZE, .max_keysize = AES_MAX_KEY_SIZE, .ivsize = AES_BLOCK_SIZE, .setkey = atmel_aes_setkey, .encrypt = atmel_aes_cbc_encrypt, .decrypt = atmel_aes_cbc_decrypt, &#125;&#125;,&#125;; 2. encrypt flow每当encryp 时， 我们将使用ablkcipher_enqueue_request()把ablkcipher_request *req 添加到队列上。在判断HW engine 是空闲可用时，再从queue 上取出并进行HW 的加解密操作。decrypt 的流程如此类似，区别在于设定HW 的mode 设定。 2.1. data structure123456789101112131415struct crypto_queue &#123; struct list_head list; struct list_head *backlog; unsigned int qlen; unsigned int max_qlen;&#125;;struct ablkcipher_request &#123; struct crypto_async_request base; unsigned int nbytes; void *info; struct scatterlist *src; struct scatterlist *dst; void *__ctx[] CRYPTO_MINALIGN_ATTR;&#125;; 在中断完成后，atmel_aes_done_task（）-&gt; atmel_aes_finish_req() -&gt; req-&gt;base.complete(&amp;req-&gt;base, err) 这样会调用到complete（） 完成函数，实现了异步的通知行为。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static void atmel_aes_done_task(unsigned long data)&#123; struct atmel_aes_dev *dd = (struct atmel_aes_dev *) data; int err; if (!(dd-&gt;flags &amp; AES_FLAGS_DMA)) &#123; atmel_aes_read_n(dd, AES_ODATAR(0), (u32 *) dd-&gt;buf_out, dd-&gt;bufcnt &gt;&gt; 2); if (sg_copy_from_buffer(dd-&gt;out_sg, dd-&gt;nb_out_sg, dd-&gt;buf_out, dd-&gt;bufcnt)) err = 0; else err = -EINVAL; goto cpu_end; &#125; err = atmel_aes_crypt_dma_stop(dd); err = dd-&gt;err ? : err; if (dd-&gt;total &amp;&amp; !err) &#123; if (dd-&gt;flags &amp; AES_FLAGS_FAST) &#123; dd-&gt;in_sg = sg_next(dd-&gt;in_sg); dd-&gt;out_sg = sg_next(dd-&gt;out_sg); if (!dd-&gt;in_sg || !dd-&gt;out_sg) err = -EINVAL; &#125; if (!err) err = atmel_aes_crypt_dma_start(dd); if (!err) return; /* DMA started. Not fininishing. */ &#125;cpu_end: atmel_aes_finish_req(dd, err); atmel_aes_handle_queue(dd, NULL);&#125;static void atmel_aes_finish_req(struct atmel_aes_dev *dd, int err)&#123; struct ablkcipher_request *req = dd-&gt;req; clk_disable_unprepare(dd-&gt;iclk); dd-&gt;flags &amp;= ~AES_FLAGS_BUSY; req-&gt;base.complete(&amp;req-&gt;base, err);&#125; 我们可以参看kernel/crypto/testmgr.c 中的测试代码，它的使用案例。 init_completion(&amp;result.completion);ablkcipher_request_alloc(tfm, GFP_KERNEL);ablkcipher_request_set_callback(req,CRYPTO_TFM_REQ_MAY_BACKLOG, tcrypt_complete, &amp;result);crypto_ablkcipher_clear_flags(tfm, ~0);crypto_ablkcipher_setkey(tfm, template[i].key, template[i].klen);ablkcipher_request_set_crypt(req, sg, sgout, template[i].ilen, iv);crypto_ablkcipher_encrypt(req);crypto_ablkcipher_decrypt(req); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596static void tcrypt_complete(struct crypto_async_request *req, int err)&#123; struct tcrypt_result *res = req-&gt;data; if (err == -EINPROGRESS) return; res-&gt;err = err; complete(&amp;res-&gt;completion);&#125;static int __test_skcipher(struct crypto_ablkcipher *tfm, int enc, struct cipher_testvec *template, unsigned int tcount, const bool diff_dst, const int align_offset)&#123; const char *algo = crypto_tfm_alg_driver_name(crypto_ablkcipher_tfm(tfm)); unsigned int i, j, k, n, temp; char *q; struct ablkcipher_request *req; struct scatterlist sg[8]; struct scatterlist sgout[8]; const char *e, *d; struct tcrypt_result result; void *data; char iv[MAX_IVLEN]; char *xbuf[XBUFSIZE]; char *xoutbuf[XBUFSIZE]; int ret = -ENOMEM; init_completion(&amp;result.completion); req = ablkcipher_request_alloc(tfm, GFP_KERNEL); ablkcipher_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG, tcrypt_complete, &amp;result); j = 0; for (i = 0; i &lt; tcount; i++) &#123; if (template[i].np &amp;&amp; !template[i].also_non_np) continue; if (template[i].iv) memcpy(iv, template[i].iv, MAX_IVLEN); else memset(iv, 0, MAX_IVLEN); j++; data = xbuf[0]; data += align_offset; memcpy(data, template[i].input, template[i].ilen); crypto_ablkcipher_clear_flags(tfm, ~0); ret = crypto_ablkcipher_setkey(tfm, template[i].key, template[i].klen); sg_init_one(&amp;sg[0], data, template[i].ilen); ablkcipher_request_set_crypt(req, sg, (diff_dst) ? sgout : sg, template[i].ilen, iv); ret = enc ? crypto_ablkcipher_encrypt(req) : crypto_ablkcipher_decrypt(req); switch (ret) &#123; case 0: break; case -EINPROGRESS: case -EBUSY: ret = wait_for_completion_interruptible( &amp;result.completion); if (!ret &amp;&amp; !((ret = result.err))) &#123; reinit_completion(&amp;result.completion); break; &#125; /* fall through */ default: pr_err("alg: skcipher%s: %s failed on test %d for %s: ret=%d\n", d, e, j, algo, -ret); goto out; &#125; q = data; if (memcmp(q, template[i].result, template[i].rlen)) &#123; pr_err("alg: skcipher%s: Test %d failed on %s for %s\n", d, j, e, algo); hexdump(q, template[i].rlen); ret = -EINVAL; goto out; &#125; &#125; ret = 0;out: ablkcipher_request_free(req); return ret;&#125; 参看资料3.18.11/drivers/crypto/atmel-aes.c]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>cryptographic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_crypto_I]]></title>
    <url>%2F2019%2F08%2F06%2Fkernel-crypto-I%2F</url>
    <content type="text"><![CDATA[1. 基础SE(Securty Engine) 提供encryption/decryption。SE 常见使用如下形式加解密： cipher engine(密码引擎) short messages（short message 指front message 的长度小于block cipher length） residue（残余） technology (residue 指当我们最后的数据是小于cipher input block length 剩下的data) 术语 解释 明文 原始信息 加密算法 以密钥为参数，对明文进行多种置换和转换的规则和步骤，变换结果为密文。 密钥 加密与解密算法的参数，直接影响对明文进行变换的结果 密文 对明文进行变换的结果 解密算法 加密算法的逆变换，以密文为输入、密钥为参数，变换结果为明文 1.1. 常见cipher engine AES 128/192/256 DES TDES(EEE/DDD/EDE/DED) 当然cipher 还有如下full chain(加密模式) 可以搭配, 例如AES_ECB, DES_CBC等。 ECB CBC CTR OFB CFB 例如ECB 模式： residue ecb_clr： shortmessage ecb_clr: cipher chain CLR (short message) XOR(IV1)(short message) XOR(IV2)(short message) CLR(residue) RBT(residue) CTS(residue) AES_ECB O X X O X X AES_CBC O X X O O O AES_CTR X O X X O O AES_OFB O X X O X X AES_CFB O X X O X X DES_ECB O X X O X X DES_CBC O X X O X X DES_CBC X O O X O X DES_CTR O X X O X X DES_OFB O X X O X X DES_CFB O X X O X X TES_ECB O X X O X X TES_CBC O X X O X X TES_CBC X O O X O X TES_CTR O X X O X X TES_OFB O X X O X X TES_CFB O X X O X X 注： O: legal X: illegal 1.2. key(密钥)硬件模块支持set key。有些还提供了CPU cannot access 的internal key 进一步保证安全性。因此，我们在加密时需要选择何种key。 当然，internal key 是可以重新生成的，重新产生流程如下： 1.3. R/W 方式cryptographic 一般支持三种方式的encryption or decrytion: pio dma List + dma List Mode每一entry 内容常见为： attribute (algorithm) dma size dma r/w addr PIO Mode 2. Kernel Cryptocrypto 在kernel 中可以分为如下几类（）： cipher (AES, DES, TDES等)1.1. Symmetric cipher(ablkcipher, blkcipher, cipher)1.2. aead cipher(Authenticated Encryption with Associated Data ) compress(zlib, lzo 等) digest (摘要算法例如crc32, sha1, md5等) random （软件层随机数） hash (CAC, HMAC, XCBC, VMAC 等) 2.1. kernel menuconfig kernel 的crypto 子系统采用了分层的思想。作者使用crypto_alg 代表算法例如（AES_CBC, DES_CBC等）， crypto_tfm 代表用户实例化的对象，它包含了算法与处理逻辑。 crt_u里面的回调函数和cra_u中的回调函数名称几乎一模一样，但是它们的层次不同，crt中的函数实现了一大类算法的运行逻辑，比如cipher中的des中的块应该怎么分割等等，虽然对于摘要算法，sha1或者别的什么的算法逻辑没有什么区别，但是对于cipher来讲就不是这样了，同一种算法可能拥有ecb，cbc，fcb等不同的模式，于是就来了个中间层，这个中间层就是上面的联合体crt_u。 2.2. data structure123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354struct crypto_alg &#123; struct list_head cra_list; struct list_head cra_users; u32 cra_flags; unsigned int cra_blocksize; unsigned int cra_ctxsize; unsigned int cra_alignmask; int cra_priority; atomic_t cra_refcnt; char cra_name[CRYPTO_MAX_ALG_NAME]; char cra_driver_name[CRYPTO_MAX_ALG_NAME]; const struct crypto_type *cra_type; union &#123; struct ablkcipher_alg ablkcipher; struct aead_alg aead; struct blkcipher_alg blkcipher; struct cipher_alg cipher; struct compress_alg compress; struct rng_alg rng; &#125; cra_u; int (*cra_init)(struct crypto_tfm *tfm); void (*cra_exit)(struct crypto_tfm *tfm); void (*cra_destroy)(struct crypto_alg *alg); struct module *cra_module;&#125;;/* * Transforms: user-instantiated objects which encapsulate algorithms * and core processing logic. Managed via crypto_alloc_*() and * crypto_free_*(), as well as the various helpers below. */struct crypto_tfm &#123; u32 crt_flags; union &#123; struct ablkcipher_tfm ablkcipher; struct aead_tfm aead; struct blkcipher_tfm blkcipher; struct cipher_tfm cipher; struct hash_tfm hash; struct compress_tfm compress; struct rng_tfm rng; &#125; crt_u; void (*exit)(struct crypto_tfm *tfm); struct crypto_alg *__crt_alg; void *__crt_ctx[] CRYPTO_MINALIGN_ATTR;&#125;; 2.3. usagekernel中crypto 相关源码在两个位置： ${kernel_src}/crypto （向Kernel或userspace提供的api） ${kernel_src}/drivers/crypto （支持硬件加密的驱动） tfm 的管理通过如下函数：12crypto_alloc_tfm()crypto_free_tfm() 在SE 驱动中，我们使用crypto_register_alg() 将他们添加到list中1234int crypto_register_algs(struct crypto_alg *algs, int count;list_add(&amp;alg-&gt;cra_list, &amp;crypto_alg_list);int crypto_unregister_algs(struct crypto_alg *algs, int count); 他们的使用关系大致如下： crypto API &lt;—&gt; crypto core &lt;—&gt; crypto_register_alg 参看资料常用加解密算法总结1-DES、TDES、3DES Linux加密框架设计与实现(转) linux内核cryto接口的实现以及与openssl的比较 Linux Kernel Crypto API 什么是AEAD加密]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>cryptographic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_virtual_addr_map]]></title>
    <url>%2F2019%2F07%2F12%2Fkernel-virtual-addr-map%2F</url>
    <content type="text"><![CDATA[1. User spacemmap, munmap - map or unmap files or devices into memory.将文件或者设备与内存映射起来。 12345678#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *addr, size_t length);#include &lt;unistd.h&gt;int getpagesize(void); 2. Kernel space2.1. 静态映射start_kernel() -&gt;&nbsp;&nbsp;setup_arch() -&gt;&nbsp;&nbsp;&nbsp;&nbsp; paging_init() -&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;devicemaps_init(const struct machine_desc *mdesc) -&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mdesc-&gt;map_io() 涉及到的结构体struct machine_desc1234567891011121314151617181920212223242526272829struct machine_desc &#123; unsigned int nr; /* architecture number */ const char *name; /* architecture unsigned int nr_irqs; /* number of IRQs */#ifdef CONFIG_ZONE_DMA phys_addr_t dma_zone_size; /* size of DMA-able area */#endif void (*init_meminfo)(void); void (*reserve)(void);/* reserve mem blocks */ void (*map_io)(void);/* IO mapping function */ void (*init_early)(void); void (*init_irq)(void); void (*init_time)(void); void (*init_machine)(void); void (*init_late)(void);#ifdef CONFIG_MULTI_IRQ_HANDLER void (*handle_irq)(struct pt_regs *);#endif void (*restart)(enum reboot_mode, const char *);&#125;;struct map_desc &#123; unsigned long virtual; unsigned long pfn; unsigned long length; unsigned int type;&#125;; 例如我们在arch/arm/mach-s3c24xx/mach-smdk2440.csmdk2440_map_io() -&gt;&nbsp;&nbsp;iotable_init(mach_desc, size) 123456789101112131415161718static struct map_desc smdk2440_iodesc[] __initdata = &#123; &#123; .virtual = (u32)S3C24XX_VA_ISA_WORD, .pfn = __phys_to_pfn(S3C2410_CS2), .length = 0x10000, .type = MT_DEVICE, &#125;, &#125;;MACHINE_START(S3C2440, "SMDK2440") /* Maintainer: Ben Dooks &lt;ben-linux@fluff.org&gt; */ .atag_offset = 0x100, .init_irq = s3c2440_init_irq, .map_io = smdk2440_map_io, .init_machine = smdk2440_machine_init, .init_time = smdk2440_init_time,MACHINE_END 在这一步定义了物理与虚拟地址之间的映射关系，一旦编译完成就不会修改， 静态编译常用于不容易变动的物理地址与虚拟地址之间的映射，例如寄存器的映射。 2.2. 页表创建Linux下的页表映射分为两种，一是Linux自身的页表映射，另一种是ARM32 MMU硬件的映射。这样是为了更大的灵活性，可以映射Linux bits 到 硬件tables 上，例如有YOUNG, DIRTY bits. 参见 linux/arch/arm/include/asm/pagetable-2level.h 注释：1234567891011121314151617181920212223242526272829303132333435/* * Hardware-wise, we have a two level page table structure, where the first * level has 4096 entries, and the second level has 256 entries. Each entry * is one 32-bit word. Most of the bits in the second level entry are used * by hardware, and there aren't any "accessed" and "dirty" bits. * * Linux on the other hand has a three level page table structure, which can * be wrapped to fit a two level page table structure easily - using the PGD * and PTE only. However, Linux also expects one "PTE" table per page, and * at least a "dirty" bit. * * Therefore, we tweak the implementation slightly - we tell Linux that we * have 2048 entries in the first level, each of which is 8 bytes (iow, two * hardware pointers to the second level.) The second level contains two * hardware PTE tables arranged contiguously, preceded by Linux versions * which contain the state information Linux needs. We, therefore, end up * with 512 entries in the "PTE" level. * * This leads to the page tables having the following layout: * * pgd pte * | | * +--------+ * | | +------------+ +0 * +- - - - + | Linux pt 0 | * | | +------------+ +1024 * +--------+ +0 | Linux pt 1 | * | |-----&gt; +------------+ +2048 * +- - - - + +4 | h/w pt 0 | * | |-----&gt; +------------+ +3072 * +--------+ +8 | h/w pt 1 | * | | +------------+ +4096 * * See L_PTE_xxx below for definitions of bits in the "Linux pt", and * PTE_xxx for definitions of bits appearing in the "h/w pt". 32bit的Linux采用三级映射：PGD–&gt;PMD–&gt;PTE，64bit的Linux采用四级映射：PGD–&gt;PUD–&gt;PMD–&gt;PTE，多了个PUD PGD - Page Global DirectoryPUD - Page Upper DirectoryPMD - Page Middle DirectoryPTE - Page Table Entry。 在ARM32 Linux采用两层映射，省略了PMD，除非在定义了CONFIG_ARM_LPAE才会使用3级映射。 更多可以参看&lt;&gt; (ARM DDI 0406C.c (ID051414)) B3 Virtual Memory System Architecture (VMSA) iotable_init()-&gt;&nbsp;&nbsp;create_mapping()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;alloc_init_pud()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alloc_init_pmd()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alloc_init_pte()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set_pte_ext-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu_set_pte_ext()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu_v7_set_pte_ext() （linux/arm/arm/mm/proc-v7-2level.S） 12345678910111213141516171819202122232425void __init create_mapping(struct map_desc *md)&#123; ... pgd = pgd_offset_k(addr); end = addr + length; do &#123; unsigned long next = pgd_addr_end(addr, end); alloc_init_pud(pgd, addr, next, phys, type); phys += next - addr; addr = next; &#125; while (pgd++, addr != end); &#125;static void __init alloc_init_pte(pmd_t *pmd, unsigned long addr, unsigned long end, unsigned long pfn, const struct mem_type *type)&#123; pte_t *pte = early_pte_alloc(pmd, addr, type-&gt;prot_l1); do &#123; set_pte_ext(pte, pfn_pte(pfn, __pgprot(type-&gt;prot_pte)), 0); pfn++; &#125; while (pte++, addr += PAGE_SIZE, addr != end);&#125; set_pte_ext()函数，根据配置情况最终指向的是cpu_v7_set_pte_ext()12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* * cpu_v7_set_pte_ext(ptep, pte) * * Set a level 2 translation table entry. * * - ptep - pointer to level 2 translation table entry * (hardware version is stored at +2048 bytes) * - pte - PTE value to store * - ext - value for extended PTE bits */ENTRY(cpu_v7_set_pte_ext)#ifdef CONFIG_MMU str r1, [r0] @ linux version bic r3, r1, #0x000003f0 bic r3, r3, #PTE_TYPE_MASK orr r3, r3, r2 orr r3, r3, #PTE_EXT_AP0 | 2 tst r1, #1 &lt;&lt; 4 orrne r3, r3, #PTE_EXT_TEX(1) eor r1, r1, #L_PTE_DIRTY tst r1, #L_PTE_RDONLY | L_PTE_DIRTY orrne r3, r3, #PTE_EXT_APX tst r1, #L_PTE_USER orrne r3, r3, #PTE_EXT_AP1 tst r1, #L_PTE_XN orrne r3, r3, #PTE_EXT_XN tst r1, #L_PTE_YOUNG tstne r1, #L_PTE_VALID eorne r1, r1, #L_PTE_NONE tstne r1, #L_PTE_NONE moveq r3, #0 ARM( str r3, [r0, #2048]! ) THUMB( add r0, r0, #2048 ) THUMB( str r3, [r0] ) ALT_SMP(W(nop)) ALT_UP (mcr p15, 0, r0, c7, c10, 1) @ flush_pte#endif bx lrENDPROC(cpu_v7_set_pte_ext) 2.3. 动态映射2.3.1. virtual memory data structlinux/include/linux/mm_types.h 1234567891011121314151617181920212223242526272829303132333435363738394041struct mm_struct &#123; struct vm_area_struct *mmap; /* list of VMAs */ #ifdef CONFIG_MMU unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags);#endif unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ unsigned long highest_vm_end; /* highest vma end address */ pgd_t * pgd; atomic_long_t nr_ptes; /* Page table pages */ unsigned long start_code, end_code, start_data, end_data; unsigned long start_brk, brk, start_stack; unsigned long arg_start, arg_end, env_start, env_end; /* Architecture-specific MM context */ mm_context_t context; ...&#125;struct vm_area_struct &#123; unsigned long vm_start; /* Our start address within vm_mm. */ unsigned long vm_end; /* The first byte after our end address within vm_mm. */ struct vm_area_struct *vm_next, *vm_prev; /* Second cache line starts here. */ struct mm_struct *vm_mm; /* The address space we belong to. */ pgprot_t vm_page_prot; /* Access permissions of this VMA. */ unsigned long vm_flags; /* Flags, see mm.h. */ /* Information about our backing store: */ unsigned long vm_pgoff; /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */&#125;; 我们在kernel 中想要访问当前进程的mm_struct，可以使用current1struct mm_struct *mm = current-&gt;mm; 另外，我们可以访问 /proc//maps 得到某一进程的内存区域。（/proc/self 始终指向正在运行的进程） 字段 含义 00400000-0040b000 vma-&gt;vm_start ~ vma-&gt;vm_end r-xp vma-&gt;vm_flags 00000000 vma-&gt;vm_pgoff 08:01 主从设备号 1171031 设备节点inode 值 bin/cat 设备节点名字 2.3.2. memory mapping在使用high mem addr时，我们需要如下函数：12345void *kmap(struct page * page)void kunmap(struct page *page)void *kmap_atomic(struct page * page)void kumap_atomic(struct page *page) 如果* page 是low mem addr 直接返回，反之，是high mem addr kmap()在内核专用的空间创建特殊的映射。kmap() 可能会睡眠，而kmap_atomic() 会进行原子操作，不允许sleep. kernel 映射函数 remap_pfn_range() 注意: 如果使用的high mem， vmalloc() 分配的空间，我们只能PAGE_SIZE 的进行映射，他们本身逻辑连续，而物理地址非连续。 12345678910111213141516171819202122int remap_pfn_range(struct vm_area_struct *vma, unsigned long addr, unsigned long pfn, unsigned long size, pgprot_t prot)&#123; pgd_t *pgd; unsigned long next; unsigned long end = addr + PAGE_ALIGN(size); struct mm_struct *mm = vma-&gt;vm_mm; int err; pfn -= addr &gt;&gt; PAGE_SHIFT; pgd = pgd_offset(mm, addr); flush_cache_range(vma, addr, end); do &#123; next = pgd_addr_end(addr, end); err = remap_pud_range(mm, pgd, addr, next, pfn + (addr &gt;&gt; PAGE_SHIFT), prot); if (err) break; &#125; while (pgd++, addr = next, addr != end); return err;&#125; 调用关系如下：remap_pfn_range()-&gt;&nbsp;&nbsp;remap_pud_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;remap_pmd_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;remap_pte_range() 12345678910111213141516171819202122232425262728293031323334353637/* * maps a range of physical memory into the requested pages. the old * mappings are removed. any references to nonexistent pages results * in null mappings (currently treated as "copy-on-access") */static int remap_pte_range(struct mm_struct *mm, pmd_t *pmd, unsigned long addr, unsigned long end, unsigned long pfn, pgprot_t prot)&#123; pte_t *pte; spinlock_t *ptl; pte = pte_alloc_map_lock(mm, pmd, addr, &amp;ptl); do &#123; BUG_ON(!pte_none(*pte)); set_pte_at(mm, addr, pte, pte_mkspecial(pfn_pte(pfn, prot))); pfn++; &#125; while (pte++, addr += PAGE_SIZE, addr != end); pte_unmap_unlock(pte - 1, ptl); return 0;&#125;static inline void set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep, pte_t pteval)&#123; unsigned long ext = 0; if (addr &lt; TASK_SIZE &amp;&amp; pte_valid_user(pteval)) &#123; if (!pte_special(pteval)) __sync_icache_dcache(pteval); ext |= PTE_EXT_NG; &#125; set_pte_ext(ptep, pteval, ext);&#125; 可以看到与上面的静态映射其实也是差不多的，最终也会调用到set_pte_ext() -&gt; cpu_v7_set_pte_ext() 函数。 因此，映射的本质都是重新建立页表2-level 或 3-level，并刷新页表 2.3.3. io memory mappingioremap将一个IO地址空间映射到内核的虚拟地址空间上去，便于访问。ioremap 百度百科 12345#define ioremap(cookie,size) __arm_ioremap((cookie), (size), MT_DEVICE)#define ioremap_nocache(cookie,size) __arm_ioremap((cookie), (size), MT_DEVICE)#define ioremap_cache(cookie,size) __arm_ioremap((cookie), (size), MT_DEVICE_CACHED)#define ioremap_wc(cookie,size) __arm_ioremap((cookie), (size), MT_DEVICE_WC)#define iounmap __arm_iounmap &nbsp;&nbsp;ioremap()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;arm_ioremap()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arm_ioremap_caller()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arm_ioremap_pfn_caller()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ioremap_page_range() -&gt;__&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ioremap_page_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ioremap_pud_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ioremap_pmd_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ioremap_pte_range()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set_pte_at()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set_pte_ext()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu_set_pte_ext()-&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu_v7_set_pte_ext() （linux/arm/arm/mm/proc-v7-2level.S） 可以看见，大致与上面的静态映射，动态映射是相同的， 只是不同点在于__arm_ioremap_pfn_caller（） 函数中调用get_vm_area_caller（）进行vm_area 空间的申请。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748void __iomem * __arm_ioremap_pfn_caller(unsigned long pfn, unsigned long offset, size_t size, unsigned int mtype, void *caller)&#123; const struct mem_type *type; int err; unsigned long addr; struct vm_struct *area; phys_addr_t paddr = __pfn_to_phys(pfn);#ifndef CONFIG_ARM_LPAE /* * High mappings must be supersection aligned */ if (pfn &gt;= 0x100000 &amp;&amp; (paddr &amp; ~SUPERSECTION_MASK)) return NULL;#endif type = get_mem_type(mtype); if (!type) return NULL; size = PAGE_ALIGN(offset + size); /* * Try to reuse one of the static mapping whenever possible. */ if (size &amp;&amp; !(sizeof(phys_addr_t) == 4 &amp;&amp; pfn &gt;= 0x100000)) &#123; struct static_vm *svm; svm = find_static_vm_paddr(paddr, size, mtype); if (svm) &#123; addr = (unsigned long)svm-&gt;vm.addr; addr += paddr - svm-&gt;vm.phys_addr; return (void __iomem *) (offset + addr); &#125; &#125; area = get_vm_area_caller(size, VM_IOREMAP, caller); addr = (unsigned long)area-&gt;addr; area-&gt;phys_addr = paddr; err = ioremap_page_range(addr, addr + size, paddr, __pgprot(type-&gt;prot_pte)); flush_cache_vmap(addr, addr + size); return (void __iomem *) (offset + addr);&#125; get_vm_area_caller（）函数可以看见是从 VMALLOC_START ~ VMALLOC_END区域内分配一个空间。 注:由于我们的ioremap（）是将IO 连续的物理地址映射成Kernel 能访问的虚拟地址， 所以本身物理地址的连续性是能保证的。vmalloc.c 中的核心函数get_vm_area_caller（）详细分析可见最后的参看资料。123456struct vm_struct *get_vm_area_caller(unsigned long size, unsigned long flags, const void *caller)&#123; return __get_vm_area_node(size, 1, flags, VMALLOC_START, VMALLOC_END, NUMA_NO_NODE, GFP_KERNEL, caller);&#125; 1234567891011121314151617static int ioremap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end, phys_addr_t phys_addr, pgprot_t prot)&#123; pte_t *pte; u64 pfn; pfn = phys_addr &gt;&gt; PAGE_SHIFT; pte = pte_alloc_kernel(pmd, addr); if (!pte) return -ENOMEM; do &#123; BUG_ON(!pte_none(*pte)); set_pte_at(&amp;init_mm, addr, pte, pfn_pte(pfn, prot)); pfn++; &#125; while (pte++, addr += PAGE_SIZE, addr != end); return 0;&#125; io_remap_page_range() 如果没有定义，则该函数是等效于remap_pfn_range()123#ifndef io_remap_pfn_range#define io_remap_pfn_range remap_pfn_range#endif 2.3.4. dma memory mapping参见之前文章 -&gt; DMA memory mapping 参看资料basic虚拟地址映射机制–动态、静态 Linux的mmap内存映射机制解析 ARM MMU页表框架 Linux内存管理 (2)页表的映射过程 memory mapping内存映射函数remap_pfn_range学习——示例分析（1） 内存映射函数remap_pfn_range学习——示例分析（2） 内存映射函数remap_pfn_range学习——代码分析（3） ioremapLinux 字符设备驱动开发基础（五）—— ioremap() 函数解析 vmallocLinux高端内存映射(下) 高端内存映射之vmalloc分配内存中不连续的页–Linux内存管理(十九)]]></content>
      <categories>
        <category>memory</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_ubi]]></title>
    <url>%2F2019%2F07%2F05%2Fkernel-ubi%2F</url>
    <content type="text"><![CDATA[1. 背景Flash 设备存在如下缺点 存在坏块 使用寿命较短 存储介质不稳定(bitflip) 读写速度慢 只能通过擦除将0改成1 最小读写单位为page or sub-page Kernel 引入UBI (Unsorted Block Images)来解决这些问题。UBI 本身就是针对RAW Flash的一个卷管理系统，并且提供基于磨损均衡的逻辑到物理的映射。它类似于LVM（Logical Volume Manager) 因此UBI 具有如下特点： UBI provides volumes which may be dynamically created, removed, or re-sized UBI implements wear-leveling across whole flash device UBI transparently handles bad physical eraseblocks; UBI minimizes chances to lose data by means of scrubbing. （针对Nand Flash 的bit flip现象，将有bit-flips的数据块移动到好的数据块上） 2. 框架在kernel MTD 模块看来， UBI 子系统的框架如下图： UBI 子模块的文件组织结构如下图： 文件名 说明 cdev.c 字符设备节点访问操作, attach/detach MTD, volume add/remove/rename/resize build.c /dev/ubictrl, /sys 等节点注册 attach.c attach MTD sub-system vmt.c volume 逻辑操作，增删， 重命名， 重新设定size vtbl.c vmt.c 的下层，实际操作读写 fastmap.c 支持快速扫描MTD 设备 upd.c update volume, 考虑到突然掉电等引起的更新错误 eba.c Erase Block Association sub-system 子系统， 逻辑映射 wl.c wear-leveling sub-system 磨损均衡子系统 io.c 与MTD 设备I/O 交互, R/W data, VID(volume ID)/EC(Erase Counter) header kapi.c 向UBIFS 提供的api 接口 3. 代码分析3.1. 数据结构3.1.1. UBI HeadersUBI 包含两个被CRC32 保护的64 bytes header在每一个非坏块的开始： erase counter(EC) header volume identifier(VID) header 因此，LEB &lt; PEB 就是因为存储了UBI headers. 参见 drivers/mtd/ubi/ubi-media.h1234567891011struct ubi_ec_hdr &#123; __be32 magic; __u8 version; __u8 padding1[3]; __be64 ec; /* Warning: the current limit is 31-bit anyway! */ __be32 vid_hdr_offset; __be32 data_offset; __be32 image_seq; __u8 padding2[32]; __be32 hdr_crc;&#125; __packed; 每一次Erase 都会将EC 值增加。在unclean reboot 发生或者数据被corrupted， EC 将会被写入attach MTD 设备扫描的EC average。 123456789101112131415161718struct ubi_vid_hdr &#123; __be32 magic; __u8 version; __u8 vol_type; __u8 copy_flag; __u8 compat; __be32 vol_id; __be32 lnum; __u8 padding1[4]; __be32 data_size; __be32 used_ebs; __be32 data_pad; __be32 data_crc; __u8 padding2[4]; __be64 sqnum; __u8 padding3[12]; __be32 hdr_crc;&#125; __packed; EC header 存储offset 为0， 而VID header 存储offset 为next min I/O Unit, sub-page or page. NOR Flash, min I/O 为 1 byte, VID header offset 为64 Nand Flash, sub-page or page 3.1.2. volume table数据是存储在flash 设备上， volume table 是ubit_vtbl_record 的数组，每一个记录它包含了如下meta-data: 卷名 保留物理擦除快的数量 类型(static or dynamica) crc 校验 update marker（用于标记更新volume name or size） 123456789101112struct ubi_vtbl_record &#123; __be32 reserved_pebs; __be32 alignment; __be32 data_pad; __u8 vol_type; __u8 upd_marker; __be16 name_len; __u8 name[UBI_VOL_NAME_MAX+1]; __u8 flags; __u8 padding[23]; __be32 crc;&#125; __packed; UBI 使用了两个逻辑擦除快(Logical EraseBlock)保存record 数据，LEB0 and LEB1. 他们两者相互拷贝，以此来保证突发事件例如掉电等异常情形。当attach MTD 设备时，UBI确保这两个volume table是相同的，否则上次可能是unclean boot导致，使用新的，无corrupted data 拷贝到另一块。 UBI 需要维护三种table: volume table eraseblock association(EBA) table erase counter(EC) table volume table 是存储在Flash 上，它的修改只会发生在create, delete, re-size 时。 EBA table 是用于logical to phsical 映射关系。EC table 包含每个PEB 的erase conter 值， UBI wear-leveling 将会使用此表格。 EBA, EC table 可以做到存储在flash 上，但是它需要journaling, journal replay, journal commit 等，在boot-loader 时保证简单，代码的size 是不太容易的。 因此， EBA, EC table 默认在attach MTD 时，根据扫描的EC,VID header 信息在RAM 中构建. 在vid_hdr 中包含的vol_id, lnum, squm 指定了他们的volume_id， squm 序列号， lnum 逻辑num 号， UBI attach 子系统在attach 时，根据这些信息创建red-block tree， 就能顺序读取data。 3.2. UBI Sub-system3.2.1. attach mtd本质是扫描(scan_all or scan_fast(fastmap))MTD 设备上的EC、VID header 信息生成volume 等结构体。 相关的数据接口如下： ubi_ainf_peb -&gt; ubi_ainf_volume.rb -&gt; ubi_attach_info.volume。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849struct ubi_attach_info &#123; struct rb_root volumes; struct list_head corr; struct list_head free; struct list_head erase; struct list_head alien; int corr_peb_count; int empty_peb_count; int alien_peb_count; int bad_peb_count; int maybe_bad_peb_count; int vols_found; int highest_vol_id; int is_empty; int min_ec; int max_ec; unsigned long long max_sqnum; int mean_ec; uint64_t ec_sum; int ec_count; struct kmem_cache *aeb_slab_cache;&#125;;struct ubi_ainf_volume &#123; int vol_id; int highest_lnum; int leb_count; int vol_type; int used_ebs; int last_data_size; int data_pad; int compat; struct rb_node rb; /* link in the volume RB-tree */ struct rb_root root;&#125;;struct ubi_ainf_peb &#123; int ec; int pnum; /* physical eraseblock number */ int vol_id; /* ID of the volume this LEB belongs to */ int lnum; /* logical eraseblock number */ unsigned int scrub:1; unsigned int copy_flag:1; unsigned long long sqnum; union &#123; struct rb_node rb; /* link in the per-volume RB-tree of &amp;struct ubi_ainf_peb objects */ struct list_head list; &#125; u;&#125;; scan_all() 扫描每一个peb 并读取其中的ec_hdr, vid_hdr。 这里分层了三层结构体： ubi_attach_info ubi_ainf_volume ubi_ainf_peb管理volume， 以及属于该volume 的全部pebs 分类清晰，便于管理。 ubi_read_volume_table() 会在RAM 中生成volume table record. 他们是存放在具体的vol_id 的前两个LEB[0,1]中， 在process_lvol() 读取数据，并检查是否数据污染。 3.2.2. eba, eraseblock association在attach 时候， 调用ubi_eba_init（）, UBI EBA 子系统会根据数据结构 ubi_attach_info -&gt; ubi_ainf_volume -&gt; ubi_ainf_peb, 在ubi_ainf_peb 里面记录了pnum, lnum，这就是物理逻辑映射关系。 1234567891011121314151617181920212223242526int ubi_eba_init(struct ubi_device *ubi, struct ubi_attach_info *ai)&#123; for (i = 0; i &lt; num_volumes; i++) &#123; vol = ubi-&gt;volumes[i]; if (!vol) continue; vol-&gt;eba_tbl = kmalloc(vol-&gt;reserved_pebs * sizeof(int), GFP_KERNEL); for (j = 0; j &lt; vol-&gt;reserved_pebs; j++) vol-&gt;eba_tbl[j] = UBI_LEB_UNMAPPED; av = ubi_find_av(ai, idx2vol_id(ubi, i)); if (!av) continue; ubi_rb_for_each_entry(rb, aeb, &amp;av-&gt;root, u.rb) &#123; if (aeb-&gt;lnum &gt;= vol-&gt;reserved_pebs) /* * This may happen in case of an unclean reboot * during re-size. */ ubi_move_aeb_to_list(av, aeb, &amp;ai-&gt;erase); vol-&gt;eba_tbl[aeb-&gt;lnum] = aeb-&gt;pnum; &#125; &#125;&#125; 后续的write, read 都是通过在RAM 中的eba_tlb 进行逻辑查询后，再调用到io -&gt; mtd.read/write假如EBA 没有映射， 调用Wear-leveling 子系统获取PEB。 至于lnum 的值在UBIFS 中体现，是从上层下来。UBI wear-leveling 会考虑磨损均衡的情况下选择合适的PEBs 映射到某一个lnum 上。 marking eraseblocks as bad判断依据： 写操作时失败，UBI 将数据搬移，并准备对该eraseblock 进行torturing(拷问，审查)。 erase 操作失败EIO error， 直接将它标记为bad torturing 主要是两方面 eraseblock, and read check all is 0xFF write data, and read check 3.2.3. wear-leveling磨损均衡是UBI的核心功能之一，负责管理PEB的分配、回收、擦除、scrub、磨损均衡等, 在这些操作时都会触发磨损均衡检查。其中scrub、擦除, 磨损均衡功能由UBI后台线程进行异步调度管理。 12345678struct ubi_wl_entry &#123; union &#123; struct rb_node rb; /* link in the corresponding (free/used) RB-tree*/ struct list_head list; &#125; u; int ec; int pnum;&#125;; 如果used peb 的EC 与free peb 的EC 差大于 UBI_WL_THRESHOLD 则会考虑使用wear-leveling 子系统进行磨损均衡搬移，避免过多的搬移数据造成本身的反复擦除。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697static int wear_leveling_worker(struct ubi_device *ubi, struct ubi_work *wrk, int shutdown)&#123; int err, scrubbing = 0, torture = 0, protect = 0, erroneous = 0; int vol_id = -1, uninitialized_var(lnum); struct ubi_wl_entry *e1, *e2; struct ubi_vid_hdr *vid_hdr; vid_hdr = ubi_zalloc_vid_hdr(ubi, GFP_NOFS); mutex_lock(&amp;ubi-&gt;move_mutex); spin_lock(&amp;ubi-&gt;wl_lock); if (!ubi-&gt;scrub.rb_node) &#123; /* * Now pick the least worn-out used physical eraseblock and a * highly worn-out free physical eraseblock. If the erase * counters differ much enough, start wear-leveling. */ e1 = rb_entry(rb_first(&amp;ubi-&gt;used), struct ubi_wl_entry, u.rb); e2 = get_peb_for_wl(ubi); if (!(e2-&gt;ec - e1-&gt;ec &gt;= UBI_WL_THRESHOLD)) &#123; dbg_wl("no WL needed: min used EC %d, max free EC %d", e1-&gt;ec, e2-&gt;ec); /* Give the unused PEB back */ wl_tree_add(e2, &amp;ubi-&gt;free); ubi-&gt;free_count++; goto out_cancel; &#125; rb_erase(&amp;e1-&gt;u.rb, &amp;ubi-&gt;used); dbg_wl("move PEB %d EC %d to PEB %d EC %d", e1-&gt;pnum, e1-&gt;ec, e2-&gt;pnum, e2-&gt;ec); &#125; else &#123; /* Perform scrubbing */ scrubbing = 1; e1 = rb_entry(rb_first(&amp;ubi-&gt;scrub), struct ubi_wl_entry, u.rb); e2 = get_peb_for_wl(ubi); rb_erase(&amp;e1-&gt;u.rb, &amp;ubi-&gt;scrub); dbg_wl("scrub PEB %d to PEB %d", e1-&gt;pnum, e2-&gt;pnum); &#125; ubi-&gt;move_from = e1; ubi-&gt;move_to = e2; spin_unlock(&amp;ubi-&gt;wl_lock); /* * Now we are going to copy physical eraseblock @e1-&gt;pnum to @e2-&gt;pnum. * We so far do not know which logical eraseblock our physical * eraseblock (@e1) belongs to. We have to read the volume identifier * header first. * * Note, we are protected from this PEB being unmapped and erased. The * 'ubi_wl_put_peb()' would wait for moving to be finished if the PEB * which is being moved was unmapped. */ err = ubi_io_read_vid_hdr(ubi, e1-&gt;pnum, vid_hdr, 0); vol_id = be32_to_cpu(vid_hdr-&gt;vol_id); lnum = be32_to_cpu(vid_hdr-&gt;lnum); err = ubi_eba_copy_leb(ubi, e1-&gt;pnum, e2-&gt;pnum, vid_hdr); /* The PEB has been successfully moved */ if (scrubbing) ubi_msg("scrubbed PEB %d (LEB %d:%d), data moved to PEB %d", e1-&gt;pnum, vol_id, lnum, e2-&gt;pnum); ubi_free_vid_hdr(ubi, vid_hdr); spin_lock(&amp;ubi-&gt;wl_lock); if (!ubi-&gt;move_to_put) &#123; wl_tree_add(e2, &amp;ubi-&gt;used); e2 = NULL; &#125; ubi-&gt;move_from = ubi-&gt;move_to = NULL; ubi-&gt;move_to_put = ubi-&gt;wl_scheduled = 0; spin_unlock(&amp;ubi-&gt;wl_lock); err = do_sync_erase(ubi, e1, vol_id, lnum, 0); if (e2) &#123; /* * Well, the target PEB was put meanwhile, schedule it for * erasure. */ dbg_wl("PEB %d (LEB %d:%d) was put meanwhile, erase", e2-&gt;pnum, vol_id, lnum); err = do_sync_erase(ubi, e2, vol_id, lnum, 0); if (err) goto out_ro; &#125; mutex_unlock(&amp;ubi-&gt;move_mutex); return 0;&#125; 在EBA write 时，如果没有映射，我们就会调用ubi_wl_get_peb() 获取free PEB。 drivers/mtd/ubi/wl.c *ubi_wl_get_peb() -&gt;&nbsp;&nbsp;__wl_get_peb() -&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374int ubi_eba_write_leb(struct ubi_device *ubi, struct ubi_volume *vol, int lnum, const void *buf, int offset, int len)&#123; int err, pnum, tries = 0, vol_id = vol-&gt;vol_id; struct ubi_vid_hdr *vid_hdr; err = leb_write_lock(ubi, vol_id, lnum); pnum = vol-&gt;eba_tbl[lnum]; if (pnum &gt;= 0) &#123; err = ubi_io_write_data(ubi, buf, pnum, offset, len); leb_write_unlock(ubi, vol_id, lnum); return err; &#125; /* * The logical eraseblock is not mapped. We have to get a free physical * eraseblock and write the volume identifier header there first. */ vid_hdr = ubi_zalloc_vid_hdr(ubi, GFP_NOFS); vid_hdr-&gt;vol_type = UBI_VID_DYNAMIC; vid_hdr-&gt;sqnum = cpu_to_be64(ubi_next_sqnum(ubi)); vid_hdr-&gt;vol_id = cpu_to_be32(vol_id); vid_hdr-&gt;lnum = cpu_to_be32(lnum); vid_hdr-&gt;compat = ubi_get_compat(ubi, vol_id); vid_hdr-&gt;data_pad = cpu_to_be32(vol-&gt;data_pad);retry: pnum = ubi_wl_get_peb(ubi); err = ubi_io_write_vid_hdr(ubi, pnum, vid_hdr); if (len) &#123; err = ubi_io_write_data(ubi, buf, pnum, offset, len); &#125; down_read(&amp;ubi-&gt;fm_sem); vol-&gt;eba_tbl[lnum] = pnum; up_read(&amp;ubi-&gt;fm_sem); leb_write_unlock(ubi, vol_id, lnum); ubi_free_vid_hdr(ubi, vid_hdr); return 0;&#125;static int __wl_get_peb(struct ubi_device *ubi)&#123; int err; struct ubi_wl_entry *e;retry: if (!ubi-&gt;free.rb_node) &#123; if (ubi-&gt;works_count == 0) &#123; ubi_err("no free eraseblocks"); ubi_assert(list_empty(&amp;ubi-&gt;works)); return -ENOSPC; &#125; err = produce_free_peb(ubi); goto retry; &#125; e = find_mean_wl_entry(ubi, &amp;ubi-&gt;free); /* * Move the physical eraseblock to the protection queue where it will * be protected from being moved for some time. */ rb_erase(&amp;e-&gt;u.rb, &amp;ubi-&gt;free); ubi-&gt;free_count--; return e-&gt;pnum;&#125; 3.2.4. fastmapfastmap 利用存储在flash 上的fastmap volume 以此来加速attach。fastmap 一般用于large flash， 例如4Gib Nand chips。是否启用fastmap, 需要考虑到fastmap 本身会占用一些PEB，并且fastmap pool full, volume layout change or detach时，fastmap都需要写入信息到保留的PEB 中。 fastmap volume中存储的信息有： erase value a list of all PEBs and their state a list of all volumes and their EBA a list of PEBs called fastmap pool fastmap 还有一个fastmap pool 概念， 它的size 大约为 5% of the total amount of PEBs。我们从fastmap pool 中取用PEBs，这样我们只需要关心fastmap pool 的PEBs， 而不用关心total PEBs, 减少了需要存储的信息量。 参看资料Linux UBI子系统设计初探 ubi 官方文档 ubi design pdf from MTD org ubi ppt from MTD org elinux/ubifs]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>mtd</tag>
        <tag>ubi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo_add_search]]></title>
    <url>%2F2019%2F07%2F04%2Fhexo-add-search%2F</url>
    <content type="text"><![CDATA[1. 前言当博文慢慢变多的时候，标签和分类已经不能提供太大的作用，无法准确的定位到自己想要看的博客上去，所以添加一个本站内搜索功能是很有必要的。 2. 安装插件1npm install hexo-generator-searchdb --save 修改blog下的_config.yml文件，进行编辑。 123456search: path: search.xml field: post format: html limit: 10000` 修改主题配置文件blog/themes/next下的_config.yml文件，进行编辑。 12local_search: enable: true 参看资料hexo博客添加搜索功能 Hexo博客添加站内搜索 Hexo 博客添加本地搜索]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ipv6]]></title>
    <url>%2F2019%2F07%2F03%2Fipv6%2F</url>
    <content type="text"><![CDATA[ipv6 号称可以为全世界的每一粒沙子编上一个地址。 1. 地址分类 1.1. 单播地址单播地址还可以分成如下几类： 全球单播地址 本地单播地址 链路本地地址(fe80) 唯一本地地址(fc00) 站点本地地址(fec0), 已弃用，被唯一本地地址代替 兼容性地址 特殊地址 未指定地址 环回地址 子类 地址前缀（二进制） ipv6前缀标识 全球单播地址 其他形式 - 链路本地地址 111 111 1010 FE80::/10 唯一本地地址 1111 110 FC00::/7（包括FD00::/8和不常用的FC00::/8） 环回地址 00…1(128 bits) ::1/128 未指定地址 00…0(128 bits) ::/128 1.1.1 全球单播地址等同于IPv4中的公网地址，可以在IPv6 Internet上进行全局路由和访问。 1.1.2 本地单播地址1.1.2.1. 链路本地地址仅用于单个链路（链路层不能跨VLAN），不能在不同子网中路由。 1.1.2.2. 唯一本地地址唯一本地地址是本地全局的，它应用于本地通信，但不通过Internet路由，将其范围限制为组织的边界。 1.1.3. 兼容性地址 在IPv6的转换机制中还包括了一种通过IPv4路由接口以隧道方式动态传递IPv6包的技术。这样的IPv6结点会被分配一个在低32位中带有全球IPv4单播地址的IPv6全局单播地址。另有一种嵌入IPv4的IPv6地址，用于局域网内部，这类地址用于把IPv4结点当作IPv6结点。此外，还有一种称为“6to4”的IPv6地址，用于在两个通过Internet同时运行IPv4和IPv6的结点之间进行通信。 1.1.4. 特殊地址包括未指定地址和环回地址。 1.2. 组播地址IPv6组播地址可识别多个接口，对应于一组接口的地址（通常分属不同节点）。发送到组播地址的数据包被送到由该地址标识的每个接口。 地址前缀（二进制） ipv6前缀标识 11111111 ff00::/8 1.3. 任播地址一个IPv6任播地址与组播地址一样也可以识别多个接口，对应一组接口的地址。大多数情况下，这些接口属于不同的节点。发送到任播地址的数据包被送到由该地址标识的其中一个接口（该地址识别的最近接口，最近接口定义的根据是因为路由距离最近）。 地址前缀（二进制） ipv6前缀标识 从单播地址空间中进行分配 使用单播地址的格式 2. 组成结构2.1. 表示方法IPv6的地址长度为128位，是IPv4地址长度的4倍。于是IPv4点分十进制格式不再适用，采用十六进制表示。IPv6有3种表示方法： 2.1.1. 冒分十六进制表示法格式为X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示，例如：ABCD:EF01:2345:6789:ABCD:EF01:2345:6789 2.1.2. 0位压缩表示法在某些情况下，一个IPv6地址中间可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中”::”只能出现一次，例如： FF01:0:0:0:0:0:0:1101 → FF01::11010:0:0:0:0:0:0:1 → ::10:0:0:0:0:0:0:0 → :: 2.1.3. 内嵌IPv4地址表示法为了实现IPv4-IPv6互通，IPv4地址会嵌入IPv6地址中，此时地址常表示为：X:X:X:X:X:X:d.d.d.d。例如::192.168.0.1与::FFFF:192.168.0.1就是两个典型的例子，注意在前96b中，压缩0位的方法依旧适用 参看资料ipv6 百度百科 ipv6地址的分类(关于FE80开头, FEC0开头的IPV6地址等的介绍) 了解IPv6链路本地地址]]></content>
      <categories>
        <category>ipv6</category>
      </categories>
      <tags>
        <tag>ipv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[buildbot]]></title>
    <url>%2F2019%2F07%2F02%2Fbuildbot%2F</url>
    <content type="text"><![CDATA[在openwrt 官网上看到buildbot， 他以此来完成在pull 代码之后，自动编译的工作并产出报告或者邮件通知等。buildbot官网 持续集成（Continuous Integration，CI）的主要优势是，能够通过软件的自动化构建以及测试和软件度量标准（可选）精简品质保证周期。每次更改源代码并为项目生命期提供即时反馈和报告。 1. buildbot 简介BuildBot是一个开源的基于python的持续集成系统，BuildBot用python写的，该python程序只依赖python环境和Twisted（一个python网络框架），可以在很多平台运行。 自动化构建一般包括自动下载源码，编译，测试，打包。他的工作原理可以参见下图: Buildbot的原理是git，SVN等源码服务器上代码发生变化后，buildmaster（服务端）通知连接到它上的buildslave（客户端）从git或SVN服务器上自动下载源码，编译，测试，打包。最后把各个buildslave的自动化构建的结果搜集起来在web上展现，或通过email,IRC等方式通知相应的项目开发人员。 BuildBot的常用架构是一个Master和一堆Slave，Master负责对接VCS，然后管理调度各个Slave各司其职，收集Slave传回来的数据并且整理成报告。Slave负责按照Master发过来的命令跑各种任务，并将环境信息，结果，log文件等收集起来报告给Master。 master master就是Buildbot的核心，我们使用Buildbot所需要做的各种工作也是在Master上进行。Buildbot的使用方式就是在Master上编辑master.cfg文件，这其实是一个Python文件。使用者在里面定义对接的VCS，Schedule和Build的各种条件以及具体的Build任务，结果的收集报告方式等。 slave 当slave连接到master后就会不断跟master进行通信。当有任务时，master会将命令逐个发送给slave执行。 2. Openwrt buildbot我们可以访问如下链接， 可以看到openwrt 的buildbot 的情况。 Phase 1: target/subtargets Phase 2: packages 3. 其他常见持续集成工具常见的持续集成工具有： Jenkins （java 方向） Hudson (java 方向，jenkins 的前身) strider travis （对开源项目免费） codeship（对开源项目免费） 部署工具(将这个版本的所有文件打包（ tar filename.tar * ）存档，发到生产服务器) ansible chef puppet 参看资料Buildbot TutorialBuildbot初探使用 Buildot 实现持续集成buildbot自动化测试工具安装及快速入门持续集成的魅力：工具推荐六款不容错过的开源持续集成工具持续集成是什么？]]></content>
      <categories>
        <category>CI</category>
      </categories>
      <tags>
        <tag>buildbot</tag>
        <tag>openwrt</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_dma_mem]]></title>
    <url>%2F2019%2F06%2F28%2Fkernel-dma-mem%2F</url>
    <content type="text"><![CDATA[在Kernel 中对于DMA 的一致性主要在驱动中会有需求，因为提供给硬件的地址，必须是总线地址即硬件地址且是连续的。为此，kernel提供了两种方式的DMA 映射： 一致性DMA 映射（Coherent DMA Map） 流式DMA 映射（Streaming DMA Map） 1. 一致性DMA 映射1.1. 一致性DMAkernel 提供了如下函数：12345678910void *dma_alloc_coherent(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flag, struct dma_attrs *attrs);#define dma_free_coherent(d, s, c, h) dma_free_attrs(d, s, c, h, NULL)void dma_free_coherent(struct device *dev, size_t size, void *cpu_addr, dma_addr_t dma_handle, struct dma_attrs *attrs); dma_alloc_coherent（）-&gt; arm_dma_alloc()123456789101112131415161718192021222324252627void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)&#123; pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL); void *memory; if (dma_alloc_from_coherent(dev, size, handle, &amp;memory)) return memory; return __dma_alloc(dev, size, handle, gfp, prot, false, __builtin_return_address(0));&#125;static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle, gfp_t gfp, pgprot_t prot, bool is_coherent, const void *caller)&#123; ... if (is_coherent || nommu()) addr = __alloc_simple_buffer(dev, size, gfp, &amp;page); else if (!(gfp &amp; __GFP_WAIT)) addr = __alloc_from_pool(size, &amp;page); else if (!dev_get_cma_area(dev)) addr = __alloc_remap_buffer(dev, size, gfp, prot, &amp;page, caller); else addr = __alloc_from_contiguous(dev, size, prot, &amp;page, caller); &#125; 根据配置，我们选择__alloc_remap_buffer（） 函数进行alloc， CMA 的方式了解请看下面的参看资料中的连接。CMA模块学习笔记 在alloc_remap_buffer（） 会进行alloc_pages 操作，并在dma_alloc_remap（）函数中进行page 属性的重新设定，标示为nocache, 这样就保证了CPU 与MEM 之间数据的一致性。1234567891011121314151617181920212223242526272829303132static void *__alloc_remap_buffer(struct device *dev, size_t size, gfp_t gfp, pgprot_t prot, struct page **ret_page, const void *caller)&#123; struct page *page; void *ptr; page = __dma_alloc_buffer(dev, size, gfp); if (!page) return NULL; ptr = __dma_alloc_remap(page, size, gfp, prot, caller); if (!ptr) &#123; __dma_free_buffer(page, size); return NULL; &#125; *ret_page = page; return ptr;&#125;static void *__dma_alloc_remap(struct page *page, size_t size, gfp_t gfp, pgprot_t prot, const void *caller)&#123; /* * DMA allocation can be mapped to user space, so lets * set VM_USERMAP flags too. */ return dma_common_contiguous_remap(page, size, VM_ARM_DMA_CONSISTENT | VM_USERMAP, prot, caller);&#125; 1.2 DMA 池1234dma_pool_create(name, dev, size, align, alloc);dma_pool_destroy(pool) pci_pool_destroy(pool);dma_pool_alloc(pool, flags, handle) pci_pool_alloc(pool, flags, handle);dma_pool_free(pool, vaddr, addr) pci_pool_free(pool, vaddr, addr); 2. 流式DMA 映射流式映射，kernel 还分为了两种形式： 多page 单个page 2.1. 多个page 流式映射LDD3 上也叫做分散/聚集映射，原理大致与单个page 映射相同， 不同点在于多个循环映射 struct scatterlist *sg 里面聚集的pages dma_data_direction分为如下几种： DMA_BIDIRECTIONAL （双向） DMA_FROM_DEVICE DMA_TO_DEVICE DMA_NONE 123456enum dma_data_direction &#123; DMA_BIDIRECTIONAL = 0, DMA_TO_DEVICE = 1, DMA_FROM_DEVICE = 2, DMA_NONE = 3,&#125;; 1234567int dma_map_sg(struct device *dev, struct scatterlist *sg, int nents, enum dma_data_direction dir, struct dma_attrs *attrs);void dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents, enum dma_data_direction dir, struct dma_attrs *attrs); 注意：在dma_unmap_sg 之前，CPU 是不能操作page的， 原因在于这些addr 都是cached 地址，只有在保证地址被flush 到主存中才能让CPU 操作 Kernel 封装了如下函数，帮助我们显示的刷新cache 的数据，保证数据cache, memory 之间的一致性。 使用dma_sync_sg_for_cpu（）函数，将使用权给CPU（之后Device 不能访问，否则数据不一致），使用dma_sync_sg_for_device（）函数，将使用权给Device（CPU 不能访问）。 1234567voiddma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems, enum dma_data_direction dir);voiddma_sync_sg_for_device(struct device *dev, struct scatterlist *sg, int nelems, enum dma_data_direction dir) ; 究其原因，是因为流式DMA缓冲区是cached，在map时刷了下cache，在设备DMA完成unmap时再刷cache（根据数据流向写回或者无效），来保证了cache数据一致性，在unmap之前CPU操作缓冲区是不能保证数据一致的。因此kernel需要严格保证操作时序。当然kernel也提供函数dma_sync_sg_for_cpu与dma_sync_sg_for_device，可以在未释放时操作缓冲区，很明显这2个函数实现中肯定是再次进行刷新cache的操作保证数据一致性。 2.2. 单个page 流式映射12dma_map_single(dev, addr, size, dir);dma_unmap_single(dev, hnd, size, dir); 与前面分散/聚集的多页映射一样， 我们不能在Device 访问期间，CPU 在访问，两者不能交互访问。1234567891011121314151617181920212223242526void dma_sync_single_for_cpu(struct device *dev, dma_addr_t addr, size_t size, enum dma_data_direction dir);void dma_sync_single_for_device(struct device *dev, dma_addr_t addr, size_t size, enum dma_data_direction dir); ``` dma_map_single ==&gt; __dma_map_page ==&gt; __dma_page_cpu_to_dev ==&gt; ___dma_page_cpu_to_dev ```cstatic void __dma_page_cpu_to_dev(struct page *page, unsigned long off, size_t size, enum dma_data_direction dir)&#123; phys_addr_t paddr; dma_cache_maint_page(page, off, size, dir, dmac_map_area); paddr = page_to_phys(page) + off; if (dir == DMA_FROM_DEVICE) &#123; outer_inv_range(paddr, paddr + size); &#125; else &#123; outer_clean_range(paddr, paddr + size); &#125; /* FIXME: non-speculating: flush on bidirectional mappings? */&#125; dmac_map_area 在我们配置的ARMV7 是指向的rch/arm/mm/cache-v7.S 文件中12345678910111213ENTRY(v7_dma_map_area) add r1, r1, r0 teq r2, #DMA_FROM_DEVICE beq v7_dma_inv_range b v7_dma_clean_rangeENDPROC(v7_dma_map_area)ENTRY(v7_dma_unmap_area) add r1, r1, r0 teq r2, #DMA_TO_DEVICE bne v7_dma_inv_range ret lrENDPROC(v7_dma_unmap_area) 我们由此可以看出dma_map_sigle() 最终是使用汇编指令clean 或者invalidate cache 里面的数据，保证cache 与mem 之间的一致性。因此，在给Device 访问后，禁止CPU 访问，除非使用dma_sync_single_for_cpu（）函数，以此来将cache 数据invalidate。 参看资料https://blog.csdn.net/skyflying2012/article/https://my.oschina.net/yepanl/blog/3053881http://www.wowotech.net/memory_management/cma.html]]></content>
      <categories>
        <category>memory</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel_mtd]]></title>
    <url>%2F2019%2F06%2F25%2Fkernel-mtd%2F</url>
    <content type="text"><![CDATA[1. Flash 大致分类 Nor Flash (intel 开发) Nand Flash (Toshiba 开发) OneNand Flash(Samsung 开发) NAND Flash在容量、功耗、使用寿命、写速度快、芯片面积小、单元密度高、擦除速度快、成本低等方面的优势使其成为高数据存储密度的理想解决方案。NOR Flash的传输效率很高，但写入和擦除速度较低； OneNAND结合了NAND存储密度高、写入速度快和NOR读取速度快的优点，整体性能完全超越常规的NAND和NOR。OneNAND采用NAND逻辑结构的存储内核和NOR的控制接口，并直接在系统内整合一定容量SRAM静态随即存储器作为高速缓冲区。 当OneNAND执行程序时，代码必须从OneNAND存储核心载入到SRAM，然后在SRAM上执行。由于SRAM的速度优势，数据载入动作几乎可以在瞬间完成，用户感觉不到迟滞现象，加上SRAM被直接封装在OneNAND芯片内部，外界看起来就好像是OneNAND也具备程序的本地执行功能。 Flash 读 写 擦除 坏块 XIP(eXecute In Place) 容量 寿命 成本 Nor Flash 100MBps 0.5MBps 0.3MBps - YES 常见&lt;= 32M 10几万 较高 Nand Flash 15MBps 7MBps 64MBps 有 - 大容量 100万 低 OneNand Flash 100MBps 10MBps 64MBps 有 YES 较大容量 100万 较低 1.1. 总线接口1.1.1. Nand FlashNand Flash 常见有： 总线接口Flash SPI Flash总线flash需要你的MCU上有外部总线接口，SPI flash就是通过SPI口对flash进行读写。速度上，总线flash比SPI的快，但是SPI的便宜。 如果Nand Flash 使用总线接口，一般pin 如下： Pins Function I/O 0-7(15) Data input or output(16 bit buswidth chips are supported in kernel) /CE Chip Enable /CLE Command Latch Enable ALE Address Latch Enable /RE Read Enable /WE Write Enable /WP Write Protect /SE Spare area Enable ( link to GND) R/B Ready / Busy Output At the moment there are only a few filesystems which support NAND: JFFS2 and YAFFS for bare NAND Flash and SmartMediaCards NTFL for DiskOnChip devices TRUEFFS from M-Systems for DiskOnChip devices SmartMedia DOS-FAT as defined by the SSFDC Forum UBIFS for bare NAND flash 1.1.2. Nor Flash在通信方式上Nor Flash 分为两种类型：CFI Flash和 SPI Flash。CFI Flash英文全称是common flash interface,也就是公共闪存接口，是由存储芯片工业界定义的一种获取闪存芯片物理参数和结构参数的操作规程和标准。CFI有许多关于闪存芯片的规定，有利于嵌入式对FLASH的编程。现在的很多NOR FLASH 都支持CFI，但并不是所有的都支持。 CFI接口，相对于串口的SPI来说，也被称为parallel接口，并行接口；另外，CFI接口是JEDEC定义的，所以，有的又成CFI接口为JEDEC接口。所以，可以简单理解为：对于Nor Flash来说，CFI接口＝JEDEC接口＝Parallel接口 = 并行接口 SPI Flashserial peripheral interface串行外围设备接口,是一种常见的时钟同步串行通信接口。 两者不同处CFI接口的的Nor Flash的针脚较多，芯片较大。之所有会有SPI接口, 可以减少针脚数目，减少芯片封装大小，采用了SPI后的Nor Flash，针脚只有8个。SPI容量都不是很大，读写速度慢，但是价格便宜，操作简单。而parallel接口速度快，容量上市场上已经有1Gmbit的容量，价格昂贵。 2. 延伸扩展 2.1. SSD SATA 接口 （串行口） 2.2. SSD NVME 接口 （PCIe 口） SSD技术扫盲之：什么是NVMe？ NVMe SSD有什么特点？ 3. Kernel MTD Source code Kernel 中MTD 的源码如下图所示： MTD 组成的源代码框架如下： 项目 说明 FTL Flash Translation Layer, 需要PCMCIA 硬件授权专利 NFTL Nand flash translation layer, 需要DiskOnChip 硬件授权专利 INFTL Inverse Nand flash translation layer, 需要DiskOnChip 硬件授权专利 spi-nor spi nor flash source code chips, maps CFI Nor Flash nand nand flash ubi unsorted block images, 基于raw flash 的卷管理系统 在mtd 目录下还有一些有意思的code, 他们分别是： mtdconcat.c 将多个MTD 设备组成一个MTD， 功能类似于rapid 磁盘阵列 cmdlinepart.c 提供解析启动参数中的MTD 信息 mtdswap.c 交换分区，用于wear leveling 记录erase counter， 但UBI 已经具备此功能 mtdsuper.c 用于向fs/jffs2, fs/romfs 提供挂载接口 4. 源代码框架Kernel MTD 在Kernel 中的结构如下： 在MTD Sub-system 中的结构如下： mtdchar.c 向flash tools 或者用户层提供IOCTL 操作。mtdblock.c 向kernel 提供block read/write sector访问。 他们两者的动态加载是通过mtdcore.c 中的add_mtd_device()函数。 例如在mtdblock.c 中：12345678910static struct mtd_notifier blktrans_notifier = &#123; .add = blktrans_notify_add, .remove = blktrans_notify_remove,&#125;;int register_mtd_blktrans(struct mtd_blktrans_ops *tr)&#123; ... register_mtd_user(&amp;blktrans_notifier);&#125; 在mtdcore.c 中12345678910111213141516int add_mtd_device(struct mtd_info *mtd)&#123; /* register char dev node */ mtd-&gt;dev.type = &amp;mtd_devtype; mtd-&gt;dev.class = &amp;mtd_class; mtd-&gt;dev.devt = MTD_DEVT(i); dev_set_name(&amp;mtd-&gt;dev, "mtd%d", i); dev_set_drvdata(&amp;mtd-&gt;dev, mtd); if (device_register(&amp;mtd-&gt;dev) != 0) goto fail_added; /* call mtd_notifiers, so it will call mtdblock.c blktrans_notify_add() */ list_for_each_entry(not, &amp;mtd_notifiers, list) not-&gt;add(mtd);&#125; 大致流程如下图所示： 注册相关数据结构：1234567891011121314struct mtd_part &#123; struct mtd_info mtd; struct mtd_info *master; uint64_t offset; struct list_head list;&#125;;struct mtd_partition &#123; const char *name; /* identifier string */ uint64_t size; /* partition size */ uint64_t offset; /* offset within the master MTD space */ uint32_t mask_flags; /* master MTD flags to mask out for this partition */ struct nand_ecclayout *ecclayout; /* out of band layout for this partition (NAND only) */&#125;; 参看资源：OneNAND 三星OneNAND技术 Nand Flash，Nor Flash，CFI Flash，SPI Flash 之间的关系 CFI与SPI flash区别 MTD 官网]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>mtd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员40岁后该如何发展]]></title>
    <url>%2F2019%2F06%2F03%2F2019-6-8%2F</url>
    <content type="text"><![CDATA[2019年6月8号，看到的记录。 网易技术大牛：程序员40岁后该如何发展？ 油腻的中年人，请对自己好一点 1. 网易技术大牛：程序员40岁后该如何发展？1.1. 总结–积累性程序员并不像医生，生物学等可以线性积累。个人的技能积累一般有三种： 抛物线 线性 指数型 因此，程序员也是强调积累性。我们可以通过如下： 个人博客（分享，方便自己查阅） 写书籍 （个人博客积累到一定程度） 参加开源社区，沙龙等交流，产生个人影响力等 1.2.成长录1.2.1.面试发现越大的企业越注重基础知识，计算机原理，数据结构，操作系统等。 （基础知识牢靠，人的可塑性更强，每方面都能去尝试） BAT，Facebook 等一般看中算法与思路。 1.2.2. 简历的书写建议1.2.2.1. 相对简单（不超过2、3页）信息多，对面试官不能选择重点。 1.2.2.2. 量化多使用量化的东西，少一些模糊的。如：多大规模，处理的多大的数据量，管理多少机器，处理的速度，实际如何。具体使用了什么技术。 1.2.2.3. 清晰（表格、列表），专业术语避免大段的描述，使用清晰的表格。 1.2.2.4. 点，面，体技术提炼（点）从平时的琐碎的事情中，发现提炼自我感觉或者行业中认为的技术亮点。我们就去深挖他。 横向对比(面)研究由点到面。从技术亮点展开。 你知道还有些什么方式技术可以达到这个需求？ 为什么选择当前的方式？ 其他方式的优缺点，适用环境？ 例如负载均衡的实现方式有哪些？ 拓展开(体)由面的发散，涉及的相关知识。 例如：你研究了多线程，你知道它内部的机理吗？有哪些同步机制等展开问题。 1.2.2.5. 理论升华反复阅读一些经典书籍（例如深入理解Linux网络内幕，深入理解Linux等四库全书），积攒一些理论体系，自己的底蕴。 有些东西，思路是相通的，学习理解类似的东西更快。例如：CPU的缓存，FS 的缓存，网络中的缓存，CDN 的缓存。 之前的点、面、体都是招式，理论升华是内功。 不仅能到达能用，而且还能说的头头是道，在面试时能总结说出自己做过的事情，避免吃亏。 例如：线程同步有这几种方式，什么情况下改用什么，现在是基于什么特殊场景，使用什么方式，这样比单纯的说只用了xxx技术更好。 1.2.3. 代码分析代码不会说谎。源码分析刚开始不能总结一些，需要借助书籍进行理论升华。 不要永远选择自己熟悉的上手，而是应该选择最核心的、有价值的东西。（脱离舒适区，善于去问大牛，放下面子） 1.2.4. 开源软件的源代码学习 手动安装 使用起来 经典相关数据 阅读核心源代码 Debug 1.3. 沟通的重要性分享，与同事，客户产品需要有效交流。 体系的思考，提前打好心理草稿： 要表达的点 要让比人get 到的点 2.油腻的中年人，请对自己好一点2.1. 要花额外的时间锻炼身体 健康排在第一位，任何事情，都不要拿健康去做交换。 2.2. 多花一些时间陪家人 happy wife, happy life.这是我最大的心得。 2.3. 旅行？阅读？培养几个自己的爱好。到世上一趟不容易，人生本身就是“体验”的集合： 空间维度，大千世界，多出去走走，被大自然的鬼斧神工所震撼 时间维度，历史长河，多阅读看看，学习前人多年的智慧沉淀除了上班，陪家人，尽量要有几项自己的兴趣爱好。 3. 年轻人必须尽早掌握的思维方式现在赚钱还是以后赚大钱？年轻人必须尽早掌握的思维方式！纯干货输出丨ztalk 3.1. 寻找确定性找到大概率可以成功的方法和道路。寻找确定性的结果，在过程中需要与人性，个人理论知识相结合，同时，也要拉长时间的维度。 例如选择长期的投资基金而不是做短期的频繁交易买进卖出，这样只会让基金公司赚得更多的管理费用。现在是夏天，短期的天气是不可能精确的，但是几个月之后一定会进入冬天。 3.2. 更高时间的维度去思考我们要做的就是基于长时间维度的考量，押注于更确定性的事情上。 例如，在大学期间，确定性的事情是：将有限的金钱加上无限时间和精力，投入到能让你赚钱的技能上，这远比投资理财要好的多。 同样，我们也应该站在人生的时间维度上去考虑事情（培养自己的眼光）。 3.3. 有舍有得，太极阴阳在某一个行业没有摧毁性的问题时，都会有阴阳，福兮祸所伏，祸兮福所倚。即西方的经济周期的想法。 在别人恐惧时我贪婪，在别人贪婪时我恐惧。 – 沃伦.巴菲特]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>programmer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arm arm part B]]></title>
    <url>%2F2019%2F05%2F30%2Farm_arm_part_B%2F</url>
    <content type="text"><![CDATA[Reference: &lt;&gt; (ARM DDI 0406C.c (ID051414)) Part B System Level ArchitectureB1 System Level Programmers’ ModelB1.1 About the System level programmers’ modelB1.2 System level concepts and terminologyB1.2.1 Mode, state, and privilege levelModeThe ARM architecture A and R profiles provide a set of modes that support normal software execution and handleexceptions. The current mode determines:• the set of registers that are available to the processor• the privilege level of the executing software State Instruction set state one of ARM state, Thumb state, Jazelle state, or ThumbEE state. Execution state consists of the instruction set state and some control bits that modify how theinstruction stream is decoded. For details, see Execution state registers on page A2-50 and ProgramStatus Registers (PSRs) on page B1-1147. Security state Debug state Privilege levelSecure statePL0 Software executed in User mode executes at PL0.PL1 Software executed in any mode other than User mode executes at PL1. Non-secure statePL0 Software executed in User mode executes at PL0.PL1 Software executed in any mode other than User or Hyp mode executes at PL1.PL2 In an implementation that includes the Virtualization Extensions, software executed inHyp mode executes at PL2. B1.3 ARM processor modes and ARM core registersB1.3.1 ARM processor modesFixme [Table B1-1 ARM processor modes] page1139 System modeSoftware executing in System mode executes at PL1. System mode has the same registers availableas User mode, and is not entered by any exception. Supervisor modeSupervisor mode is the default mode to which a Supervisor Call exception is taken.Executing a SVC (Supervisor Call) instruction generates an Supervisor Call exception, that is takento Supervisor mode.A processor enters Supervisor mode on Reset Hyp modeHyp mode is the Non-secure PL2 mode, implemented as part of the Virtualization Extensions.The Hypervisor Call exception and Hyp Trap exception are exceptions that are implemented as partof the Virtualization Extensions, and that are always taken in Hyp mode.• In Hyp mode, the only exception return is execution of an ERET instruction, see ERET on page B9-1982• The instructions described in the following sections are UNDEFINED if executed in Hyp mode: — SRS (Thumb) on page B9-2004 — SRS (ARM) on page B9-2006 — RFE on page B9-2000 — LDM (exception return) on page B9-1986 — LDM (User registers) on page B9-1988 — STM (User registers) on page B9-2008 — SUBS PC, LR and related instructions (ARM) on page B9-2012. — SUBS PC, LR (Thumb) on page B9-2010, when executed with a nonzero constant. • In Hyp mode, the CPACR has no effect on the execution of coprocessor, floating-point, or Advanced SIMDinstructions. The HCPTR controls execution of these instructions in Hyp mode. • If software running in Hyp mode executes an SVC instruction, the Supervisor Call exception generated by theinstruction is taken to Hyp mode, see SVC (previously SWI) on page A8-720. Monitor modeMonitor mode is the mode to which a Secure Monitor Call exception is taken.Monitor mode is a Secure mode, meaning it is always in the Secure state, regardless of the value ofthe SCR.NS bit. Monitor mode provides the normal method of changing between the Secure and Non-secure security states. Fixme [Figure B1-1 Modes, privilege levels, and security states] page1141 B1.3.2 ARM core registersFixme [Figure B1-2 ARM core registers, PSRs, and ELR_hyp, showing register banking] page1144 B1.3.3 Program Status Registers (PSRs)The Current Program Status Register (CPSR)The Current Program Status Register (CPSR) holds processor status and control information:• the APSR, see The Application Program Status Register (APSR) on page A2-49• the current instruction set state, see Instruction set state register, ISETSTATE on page A2-50• the execution state bits for the Thumb If-Then instruction, see IT block state register, ITSTATE on page A2-51• the current endianness, see Endianness mapping register, ENDIANSTATE on page A2-53• the current processor mode• interrupt and asynchronous abort disable bits. The Saved Program Status Registers (SPSRs)The purpose of an SPSR is to record the pre-exception value of the CPSR. Fixme [Format of the CPSR and SPSRs] Page1148 B1.3.4 ELR_hypHyp mode does not provide its own Banked copy of LR. Instead, on taking an exception to Hyp mode, the preferredreturn address is stored in ELR_hyp, a 32-bit Special register implemented for this purpose.ELR_hyp is implemented only as part of the Virtualization Extensions. The ERET instruction uses the value in ELR_hyp as the return address for the exception. For more information, seeERET on page B9-1982. B1.4 Instruction set statesIf an exception is taken to a PL1 mode, the SCTLR.TE bit for the security state the exception is taken to determinesthe processor instruction set state that handles the exception, and if necessary, the processor changes to thisinstruction set state on exception entry. If the exception is taken to Hyp mode, the HSCTLR.TE bit determines the processor instruction set state thathandles the exception, and if necessary, the processor changes to this instruction set state on exception entry. B1.5 The Security ExtensionsB1.5.1 Security statesThe Security Extensions define two security states, Secure state and Non-secure state.• Each security state operates in its own virtual memory address space, with its own translation regime.— in any implementation that includes the Security Extensions, Monitor mode is available only in Securestate— in an implementation that also includes the Virtualization Extensions, Hyp mode is available only inNon-secure state. The ARM core registers and the processor status registers are not Banked between the Secure and the Non-securestates. ARM expects that, when switching execution between the Non-secure and Secure states, a kernel runningmostly in Monitor mode will switch the values of these registers.The registers LR_mon and SPSR_mon are UNKNOWN when executing in Non-secure state. Changing from Secure to Non-secure stateExcept in Monitor mode and Hyp mode, the security state is controlled by the SCR.NS bit. Software executing in a Secure PL1 mode can change the SCR, but ARM strongly recommends that software obeys the following rules for changing SCR.NS:• To avoid security holes, software must not: — Change from Secure to Non-secure state by using an MSR or CPS instruction to switch from Monitor mode to some other mode while SCR.NS is 1. — Use an MCR instruction that writes SCR.NS to change from Secure to Non-secure state. This means ARM recommends that software does not alter SCR.NS in any mode except Monitor mode. ARM deprecates changing SCR.NS in any other mode. • The usual mechanism for changing from Secure to Non-secure state is an exception return.To return toNon-secure state, software executing in Monitor mode sets SCR.NS to 1 and then performs the exceptionreturn. B1.6 The Large Physical Address ExtensionThe Large Physical Address Extension is an OPTIONAL extension to the ARMv7-A architecture profile. Anyimplementation that includes the Large Physical Address Extension must also include the MultiprocessingExtensions. The Large Physical Address Extension adds a new translation table format:• the format used in an implementation that does not include the Large Physical Address Extension is nowcalled the Short-descriptor format, see Short-descriptor translation table format on page B3-1324• the format added by the Large Physical Address Extension is the Long-descriptor format, seeLong-descriptor translation table format on page B3-1338. An implementation that includes the Large Physical Address Extension must support both translation table formats. B1.7 The Virtualization ExtensionsThe Virtualization Extensions are an OPTIONAL extension to the ARMv7-A architecture profile. Anyimplementation that includes the Virtualization Extensions must include the Security Extensions, the Large PhysicalAddress Extension, and the Multiprocessing Extensions. The basic model of a virtualized system involves:• a hypervisor, running in Non-secure Hyp mode, that is responsible for switching Guest operating systems• a number of Guest operating systems, each of which runs in the Non-secure PL1 and PL0 modes• for each Guest operating system, applications, that usually run in User mode. Each virtual machine is identified by a virtual machine identifier (VMID), assigned by the hypervisor.• With the Security Extensions, the Virtualization Extensions control the routing of interrupts andasynchronous Data Abort exceptions to the appropriate one of:— the current Guest OS— a Guest OS that is not currently running— the hypervisor— the Secure monitor. • When an implementation includes the Virtualization Extensions, it provides independent translation regimesfor memory accesses from: — Secure modes, the Secure PL1&amp;0 translation regime — Non-secure Hyp mode, the Non-secure PL2 translation regime — Non-secure PL1 and PL0 modes, the Non-secure PL1&amp;0 translation regime • In the Non-secure PL1&amp;0 translation regime, address translation occurs in two stages:— Stage 1 maps the Virtual Address (VA) to an Intermediate Physical Address (IPA). Typically, the GuestOS configures and controls this stage, and believes that the IPA is the Physical Address (PA)— Stage 2 maps the IPA to the PA. Typically, the hypervisor controls this stage, and a Guest OS iscompletely unaware of this translation. B1.7.1 Impact of the Virtualization Extensions on the modes and exception model• Implements new exceptions, see: — Hypervisor Call (HVC) exception on page B1-1212 — Hyp Trap exception on page B1-1209 — Virtual IRQ exception on page B1-1221 — Virtual FIQ exception on page B1-1223 — Virtual Abort exception on page B1-1218. • Implements a new register that holds the exception vector base address for exceptions taken to Hyp mode,the HVBAR. • Implements a new exception return instruction, ERET, for return from Hyp mode • Provide mechanisms to trap processor functions to Hyp mode, using the Hyp Trap exception, see Traps tothe hypervisor on page B1-1248.When an operation is trapped to Hyp mode, the hypervisor typically either: — emulates the required operation, so the application running in the Guest OS is unaware of the trap to Hyp mode — returns an error to the Guest OS. B1.8 Exception handlingB1.8.1 Exception vectors and the exception base addressWhen an exception is taken, processor execution is forced to an address that corresponds to the type of exception.This address is called the exception vector for that exception. A set of exception vectors comprises eight consecutive word-aligned memory addresses, starting at an exceptionbase address. These eight vectors form a vector table. For the IRQ and FIQ exceptions only, when the exceptionsare taken to IRQ mode and FIQ mode, software can change the exception vectors from the vector table values bysetting the SCTLR.VE bit to 1, see Vectored interrupt support on page B1-1168. Implementation that does not include the Security Extensions (1 pair interrupt vectors)This section applied to all ARMv7-R implementations.An implementation that does not include the Security Extensions has a single vector table, the baseaddress of which is selected by SCTLR.V, see SCTLR, System Control Register, VMSA onpage B4-1707 or SCTLR, System Control Register, PMSA on page B6-1932: V == 0 Exception base address = 0x00000000. This setting is referred to as normal vectors, or as low vectors. V == 1 Exception base address = 0xFFFF0000. This setting is referred to as high vectors, or Hivecs. Implementation that includes the Security Extensions (3 pair interrupt vectors)Any implementation that includes the Security Extensions has the following vector tables:• One for exceptions taken to Secure Monitor mode. This is the Monitor vector table, and is inthe address space of the Secure PL1&amp;0 translation regime.• One for exceptions taken to Secure PL1 modes other than Monitor mode. This is the Securevector table, and is in the address space of the Secure PL1&amp;0 translation regime.• One for exceptions taken to Non-secure PL1 modes. This is the Non-secure vector table, andis in the address space of the Non-secure PL1&amp;0 translation regime. For the Monitor vector table, MVBAR holds the exception base address. For the Secure vector table:• the Secure SCTLR.V bit determines the exception base address: V == 0 The Secure VBAR holds the exception base address. V == 1 Exception base address = 0xFFFF0000, the Hivecs setting. For the Non-secure vector table:• the Non-secure SCTLR.V bit determines the exception base address: V == 0 The Non-secure VBAR holds the exception base address. V == 1 Exception base address = 0xFFFF0000, the Hivecs setting. Implementation that includes the Virtualization Extensions (4 pair interrupt vectors)An implementation that includes the Virtualization Extensions must include the SecurityExtensions, and also includes an additional vector table. Therefore, it has the following vectortables:• One for exceptions taken to Secure Monitor mode. This is the Monitor vector table, and is inthe address space of the Secure PL1&amp;0 translation regime.• One for exceptions taken to Secure PL1 modes other than Monitor mode. This is the Securevector table, and is in the address space of the Secure PL1&amp;0 translation regime.• One for exceptions taken to Hyp mode, the Non-secure PL2 mode. This is the Hyp vectortable, and is in the address space of the Non-secure PL2 translation regime.• One for exceptions taken to Non-secure PL1 modes. This is the Non-secure vector table, andis in the address space of the Non-secure PL1&amp;0 translation regime. The exception base addresses of the Monitor vector table, the Secure vector table, and theNon-secure vector table are determined in the same way as for an implementation that includes theSecurity extensions but not the Virtualization extensions. For the Hyp vector table, HVBAR holds the exception base address. The vector tables and exception offsetsFixme [Table B1-3 The vector tables] page1167 B1.8.4 Processor mode for taking exceptionsExceptions taken to Hyp mode• Any exception taken from Hyp mode, that is not routed to Secure Monitor Mode by the controls describedin Asynchronous exception routing controls on page B1-1175, is taken to Hyp mode. • The following exceptions, if taken from Non-secure state, are taken to Hyp mode: — An abort that Routing of aborts on page B3-1396 identifies as taken to Hyp mode. — A Hyp Trap exception, see Traps to the hypervisor on page B1-1248. — A Hypervisor Call exception. This is generated by executing a HVC instruction in a Non-secure mode. — An asynchronous abort, IRQ exception or FIQ exception that is not routed to Secure Monitor mode but is explicitly routed to Hyp mode, as described in Asynchronous exception routing controls on page B1-1175. — A synchronous external abort, Alignment fault, Undefined Instruction exception, or Supervisor Call exception taken from the Non-secure PL0 mode and explicitly routed to Hyp mode, as described in Routing general exceptions to Hyp mode on page B1-1192. Note A synchronous external abort can be routed to Hyp mode only if it not routed to Secure Monitor mode. — A debug exception that is explicitly routed to Hyp mode as described in Routing Debug exceptions to Hyp mode on page B1-1194. Asynchronous exception routing controlsIn an implementation that includes the Security Extensions, the following bits in the SCR control the routing ofasynchronous exceptions:SCR.EA When this bit is set to 1, any external abort is taken to Secure Monitor modeSCR.FIQ When this bit is set to 1, any FIQ exception is taken to Secure Monitor mode.SCR.IRQ When this bit is set to 1, any IRQ exception is taken to Secure Monitor mode.Only Secure software can change the values of these bits. In an implementation that includes the Virtualization Extensions, the following bits in the HCR route asynchronousexceptions to Hyp mode:HCR.AMO If SCR.EA is set to 0, when this bit is set to 1, an asynchronous external abort taken from a Non-secure PL1 or PL0 mode is taken to Hyp mode, instead of to Non-secure Abort mode. HCR.FMO If SCR.FIQ is set to 0, when this bit is set to 1, an FIQ exception taken from a Non-secure PL1 or PL0 mode is taken to Hyp mode, instead of to Non-secure FIQ mode. HCR.IMO If SCR.IRQ is set to 0, when this bit is set to 1, an IRQ exceptions taken from a Non-secure PL1 or PL0 mode is taken to Hyp mode, instead of to Non-secure IRQ mode. Only software executing in Hyp mode, or Secure software executing in Monitor mode when SCR.NS is set to 1, can change the values of these bits. B1.8.5 Processor state on exception entryInstruction set state on exception entryOn exception entry, CPSR.{T, J} are set to the values shown, with the CPSR.T value determined by SCTLR.TE or HSCTLR.TE Fixme [Table B1-8 CPSR.J and CPSR.T bit values on exception entry] page1182 CPSR.E bit value on exception entrFixme [Table B1-9 CPSR.E bit value on exception entry] page1182 B1.8.6 Asynchronous exception maskingThe CPSR.{A, I, F} bits can mask the corresponding exceptions, as follows:• CPSR.A can mask asynchronous aborts• CPSR.I can mask IRQ exceptions• CPSR.F can mask FIQ exceptions. In an ARMv7 implementation that does not include the Security Extensions, setting one of these bits to 1 masks thecorresponding exception, meaning the exception cannot be taken. In an implementation that includes the Security Extensions, the SCR.{AW, FW} bits provide a mechanism toprevent use of the CPSR.{A, F} mask bits by Non-secure software. In an implementation that includes theVirtualization Extensions:• HCR.{AMO, FMO} modify this mechanism• HCR.IMO can prevent the masking, by CPSR.I, of IRQs taken from Non-secure state. When an SCR.{AW, FW} bit is set to 0, Non-secure software cannot update the correspondingCPSR bit. Fixme [Table B1-11 Control of masking by CPSR.A] page1185 Fixme [Table B1-12 Control of masking by CPSR.I] page1185 Fixme [Table B1-13 Control of masking by CPSR.F] page1185 B1.8.7 Summaries of asynchronous exception behaviorAsynchronous exception behavior, Security Extensions onlyFixme [Table B1-14 Behavior of asynchronous aborts, Virtualization Extensions not implemented] page1187 Fixme [Table B1-15 Behavior of IRQ exceptions, Virtualization Extensions not implemented] page1188 Fixme [Table B1-16 Behavior of FIQ exceptions, Virtualization Extensions not implemented] page1188 Asynchronous exception behavior, with the Virtualization ExtensionsFixme [Table B1-17 Behavior of asynchronous aborts, Virtualization Extensions implemented] page1189 Fixme [Table B1-18 Behavior of IRQ exceptions, Virtualization Extensions implemented] page1190 Fixme [Table B1-19 Behavior of FIQ exceptions, Virtualization Extensions implemented] page1191 B1.8.8 Routing general exceptions to Hyp modeWhen HCR.TGE is set to 1, and the processor is in Non-secure User mode, the following exceptions are taken toHyp mode, instead of to the default Non-secure mode for handling the exception:• Undefined Instruction exceptions.• Supervisor Call exceptions.• Synchronous External aborts.• Any Alignment fault other than an alignment fault caused by the memory type when SCTLR.M is 1. B1.8.9 Routing Debug exceptions to Hyp modeWhen HDCR.TDE is set to 1, if the processor is executing in a Non-secure mode other than Hyp mode, any Debugexception is routed to Hyp mode. This means it generates a Hyp Trap exception B1.8.10 Exception returnOn an exception return, the CPSR takes either:• the value loaded by the RFE instruction• if the exception return is not performed by executing an RFE instruction, the value of the current SPSR at thetime of the exception return Return from an exception taken to a PL1 modeFor an exception taken to a PL1 mode, the ARM architecture provides the following exception return instructions:• Data-processing instructions with the S bit set and the PC as a destination, see SUBS PC, LR (Thumb) onpage B9-2010 and SUBS PC, LR and related instructions (ARM) on page B9-2012.Typically: — a return where no subtraction is required uses SUBS with an operand of 0, or the equivalent MOVS instruction — a return requiring subtraction uses SUBS with a nonzero operand. • From ARMv6, the RFE instruction, see RFE on page B9-2000. If a subtraction is required, typically it isperformed before saving the LR value to memory. • In ARM state, a form of the LDM instruction, see LDM (exception return) on page B9-1986. If a subtraction isrequired, typically it is performed before saving the LR value to memory. Return from an exception taken to a PL2 modeFor an exception taken to a PL2 mode, the ARM architecture provides the ERET instruction, see ERET onpage B9-1982. An exception handler executing in a PL2 mode must return using the ERET instruction.Hyp mode is the only PL2 mode. Both Hyp mode and the ERET instruction are implemented only as part of theVirtualization Extensions. B1.8.11 Virtual exceptions in the Virtualization ExtensionsFixme [Table B1-20 HCR bits controlling asynchronous exceptions] page1198 B1.8.12 Low interrupt latency configurationSetting SCTLR.FI to 1 enables the low interrupt latency configuration of an implementation. This configuration canreduce the interrupt latency of the processor. The mechanisms implemented to achieve low interrupt latency areIMPLEMENTATION DEFINED. For the description of the SCTLR see either:• SCTLR, System Control Register, VMSA on page B4-1707• SCTLR, System Control Register, PMSA on page B6-1932 B1.8.13 Wait For Event and Send EventARMv7 and ARMv6K provide a mechanism, the Wait For Event mechanism, that permits a processor in amultiprocessor system to request entry to a low-power state, and, if the request succeeds, to remain in that state untilit receives an event generated by a Send Event operation on another processor in the system.example using for spin-lock The Virtualization Extensions provide a bit that traps to Hyp mode any attempt to enter a low-power state from aNon-secure PL1 or PL0 mode. WFE wake-up eventsThe following events are WFE wake-up events:• the execution of an SEV instruction on any processor in the multiprocessor system• a physical IRQ interrupt, unless masked by the CPSR.I bit• a physical FIQ interrupt, unless masked by the CPSR.F bit• a physical asynchronous abort, unless masked by the CPSR.A bit• in Non-secure state in any mode other than Hyp mode: — when HCR.IMO is set to 1, a virtual IRQ interrupt, unless masked by the CPSR.I bit — when HCR.FMO is set to 1, a virtual FIQ interrupt, unless masked by the CPSR.F bit — when HCR.AMO is set to 1, a virtual asynchronous abort, unless masked by the CPSR.A bit• an asynchronous debug event, if invasive debug is enabled and the debug event is permitted• an event sent by the timer event stream, see Event streams on page B8-1964• an event sent by some IMPLEMENTATION DEFINED mechanism. The Event RegisterThe Event Register is a single bit register for each processor. When set, an event register indicates that an event hasoccurred, since the register was last cleared The Event Register is set by:• an SEV instruction• an event sent by some IMPLEMENTATION DEFINED mechanism• a debug event that causes entry into Debug state• an exception return. The Send Event instructionThe Send Event instruction, SEV, causes an event to be signaled to all processors in the multiprocessor system.ARM recommends that software includes a DSB instruction before an SEV instruction Execution of the Send Event instruction sets the Event Register. The Send Event instruction is available at all privilege levels The Wait For Event instructionThe action of the Wait For Event instruction depends on the state of the Event Register:• If the Event Register is set, the instruction clears the register and completes immediately. Normally, if thishappens the software makes another attempt to claim the lock. • If the Event Register is clear the processor can suspend execution and enter a low-power state. It can remainin that state until the processor detects a WFE wake-up event or a reset. When the processor detects a WFEwake-up event, or earlier if the implementation chooses, the WFE instruction completes. The Wait For Event instruction, WFE, is available at all privilege levels, B1.8.14 Wait For InterruptWhen a processor issues a WFI instruction it can suspend execution and enter a low-power state. The Virtualization Extensions provide a bit that traps to Hyp mode any attempt to enter a low-power state from aNon-secure PL1 or PL0 mode. The processor can remain in the WFI low-power state until it is reset, or it detects one of the following WFI wake-upevents:• a physical IRQ interrupt, regardless of the value of the CPSR.I bit• a physical FIQ interrupt, regardless of the value of the CPSR.F bit• a physical asynchronous abort, regardless of the value of the CPSR.A bit• in Non-secure state in any mode other than Hyp mode: — when HCR.IMO is set to 1, a virtual IRQ interrupt, regardless of the value of the CPSR.I bit — when HCR.FMO is set to 1, a virtual FIQ interrupt, regardless of the value of the CPSR.F bit — when HCR.AMO is set to 1, a virtual asynchronous abort, regardless of the value of the CPSR.A bit• an asynchronous debug event, when invasive debug is enabled and the debug event is permitted. WFI wake-up events cannot be masked by the mask bits in the CPSR. Using WFI to indicate an idle state on bus interfaces Linux cpuidle framework(1)_概述和软件架构 B1.9 Exception descriptionsskip B1.10 Coprocessors and system controlThe ARM architecture supports sixteen coprocessors, usually referred to as CP0 to CP15.The architecture reserves two of these coprocessors, CP14 and CP15,for configuration and control related to the architecture:• CP14 is reserved for the configuration and control of: — debug features, see The CP14 debug register interface on page C6-2123 — trace features, see the Embedded Trace Macrocell Architecture Specification and the CoreSight Program Flow Trace Architecture Specification — the Thumb Execution Environment, see Thumb Execution Environment on page B1-1240 — direct Java bytecode execution, see Jazelle direct bytecode execution on page B1-1241.• CP15 is called the System Control coprocessor, and is reserved for the control and configuration of the ARMprocessor system, including architecture and feature identification. The implementation of the CP15 registers depends heavily on whether the ARMv7 implementation is:• an ARMv7-A implementation with a Virtual Memory System Architecture (VMSA)• an ARMv7-R implementation with a Protected Memory System Architecture (PMSA).The implementation of the CP14 registers is generally similar in ARMv7-A and ARMv7-R implementation. Most CP14 and CP15 registers are accessible only from PL1 or higher. For possible accesses from PL0:• The register descriptions in Chapter B4 System Control Registers in a VMSA implementation and Chapter B6System Control Registers in a PMSA implementation indicate whether a register is accessible from PL0.• The descriptions of the CP14 interface in Chapter C6 Debug Register Interfaces include the permittedaccesses to the debug registers from PL0.• The following sections summarize the permitted accesses to CP15 registers from PL0: — for a VMSA implementation, PL0 views of the CP15 registers on page B3-1488 — for a PMSA implementation, PL0 views of the CP15 registers on page B5-1797. B1.11 Advanced SIMD and floating-point supportskip B1.12 Thumb Execution Environmentskip B1.13 Jazelle direct bytecode executionskip B1.14 Traps to the hypervisorB1.14.1 General information about traps to the hypervisorThe Hyp Trap exception provides the standard mechanism for trapping Guest OS functions to the hypervisor.and enters the exception handler using the vector atoffset 0x14 from the Hyp vector base address. For more information see Exception handling on page B1-1165 A Hyp Trap exception can be generated only when all of the following apply:• The processor is both: — not in Debug state — in a Non-secure PL1 or PL0 mode.• Traps to Hyp mode never apply in Secure state, regardless of the value of the SCR.NS bit. B1.14.2 Trapping ID mechanismsFor a small number of frequently-accessed ID registers, the Virtualization Extensions provide read/write aliases ofthe registers, accessible only from Hyp mode, or from Secure state. A read of the original ID register from aNon-secure PL1 mode actually returns the value of the read/write alias register. Fixme [Table B1-26 ID register substitution by the Virtualization Extensions] page1251 Fixme [Table B1-27 ID register groups for Hyp Trap exceptions] page1252 B1.14.17 Summary of trap controls Fixme [Table B1-29 Summary of Hyp trap controls] page1262 B2 Common Memory System Architecture FeaturesB2.2 Caches and branch predictorsB2.2.1 Cache identificationThe ARMv7 cache identification consists of a set of registers that describe the implemented caches that are underthe control of the processor:• A single Cache Type Register defines: — the minimum line length of any of the instruction caches — the minimum line length of any of the data or unified caches — the cache indexing and tagging policy of the Level 1 instruction cache. For more information, see: — CTR, Cache Type Register, VMSA on page B4-1556, for a VMSA implementation — CTR, Cache Type Register, PMSA on page B6-1835, for a PMSA implementation. • A single Cache Level ID Register defines: — the type of cache implemented at a each cache level, up to the maximum of seven levels — the Level of Coherence (LoC) for the caches — the Level of Unification (LoU) for the caches. For more information, see: — CLIDR, Cache Level ID Register, VMSA on page B4-1530, for a VMSA implementation — CLIDR, Cache Level ID Register, PMSA on page B6-1816, for a PMSA implementation • A single Cache Size Selection Register selects the cache level and cache type of the current Cache SizeIdentification Register, see: — CSSELR, Cache Size Selection Register, VMSA on page B4-1555, for a VMSA implementation — CSSELR, Cache Size Selection Register, PMSA on page B6-1834, for a PMSA implementation. • For each implemented cache, across all the levels of caching, a Cache Size Identification Register defines: — whether the cache supports Write-Through, Write-Back, Read-Allocate and Write-Allocate — the number of sets, associativity and line length of the cache For more information, see: — CCSIDR, Cache Size ID Registers, VMSA on page B4-1528, for a VMSA implementation — CCSIDR, Cache Size ID Registers, PMSA on page B6-1814, for a PMSA implementation. Identifying the cache resources in ARMv7In ARMv7 the architecture defines support for multiple levels of cache, up to a maximum of seven levels.software must: Read the Cache Type Register to find the indexing and tagging policy used for the Level 1 instruction cache.This register also provides the size of the smallest cache lines used for the instruction caches, and for the dataand unified caches. These values are used in cache maintenance operations. Read the Cache Level ID Register to find what caches are implemented. The register includes seven Cachetype fields, for cache levels 1 to 7. Scanning these fields, starting from Level 1, identifies the instruction, dataor unified caches implemented at each level. This scan ends when it reaches a level at which no caches aredefined. The Cache Level ID Register also provides the Level of Unification (LoU) and the Level ofCoherence (LoC) for the cache implementation. For each cache identified at stage 2:• Write to the Cache Size Selection Register to select the required cache. A cache is identified by itslevel, and whether it is: — an instruction cache — a data or unified cache.• Read the Cache Size ID Register to find details of the cache. B2.2.2 Cache behaviorGeneral behavior of the cachesWhen a memory location is marked with a Normal Cacheable memory attribute, determining whether a copy of thememory location is held in a cache still depends on many aspects of the implementation. The followingnon-exhaustive list of factors might be involved:• the size, line length, and associativity of the cache• the cache allocation algorithm• activity by other elements of the system that can access the memory• speculative instruction fetching algorithms• speculative data fetching algorithms• interrupt behaviors. For the purpose of these principles, a cache entry covers at least 16 bytes and no more than 2KB of contiguousaddress space, aligned to its size. Behavior of the caches at resetIn ARMv7:• All caches are disabled at reset.• An implementation can require the use of a specific cache initialization routine to invalidate its storage arraybefore it is enabled. B2.2.3 Cache enabling and disablingLevels of cache on page B2-1265 indicates that:• In ARMv7 the architecture defines the control of multiple levels of cache.• Before ARMv7 the architecture defines the control of only one level of cache. In ARMv7:• SCTLR.C enables or disables all data and unified caches for data accesses, across all levels of cache visibleto the processor. It is IMPLEMENTATION DEFINED whether it also enables or disables the use of unified cachesfor instruction accesses.• SCTLR.I enables or disables all instruction caches, across all levels of cache visible to the processor. - SCTLR, System Control Register, VMSA on page B4-1707, for a VMSA implementation - SCTLR, System Control Register, PMSA on page B6-1932, for a PMSA implementation. B2.2.4 Branch predictorsBranch predictor hardware typically uses a form of cache to hold branch information. The ARM architecturepermits this branch predictor hardware to be visible to software, and so the branch predictor is not architecturallyinvisible. This means that under some circumstances software must perform branch predictor maintenance to avoidincorrect execution caused by out-of-date entries in the branch predictor. Requirements for branch predictor maintenance operationsthe instructions at the virtual addresses change:• enabling or disabling the MMU• writing new mappings to the translation tables• any change to the TTBR0, TTBR1, or TTBCR registers, unless accompanied by a change to the ContextID,or a change to the VMID• changes to the VTTBR or VTCR registers, unless accompanied by a change to the VMID. then branch predictor maintenance operations must be performed to invalidate entries in the branchpredictor, to ensure that the change is visible to subsequent execution. B2.2.6 About ARMv7 cache and branch predictor maintenance functionalityTerms used in describing the maintenance operations• by the address of the memory location to be maintained, referred to as operating by MVA• by a mechanism that describes the location in the hardware of the cache, referred to as operating by set/way. Terminology for operations by MVAThe term Modified Virtual Address (MVA) relates to the Fast Context Switch Extension (FCSE) mechanism,described in Appendix D10 Fast Context Switch Extension (FCSE). When the FCSE is absent or disabled, the MVA and VA have the same value. Virtual addresses only exist in systems with a MMU. When no MMU is implemented, or all applicable MMUs are disabled, the MVA and VA are identical to the PA. Terminology for operations by set/wayCache maintenance operations by set/way refer to the particular structures in a cache. LevelThe cache level of the hierarchy. SetEach level of a cache is split up into a number of sets. Each set is a set of locations in a cache level to which an address can be assigned. WayThe Associativity of a cache defines the number of locations in a set to which an address can be assigned. B2.2.7 Cache and branch predictor maintenance operationsCache and branch predictor maintenance operations are performed using accesses to CP15 c7. The followingsections define the encodings for these operations:• Cache and branch predictor maintenance operations, VMSA on page B4-1743, for a VMSA implementation• Cache and branch predictor maintenance operations, PMSA on page B6-1943, for a PMSA implementation. Summary of cache and branch predictor maintenance operationsData cache and unified cache operationsOperations by MVAThe data and unified cache operations by MVA are:DCIMVAC Invalidate, to point of coherency.DCCMVAC Clean, to point of coherency.DCCMVAU Clean, to point of unification.DCCIMVAC Clean and invalidate, to point of coherency. Operations by set/wayThe data and unified cache operations by set/way are:DCISW Invalidate.DCCSW Clean.DCCISW Clean and invalidate, to point of coherency. Instruction cache operationsOperation by MVAICIMVAU Invalidate, to point of unification. Operations on all entriesThe instruction cache operations that operate on all entries are:ICIALLU Invalidate all, to point of unification.ICIALLUIS Invalidate all, to point of unification, Inner Shareable. Branch predictor operationsOperation by MVABPIMVA Invalidate. Operations on all entriesBPIALL Invalidate all.BPIALLIS Invalidate all, Inner Shareable. B3 Virtual Memory System Architecture (VMSA)B3.1 About the VMSAIn VMSAv7, a Memory Management Unit (MMU) controls address translation, access permissions, and memoryattribute determination and checking. Each supported stage of memory system control is provided by an MMU, with its own independent set of controls.Therefore, the Extended VMSAv7 provides the following MMUs:• Secure PL1&amp;0 stage 1 MMU• Non-secure PL2 stage 1 MMU• Non-secure PL1&amp;0 stage 1 MMU• Non-secure PL1&amp;0 stage 2 MMU. Fixme [Figure B3-1 VMSA translation regimes, and associated MMUs]page1309 B3.1.1 Address types used in a VMSA descriptionVirtual Address (VA)An address used in an instruction, as a data or instruction address, is a Virtual Address (VA).An address held in the PC, LR, or SP, is a VA. Modified Virtual Address (MVA)On an implementation that implements and uses the FCSE(Appendix D10 Fast Context Switch Extension (FCSE)), the FCSE takes a VA and transforms it to an MVA. Intermediate Physical Address (IPA)In a translation regime that provides two stages of address translation, the IPA is the address afterthe stage 1 translation, and is the input address for the stage 2 translation. Physical Address (PA)B3.1.2 Address spaces in a VMSA implementationThe ARMv7 architecture supports:• A VA address space of up to 32 bits. The actual width is IMPLEMENTATION DEFINED.• An IPA address space of up to 40 bits. The translation tables and associated system control registers define the width of the implemented address space. Note: The Large Physical Address Extension defines two translation table formats. The Long-descriptor format gives access to the full 40-bit IPA or PA address space at a granularity of 4KB. The Short-descriptor format:• Gives access to a 32-bit PA address space at 4KB granularity.• Optionally, gives access to a 40-bit PA address space, but only at 16MB granularity. If an implementation includes the Security Extensions, the address maps are defined independently for Secure and Non-secure operation, providing two independent 40-bit address spaces, where:• a VA accessed from Non-secure state can only be translated to the Non-secure address map• a VA accessed from Secure state can be translated to either the Secure or the Non-secure address map. B3.1.3 About address translationB3.1.3.1. VMSAv7 without the Security ExtensionsSupports only a single PL1&amp;0 stage 1 MMU. Operation of this MMU can be split between two sets of translation tables, defined by TTBR0 and TTBR1, and controlled by TTBCR. B3.1.3.2. VMSAv7 with the Security Extensions but without the Virtualization ExtensionsSupports only the Secure PL1&amp;0 stage 1 MMU and the Non-secure PL1&amp;0 stage 1 MMU. Operation of each of these MMUs can be split between two sets of translation tables, defined by the Secure and Non-secure copies of TTBR0 and TTBR1, and controlled by the Secure and Non-secure copies of TTBCR. Note: Secure and Non-secure has copies of TTBR0 and TTBR1, TTBCR. B3.1.3.3. VMSAv7 with Virtualization ExtensionsSecure PL1&amp;0 stage 1 MMUOperation of this MMU can be split between two sets of translation tables, defined by the Secure copies of TTBR0 and TTBR1, and controlled by the Secure copy of TTBCR. Non-secure PL2 stage 1 MMUThe HTTBR defines the translation table for this MMU, controlled by HTCR. Non-secure PL1&amp;0 stage 1 MMUOperation of this MMU can be split between two sets of translation tables, defined by the Non-secure copies of TTBR0 and TTBR1 and controlled by the Non-secure copy of TTBCR. Non-secure PL1&amp;0 stage 2 controlThe VTTBR defines the translation table for this MMU, controlled by VTCR. Fixme [Figure B3-2 Memory translation summary, with Virtualization Extensions]Page 1312 A full translation table lookup is called a translation table walk.It is performed automatically by hardware. Translation Lookaside Buffers (TLBs) reduce the average cost of a memory access by caching the results of translation table walks. To reduce the software overhead of TLB maintenance, the VMSA distinguishes between Global pages and Process-specific pages. The Address Space Identifier (ASID) identifies pages associated with a specific process and provides a mechanism for changing process-specific tables without having to maintain the TLB tructures. If an implementation includes the Virtualization Extensions, the virtual machine identifier (VMID) identifies the current virtual machine, with its own independent ASID space. B3.2 The effects of disabling MMUs on VMSA behaviorAbout the VMSA on page B3-1308 defines the translation regimes and the associated MMUs. The VMSA includesan enable bit for each MMU, as follows:• SCTLR.M, in the Secure copy of the register, controls Secure PL1&amp;0 stage 1 MMU• SCTLR.M, in the Non-secure copy of the register, controls Non-secure PL1&amp;0 stage 1 MMU• HCR.VM controls Non-secure PL1&amp;0 stage 2 MMU• HSCTLR.M controls Non-secure PL2 stage 1 MMU. B3.2.1 VMSA behavior when a stage 1 MMU is disabledNon-secure PL1 and PL0 accesses when HCR.DC is set to 1, Virtualization ExtensionsIn an implementation that includes the Virtualization Extensions, for an access from a Non-secure PL1 or PL0 mode when HCR.DC is set to 1, the stage 1 translation assigns the Normal Non-shareable, Inner Write-Back Write-Allocate, Outer Write-Back Write-Allocate memory attributes. All other accessesData accessThe stage 1 translation assigns the Strongly-Ordered memory type. NoteThis means the access is Non-cacheable. Unexpected data cache hit behavior is IMPLEMENTATION DEFINED. Instruction accessThe stage 1 translation assigns Normal memory attribute, with the cacheability andshareability attributes determined by the value of:• the Secure copy of SCTLR.I for the Secure PL1&amp;0 translation regime• the Non-secure copy of SCTLR.I for the Non-secure PL1&amp;0 translation regime• HSCTLR.I for the Non-secure PL2 translation regime. B3.2.2 VMSA behavior when the stage 2 MMU is disabledWhen the stage 2 MMU is disabled:• the IPA output from the stage 1 translation maps flat to the PA• the memory attributes and permissions from the stage 1 translation apply to the PA. If the stage 1 MMU and the stage 2 MMU are both disabled, see Behavior of instruction fetches when all associatedMMUs are disabled. B3.3 Translation tablesVMSAv7 defines two alternative translation table formats: Short-descriptor formatThis is the original format defined in issue A of this Architecture Reference Manual, and is the only format supported on implementations that do not include the Large Physical Address Extension. It uses 32-bit descriptor entries in the translation tables, and provides:• Up to two levels of address lookup.• 32-bit input addresses.• Output addresses of up to 40 bits.• Support for PAs of more than 32 bits by use of supersections, with 16MB granularity.• Support for No access, Client, and Manager domains.• 32-bit table entries. Long-descriptor formatThe Large Physical Address Extension adds support for this format. It uses 64-bit descriptor entries in the translation tables, and provides:• Up to three levels of address lookup.• Input addresses of up to 40 bits, when used for stage 2 translations.• Output addresses of up to 40 bits.• 4KB assignment granularity across the entire PA range.• No support for domains, all memory regions are treated as in a Client domain.• 64-bit table entries.• Fixed 4KB table size, unless truncated by the size of the input address space. The Large Physical Address Extension is an OPTIONAL extension, but an implementation that includes the Virtualization Extensions must also include the Large Physical Address Extension. B3.3.1 Translation table walksA translation table walk occurs as the result of a TLB miss, and starts with a read of the appropriate starting-leveltranslation table. The physical address of the base of the starting-level translation table is determined from the appropriate Translationtable base register (TTBR). B3.3.2 Information returned by a translation table lookupIf the required translation table descriptor is not held in a TLB, a translation table walk is performed to obtain the descriptor. A lookup, whether from the TLB or as the result of a translation table walk, returns both:• an output address that corresponds to the input address for the lookup• a set of properties that correspond to that output address. The returned properties are classified as providing address map control, access controls, or region attributes. B3.3.3 Determining the translation table base addressFixme[Figure B3-2 Memory translation summary, with Virtualization Extensions]page1312 B3.3.4 Security Extensions control of translation table walksWhen an implementation includes the Security Extensions, two bits in the TTBCR for the current security statecontrol whether a translation table walk is performed on a TLB miss. These two bits are the:• PD0 and PD1 bits, on a processor using the Short-descriptor translation table format• EPD0 and EPD1 bits, on a processor using the Long-descriptor translation table format. The effect of these bits is:{E}PDx == 0 If a TLB miss occurs based on TTBRx, a translation table walk is performed. The current securitystate determines whether the memory access is Secure or Non-secure.{E}PDx == 1 If a TLB miss occurs based on TTBRx, a First level Translation fault is returned, and no translationtable walk is performed. B3.3.5 Access to the Secure or Non-secure physical address mapAs stated in Address spaces in a VMSA implementation on page B3-1311, a processor that implements the SecurityExtensions implements independent Secure and Non-secure address maps. These are defined by the translationtables identified by the Secure TTBR0 and TTBR1. In both translation table formats:• In the Secure translation tables, the NS bit in a descriptor indicates whether the descriptor refers to the Secureor the Non-secure address map:NS == 0 Access the Secure physical address space.NS == 1 Access the Non-secure physical address space. B3.5 Short-descriptor translation table formatThe Short-descriptor translation table format supports a memory map based on memory sections or pages:SupersectionsConsist of 16MB blocks of memory. Support for Supersections is optional, except that animplementation that includes the Large Physical Address Extension and supports more that 32 bitsof Physical Address must also support Supersections to provide access to the entire PhysicalAddress space. SectionsConsist of 1MB blocks of memory. Large pagesConsist of 64KB blocks of memory. Small pagesConsist of 4KB blocks of memory. When using the Short-descriptor translation table format, two levels of translation tables are held in memory: First-level table Second-level tables In the translation tables, in general, a descriptor is one of:• an invalid or fault entry• a page table entry, that points to a next-level translation table• a page or section entry, that defines the memory properties for the access• a reserved format.Bits[1:0] of the descriptor give the primary indication of the descriptor type. Fixme[Figure B3-3 General view of address translation using Short-descriptor format translation tables] Page 1325 B3.5.1 Short-descriptor translation table format descriptorsShort-descriptor translation table first-level descriptor formatsFixme [Figure B3-4 Short-descriptor first-level descriptor formats] Page1326 Descriptor bits[1:0] identify the descriptor type. Short-descriptor translation table second-level descriptor formatsFixme [Figure B3-5 Short-descriptor second-level descriptor formats] Page1327 B3.5.2 Memory attributes in the Short-descriptor translation table format descriptorsTEX[2:0], C, BMemory region attribute bits, see Memory region attributes on page B3-1366.These bits are not present in a Page table entry XN bitThe Execute-never bit. Determines whether the processor can execute software from the addressedregion, see Execute-never restrictions on instruction fetching on page B3-1359.This bit is not present in a Page table entry. PXN bit, when supportedThe Privileged execute-never bit:• On an implementation that does not include the Large Physical Address Extension, supportfor the PXN bit in the Short-descriptor translation table format is OPTIONAL.• On an implementation that includes the Large Physical Address Extension, theShort-descriptor translation table format must include the PXN bit. NS bitNon-secure bit. If an implementation includes the Security Extensions, for memory accesses fromSecure state, this bit specifies whether the translated PA is in the Secure or Non-secure address map DomainDomain field, see Domains, Short-descriptor format only on page B3-1362.Page table descriptor applies to all entries in the corresponding second-level translation table. AP[2], AP[1:0]Access Permissions bits, see Memory access control on page B3-1356 S bitThe Shareable bit. nG bitThe not global bit. Determines how the translation is marked in the TLB, see Global andprocess-specific translation table entries on page B3-1378. B3.5.4 Selecting between TTBR0 and TTBR1, Short-descriptor translation table formatthe value of TTBCR.N indicates the number of most significant bits of the input VA that determine whether TTBR0 or TTBR1 :• If N == 0 then use TTBR0. Setting TTBCR.N to zero disables use of a second set of translation tables.• if N &gt; 0 then: — if bits[31:32-N] of the input VA are all zero then use TTBR0 — otherwise use TTBR1. Fixme [Table B3-1 Effect of TTBCR.N on address translation, Short-descriptor format] page1330Whenever TTBCR.N is nonzero, the size of the translation table addressed by TTBR1 is 16KB. Fixme [Figure B3-6 How TTBCR.N controls the boundary between the TTBRs, Short-descriptor format] page1331 B3.5.5 Translation table walks, when using the Short-descriptor translation table formatReading a first-level translation tableFixme [Figure B3-7 Accessing first-level translation table based on TTBR0, Short-descriptor format] page1332 The full translation flow for Sections, Supersections, Small pages and Large pagesFixme [Figure B3-11 Small page address translation] page1337 B3.6 Long-descriptor translation table formatFixme [Figure B3-12 General view of stage 1 address translation using Long-descriptor format]page1338 B3.6.1 Long-descriptor translation table format descriptorsIn general, a descriptor is one of:• an invalid or fault entry• a table entry, that points to the next-level translation table• a block entry, that defines the memory properties for the access• a reserved format. Long-descriptor translation table first-level and second-level descriptor formatsFixme [Figure B3-14 Long-descriptor first-level and second-level descriptor formats]page1340 Long-descriptor translation table third-level descriptor formatsFixme [Figure B3-15 Long-descriptor third-level descriptor formats]page1341 B3.6.3 Control of Secure or Non-secure memory access, Long-descriptor formatIn the Long-descriptor format:• the NS bit relates only to the memory block or page at the output address defined by the descriptor• the descriptors also include an NSTable bit, see Hierarchical control of Secure or Non-secure memoryaccesses, Long-descriptor format. NSTable == 0 The defined table address is in the Secure physical address space.NSTable == 1 The defined table address is in the Non-secure physical address space. B3.6.4 Selecting between TTBR0 and TTBR1, Long-descriptor translation table formatThe TTBCR.T0SZ and TTBCR.T1SZ size fields control the use of TTBR0 and TTBR1, Fixme [Table B3-2 Use of TTBR0 and TTBR1, Long-descriptor format]page1345 Fixme [Figure B3-18 Control of TTBR boundary, when TTBCR.T1SZ is zero]page1346 B3.6.5 Long-descriptor translation table format address lookup levelsFixme [Table B3-3 Properties of the three levels of address lookup with Long-descriptor translation tables]page1348 B3.6.6 Translation table walks, when using the Long-descriptor translation table formatExample Full translation flow, starting at second-level lookupFixme [Figure B3-22 Complete Long-descriptor format stage 1 translation, starting at second level]page1355 B3.7 Memory access controlIn addition to an output address, a translation table entry that refers to page or region of memory includes fields thatdefine properties of the target memory region. B3.7.1 Access permissionsAccess permission bits in a translation table descriptor control access to the corresponding memory region. TheShort-descriptor translation table format supports two options for defining the access permissions:• three bits, AP[2:0], define the access permissions• two bits, AP[2:1], define the access permissions, and AP[0] can be used as an Access flag. SCTLR.AFE selects the access permissions option. Setting this bit to 1, to enable the Access flag, also selects useof AP[2:1] to define access permissions The Long-descriptor translation table format uses only AP[2:1] to control the access permissions, and provides anAF bit for use as an Access flag AP[2:1] access permissions modelFixme [Table B3-6 VMSAv7 AP[2:1] access permissions model]page1357 AP[2:0] access permissions control, Short-descriptor format onlyFixme [Table B3-8 VMSAv7 MMU access permissions]page1358 B3.7.2 Execute-never restrictions on instruction fetchingExecute-never (XN) controls provide an additional level of control on memory accesses permitted by the accesspermissions settings. XN, Execute-neverWhen the XN bit is 1, a Permission fault is generated if the processor attempts to execute aninstruction fetched from the corresponding memory region. PXN, Privileged execute-neverWhen the PXN bit is 1, a Permission fault is generated if the processor is executing at PL1 andattempts to execute an instruction fetched from the corresponding memory region. B3.7.3 Domains, Short-descriptor format onlyA domain is a collection of memory regions. The Short-descriptor translation table format supports 16 domains, andrequires the software that defines a translation table to assign each VMSA memory region to a domain. B3.7.4 The Access flagThe Access flag indicates when a page or section of memory is accessed for the first time since the Access flag inthe corresponding translation table descriptor was set to 0 B3.7.5 PL2 control of Non-secure access permissionsNon-secure software executing at PL2 controls two sets of translation tables, both of which use the Long-descriptortranslation table format:• The translation tables that control the Non-secure PL2 stage 1 translations. These map VAs to PAs, formemory accesses made when executing in Non-secure state at PL2, and are indicated and controlled by theHTTBR and HTCR. The HAP[2:1] field in the stage 2 descriptors define the stage 2 access permissionsFixme [Table B3-9 Stage 2 control of access permissions]page1365 B3.8 Memory region attributesB3.8.1 Overview of memory region attributes for stage 1 translationsMemory type and attributesThese are described either:• Directly, by bits in the translation table descriptor.• Indirectly, by registers referenced by bits in the table descriptor. This is described asremapping the memory type and attribute description. The Short-descriptor translation table format can use either of these approaches, selected by theSCTLR.TRE bit:TRE == 0 Remap disabled. The TEX[2:0], C, and B bits in the translation table descriptor definethe memory region attributes. TRE == 1 Remap enabled. The TEX[0], C, and B bits in the translation table descriptor are indexbits to the MMU remap registers, that define the memory region attributes:• the Primary Region Remap Register, PRRR• the Normal Memory Remap Register, NMRR The Long-descriptor translation table format always uses remapping. ShareabilityIn the Short-descriptor translation table format, the S bit in the translation table descriptor encodeswhether the region is shareable. B3.8.2 Short-descriptor format memory region attributes, without TEX remapFixme [Table B3-10 TEX, C, and B encodings when TRE == 0]page1367 Cacheable memory attributes, without TEX remapWhen TEX[2] == 1, the translation table entry describes Cacheable memory, and the rest of the encoding definesthe Inner and Outer cache attributes:TEX[1:0] Define the Outer cache attribute.C, B Define the Inner cache attribute. Fixme [Table B3-11 Inner and Outer cache attribute encoding]page1368 B3.8.3 Short-descriptor format memory region attributes, with TEX remap• The software that defines the translation tables must program the PRRR and NMRR to define seven possiblememory region attributes.• The TEX[0], C, and B bits of the translation table descriptors define the memory region attributes, byindexing PRRR and NMRR. Fixme [Table B3-12 TEX, C, and B encodings when TRE == 1]page1369 B3.8.4 Long-descriptor format memory region attributesthe AttrIndx[2:0] field in a block or page translation table descriptor for a stage 1 translation indicates the 8-bit field in the appropriate MAIR, that specifiesthe attributes for the corresponding memory region:• AttrIndx[2] indicates the value of n in MAIRn:AttrIndx[2] == 0 Use MAIR0.AttrIndx[2] == 1 Use MAIR1 • AttrIndx[2:0] indicates the required Attr field, Attrn, where n = AttrIndx[2:0].Each AttrIndx field defines, for the corresponding memory region:• The memory type, Strongly-ordered, Device, or Normal.• For Normal memory — the inner and outer cacheability, Non-cacheable, Write-Through, or Write-Back — for Write-Through Cacheable and Write-Back Cacheable regions, the Read-Allocate and Write-Allocate policy hints, each of which is Allocate or Do not allocate Shareability, Long-descriptor formatFixme [Table B3-14 SH[1:0] field encoding for Normal memory, Long-descriptor format]page1373 For a Device or Strongly-ordered memory region, the value of the SH[1:0] field of the translation table descriptoris ignored. B3.9 Translation Lookaside Buffers (TLBs)Translation Lookaside Buffers (TLBs) are an implementation technique that caches translations or translation table entries.TLBs avoid the requirement for every memory access to perform a translation table walk in memory. B3.9.1 Global and process-specific translation table entriesIn a VMSA implementation, system software can divide a virtual memory map used by memory accesses at PL1 and PL0 into global and non-global regions, indicated by the nG bit in the translation table descriptors:nG == 0The translation is global, meaning the region is available for all processes. nG == 1The translation is non-global, or process-specific, meaning it relates to the current ASID, as defined by the CONTEXTIDR. B3.9.2 TLB matchingB3.9.3 TLB behavior at resetThe ARMv7 architecture does not require a reset to invalidate the TLB. All TLBs are disabled from reset. All MMUs are disabled from reset, and the contents of the TLBs have no effect on address translation. B3.9.5 TLB conflict abortsThe Large Physical Address Extension introduces the concept of a TLB conflict abort, and adds fault status encodings for such an abort. An implementation can generate a TLB conflict abort if it detects that the address being looked up in the TLB hits multiple entries.In some implementations, multiple hits in the TLB can generate a synchronous Data Abort or Prefetch Abort exception. B3.10 TLB maintenance requirementsB3.10.1 General TLB maintenance requirementsThe architecture defines CP15 c8 functions for TLB maintenance operations, and supports the following operations: invalidate all unlocked entries in the TLB invalidate a single TLB entry, by MVA, or MVA and ASID for a non-global entry invalidate all TLB entries that match a specified ASID. The Multiprocessing Extensions add the following operations:• invalidate all TLB entries that match a specified MVA, regardless of the ASID Using break-before-make when updating translation table entriesARM strongly recommends the use of a break-before-make when changing translation table entries whenever multiple threads of execution can use the same translation tables and the change to the translation entries involves any of:• A change of the memory type.• A change of the cacheability attributes.• A change of the output address (OA), if the OA of at least one of the old translation table entry and the newtranslation table entry is writable. break-before-make Replace the old translation table entry, and execute DSB instruction. Invalidate the translation table entry with a broadcast TLB invalidation instruction, and execute a DSB instruction Write the new translation table entry, and execute a DSB instruction B3.10.2 Maintenance requirements on changing system control register valuesThe TLB contents can be influenced by control bits in a number of system control registers. The system control register changes that this applies to are:• any change to the NMRR, PRRR, MAIRn, or HMAIRn registers• any change to the SCTLR.AFE bit, see Changing the Access flag enable• any change to the SCTLR.TRE bit• any change to the translation table base address in TTBR0• any change to the translation table base address in TTBR1• in an implementation that includes the Virtualization Extensions: — any change to the SCTLR.{WXN, UWXN} bits — any change to the SCR.SIF bit — any change to the HCR.VM bit — any change to HCR.PTW bit, see Changing HCR.PTW — any change to the HTTBR.BADDR field — any change to the VTTBR.BADDR field• in an implementation that includes the Large Physical Address Extension, changing TTBCR.EAE, seeChanging the current Translation table format on page B3-1386• when using the Short-descriptor translation table format: — any change to the RGN, IRGN, S, or NOS fields in TTBR0 or TTBR1 — any change to the PD0 or PD1 fields in TTBCR• when using the Long-descriptor translation table format: — any change to the TnSZ, ORGNn, IRGNn, SHn, or EPDn fields in the TTBCR, where n is 0 or 1 — any change to the T0SZ, ORGN0, IRGN0, or SH0 fields in the HTCR — any change to the T0SZ, ORGN0, IRGN0, or SH0 fields in the VTCR. B3.10.3 Atomicity of register changes on changing virtual machineFrom the viewpoint of software executing in a Non-secure PL1 or PL0 mode, when there is a switch from one virtualmachine to another, the registers that control or affect address translation must be changed atomically. This applies to the registers for:• Non-secure PL1&amp;0 stage 1 address translations. This means that all of the following registers must change atomically: — PRRR and NMRR, if using the Short-descriptor translation table format — MAIR0 and MAIR1, if using the Long-descriptor translation table format — TTBR0, TTBR1, TTBCR, DACR, and CONTEXTIDR — the SCTLR. These registers apply to execution in Non-secure PL1&amp;0 modes. However, when updated as part of a switch of virtual machines they are updated by software executing in Hyp mode. • Non-secure PL1&amp;0 stage 2 address translations. This means that all of the following registers and registerfields must change atomically: — VTTBR and VTCR — HMAIR0 and HMAIR1 — the HSCTLR. B3.11 Caches in a VMSA implementationB3.11.1 Data and unified cachesThe behavior of accesses from the same observer to different VAs, that are translated to the same PA with the same memory attributes, is fully coherent. This means these accesses behave as follows, regardless ofwhich VA is accessed:• two writes to the same PA occur in program order• a read of a PA returns the value of the last successful write to that PA• a write to a PA that occurs, in program order, after a read of that PA, has no effect on the value returned bythat read.The memory system behaves in this way without any requirement to use barrier or cache maintenance operations. B3.11.2 Instruction cachesIn the ARM architecture, an instruction cache is a cache that is accessed only as a result of an instruction fetch.Therefore, an instruction cache is never written to by any load or store instruction executed by the processor. The ARMv7 architecture supports three different behaviors for instruction caches:• Physically-indexed, physically-tagged(PIPT) instruction caches• Virtually-indexed, physically-tagged (VIPT) instruction caches• ASID and VMID tagged Virtually-indexed, virtually-tagged (VIVT) instruction caches. B3.11.2.1 PIPT instruction caches &amp; VIPT instruction cachesFor PIPT instruction caches, the use of memory address translation is entirely transparent to all instruction fetchesthat are not UNPREDICTABLE. An implementation that provides PIPT/VIPT instruction caches implements the IVIPT extension, see IVIPT architectureextension B3.11.2.2 IVIPT architecture extensionIt reduces the instruction cache maintenance requirement to the following condition:• instruction cache maintenance is required only after writing new data to a physical address that holds aninstruction. B3.11.2.3 ASID and VMID tagged VIVT instruction cachesInstruction maintenance can also be required as a result of any of the following situations:• enabling or disabling the MMU• writing new mappings to the translation tables• any change to the TTBR0, TTBR1, or TTBCR registers, unless accompanied by a change to the ContextID,or a change to the VMID• changes to the VTTBR or VTCR registers, unless accompanied by a change to the VMID B3.12 VMSA memory abortsIn a VMSAv7 implementation, the following mechanisms cause a processor to take an exception on a failed memoryaccess:Debug exceptionAn exception caused by the debug configuration, see About debug exceptions onpage C4-2090. Alignment faultAn Alignment fault is generated if the address used for a memory access does not have therequired alignment for the operation. For more information see Unaligned data access onpage A3-108 and Alignment faults on page B3-1402. MMU faultAn MMU fault is a fault generated by the fault checking sequence for the current translationregime. External abortAny memory system fault other than a Debug exception, an Alignment fault, or an MMUfault B3.12.1 Routing of abortsA memory abort is either a Data Abort exception or a Prefetch Abort exception. The mode to which a memory abortis taken depends on the reason for the exception, the mode the processor is in when it takes the exception: Memory aborts taken to Monitor modeIf an implementation includes the Security Extensions, when SCR.EA is set to 1, all External abortsare taken to Monitor mode. This applies to aborts taken from Secure modes and from Non-securemodes. Memory aborts taken to Secure Abort modeIf an implementation includes the Security Extensions, when the processor is executing in Securestate, all memory aborts that are not routed to Monitor mode are taken to Secure Abort mode. Memory aborts taken to Hyp mode大致都发生在Hyp mode，Non-secure 时至少也是在stage 2 发生的错误（stage 1 VA -&gt; IPA; stage2 IPA-&gt; PA. 虚拟地址-&gt;中间地址-&gt;物理地址） includes the Virtualization Extensions, the processor is executing in Non-secure state• Alignment faults taken: — When the processor is in Hyp mode. — When the processor is in a PL1 or PL0 mode and the exception is generated because the Non-secure PL1&amp;0 stage 2 translation identifies the target of an unaligned access as Device or Strongly-ordered memory. — When the processor is in the PL0 mode and HCR.TGE is set to 1. For more information see Synchronous external abort, when HCR.TGE is set to 1 on page B1-1193. • When the processor is using the Non-secure PL1&amp;0 translation regime: — MMU faults from stage 2 translations, for which the stage 1 translation did not cause an MMU fault. — Any abort taken during the stage 2 translation of an address accessed in a stage 1 translation table walk that is not routed to Secure Monitor mode• When the processor is using the Non-secure PL2 translation regime, MMU faults fromstage 1 translations. • External aborts, if SCR.EA is set to 0 and any of the following applies: — The processor was executing in Hyp mode when it took the exception. — The processor was executing in a Non-secure PL0 or PL1 mode when it took the exception, the abort is asynchronous, and HCR.AMO is set to 1. — The processor was executing in the Non-secure PL0 mode when it took the exception, the abort is synchronous, and HCR.TGE is set to 1. For more information see Synchronous external abort, when HCR.TGE is set to 1 on page B1-1193. — The abort occurred on a stage 2 translation table walk. • Debug exceptions, if HDCR.TDE is set to 1. Memory aborts taken to Non-secure Abort modeIn an implementation that does not include the Security Extensions, all memory aborts are taken toAbort mode.Otherwise, when the processor is executing in Non-secure state, the following aborts are taken toNon-secure Abort mode:• When the processor is in a Non-secure PL1 or PL0 mode, Alignment faults taken for any ofthe following reasons: — SCTLR.A is set to 1. — An instruction that does not support unaligned accesses is committed for execution, and the instruction accesses an unaligned address. — The implementation includes the Virtualization Extensions, and the PL1&amp;0 stage 1 translation identifies the target of an unaligned access as Device or Strongly-ordered memory.• When the processor is using the Non-secure PL1&amp;0 translation regime, MMU faults fromstage 1 translations.• External aborts, if all of the following apply: — the abort is not on a stage 2 translation table walk — the processor is not in Hyp mode — SCR.EA is set to 0 — the abort is asynchronous, and HCR.AMO is set to 0 — the abort is synchronous, and HCR.TGE is set to 0• When the processor is using the Non-secure PL1&amp;0 translation regime, MMU faults fromstage 1 translations.• External aborts, if all of the following apply: — the abort is not on a stage 2 translation table walk — the processor is not in Hyp mode — SCR.EA is set to 0 — the abort is asynchronous, and HCR.AMO is set to 0 — the abort is synchronous, and HCR.TGE is set to 0 B3.12.3 The MMU fault-checking sequenceIn a VMSA implementation, all memory accesses require VA to PA translation. Therefore, when a correspondingMMU is enabled, each access requires a lookup of the translation table descriptor for the accessed VA. When using the Short-descriptor format• There are one or two levels of lookup.• Lookup always starts at the first level.• The final level of lookup checks the Domain field of the descriptor and: — faults if there is no access to the Domain — checks the access permissions only for Client domains.When using the Long-descriptor format• There are one, two, or three levels of lookup.• Lookup starts at either the first level or the second level.• Domains are not supported. All accesses are treated as Client domain accesses. Fixme [Figure B3-23 Fetching the descriptor in a translation table walk]Page1400 Fixme [Figure B3-24 VMSA fault checking sequence]Page1401 Stage 2 fault on a stage 1 translation table walk, Virtualization ExtensionsWhen an implementation that includes the Virtualization Extensions is operating in a Non-secure PL1 or PL0 mode,any memory access goes through two stages of translation:• stage 1, from VA to IPA• stage 2, from IPA to PA B3.12.4 Alignment faultsThe ARMv7 memory architecture requires support for strict alignment checking. This checking is controlled bySCTLR.A. An Alignment fault can occur on an access for which the MMU is disabled. In an implementation that includes the Virtualization Extensions, any unaligned access to memory region with the Device or Strongly-ordered memory type attribute generates an Alignment fault. B3.12.5 MMU faultsThis section describes the faults that might be detected during one of the fault-checking sequences described in TheMMU fault-checking sequence. The following subsections describe the MMU faults that might be detected during a fault checking sequence:• External abort on a translation table walk• Translation fault• Access flag fault on page B3-1404• Domain fault, Short-descriptor format translation tables only on page B3-1404• Permission fault on page B3-1405. Translation faultA Translation fault can be generated at any level of lookup, and the reported fault code identifies the lookup level.A Translation fault is generated if bits[1:0] of a translation table descriptor identify the descriptor as either a Faultencoding or a reserved encoding. In addition, if an implementation includes the Virtualization Extensions, then a Translation fault is generated if theinput address for a translation either does not map on to an address range of a Translation Table Base Register, orthe Translation Table Base Register range that it maps on to is disabled. The architecture guarantees that any translation table entry that causes a Translation fault is not cached, Access flag faultAn Access flag fault can be generated at any level of lookup,• The translation tables support an Access flag bit: — the Short-descriptor format supports an Access flag only when SCTLR.AFE is set to 1 — the Long-descriptor format always supports an Access flag. The architecture guarantees that any translation table entry that causes an Access flag fault is not cached, meaningthe TLB never holds such an entry. Domain fault, Short-descriptor format translation tables onlyWhen using the Short-descriptor translation table format, a Domain fault can be generated at the first level or secondlevel of lookup. When a first-level/second-level descriptor fetch returns a valid Section first-level descriptor, the domain field ofthat descriptor is checked against the DACR. A first-level Domain fault is generated if this checkfails. A TLB might hold a translation table entry that cause a Domain fault. Permission faultA Permission fault can be generated at any level of lookup, and the reported fault code identifies the lookup level. A TLB might hold a translation table entry that cause a Permission fault. Therefore, if the handling of a Permissionfault results in an update to the associated translation tables, the software that updates the translation tables mustinvalidate the appropriate TLB entry. B3.12.6 External abortsThe ARM architecture defines external aborts as errors that occur in the memory system, other than those that aredetected by the MMU or Debug hardware.An external abort is one of:• synchronous• precise asynchronous• imprecise asynchronous. The ARM architecture does not provide any method to distinguish between precise asynchronous and impreciseasynchronous aborts. Normally, external aborts are rare. An imprecise asynchronous external abort is likely to be fatal to the process thatis running. B3.12.7 Prioritization of abortsprioritization decreasing in next order: Alignment fault an MMU fault, on either the stage 1 translation or the stage 2 translation a Watchpoint debug event. an external abort B3.13 Exception reporting in a VMSA implementationB3.13.1 About exception reportingIn an implementation that includes the Virtualization Extensions, exceptions can be taken to:• a Secure or Non-secure PL1 mode• the Non-secure PL2 mode, Hyp mode. B3.13.2 Reporting exceptions taken to PL1 modesRegisters used for reporting exceptions taken to a PL1 modeARMv7 defines the following registers, and register encodings, for exceptions taken to PL1 modes:• the DFSR holds information about a Data Abort exception• the DFAR holds the faulting address for some synchronous Data Abort exceptions• the IFSR holds information about a Prefetch Abort exception• the IFAR holds the faulting address of a Prefetch Abort exception• on a Watchpoint debug exception, the DBGWFAR can hold fault information. Auxiliary Fault Status RegistersThe ARMv7 architecture defines the following Auxiliary Fault Status Registers:• the Auxiliary Data Fault Status Register, ADFSR• the Auxiliary Instruction Fault Status Register, AIFSR. B3.13.3 Fault reporting in PL1 modesFixme [Table B3-23 Short-descriptor format FSR encodings] Page 1415 Fixme [Table B3-24 Long-descriptor format FSR encodings] Page 1416 B3.13.5 Reporting exceptions taken to the Non-secure PL2 modeRegisters used for reporting exceptions taken to Hyp modeThe Virtualization Extensions define the following registers for exceptions taken to Hyp mode:• the HSR holds syndrome information for the exception• the HDFAR holds the VA associated with a Data Abort exception• the HIFAR holds the VA associated with a Prefetch Abort exception• the HPFAR holds bits[39:12] of the IPA associated with some aborts on stage 2 address translations. Hyp Auxiliary Fault Syndrome RegistersThe Virtualization Extensions define the following Hyp Auxiliary Fault Syndrome Registers:• the Hyp Auxiliary Data Fault Syndrome Register, HADFSR• the Hyp Auxiliary Instruction Fault Syndrome Register, HAIFSR. Fixme [Table B3-28 HSR.EC encodings for aborts taken to Hyp mode] Page 1422 B3.13.6 Use of the HSRThe HSR holds syndrome information for any synchronous exception taken to Hyp mode. Compared with thereporting of exceptions taken to PL1 modes, the HSR:• Always provides details of the fault. The DFSR and IFSR are not used.• Provides more extensive information, for a wider range of exceptions. Fixme [Figure B3-25 Format of the HSR, with subdivision of the ISS field for specified EC encodings] Page 1425 Fixme [Table B3-29 HSR.EC field encoding] Page 1425 More detail ISS encoding see arm-arm pdf B3.14 Virtual Address to Physical Address translation operationCP15 c7 includes operations for Virtual Address (VA) to Physical Address (PA) translation. B3.14.1 Naming of the address translation operations, and operation summaryFixme [Table B3-31 Naming of address translation operations] Page 1438 In the stage 1 current state and stages 1 and 2 Non-secure state only operations, the meanings of the last two lettersof the names are: PR PL1 mode, read operation. PW PL1 mode, write operation. UR PL0 mode, read operation. UW PL0 mode, write operation. B3.14.2 Encoding and availability of the address translation operationsSoftware executing at PL0 never has any visibility of the address translation operations, but software executing atPL1 or higher can use the unprivileged address translation operations to find the address translations used formemory accesses by software executing at PL0 and PL1. Fixme [Table B3-32 CP15 c7 address translation operations] Page 1440 The result of an operation is always returned in the PAR. The PAR is a RW register and:• in all implementations, the 32-bit format PAR is accessed using an MCR or MRC instruction with CRn set to c7,CRm set to c4, and opc1 and opc2 both set to 0• in an implementation that includes the Large Physical Address Extension, the 64-bit format PAR is accessedusing an MCRR or MRRC instruction with CRm set to c7, and opc1 set to 0. B3.14.3 Determining the PAR format, Large Physical Address ExtensionThe Large Physical Address Extension extends the PAR to become a 64-bit register, and supports both 32-bit and64-bit PAR formats B3.15 About the system control registers for VMSAOn an ARMv7-A or ARMv7-R implementation, the system control registers comprise:• the registers accessed using the System Control Coprocessor, CP15• registers accessed using the CP14 coprocessor, including: — debug registers — trace registers — execution environment registers. B3.15.3 Classification of system control registersBanked system control registersFixme [Table B3-33 Banked CP15 registers] Page 1452 Restricted access system control registersFixme [Table B3-34 Restricted access CP15 registers] Page 1453 PL2-mode system control registersFixme [Table B3-35 Banked PL2-mode CP15 read/write registers] Page 1455 Fixme [Table B3-37 Banked PL2-mode CP15 write-only operations] Page 1457 Common system control registersSome system control registers and operations are common to the Secure and Non-secure security states.Fixme [Table B3-38 Common CP15 registers] Page 1457 B3.16 Organization of the CP14 registers in a VMSA implementationThe CP14 registers provide a number of distinct control functions, covering:• Debug• Trace• Execution environment control, for the Jazelle and ThumbEE execution environments. The CP14 register encodings are classified by the {CRn, opc1, CRm, opc2} values required to access them usingan MCR or an MRC instruction. The opc1 value determines the primary allocation of these registers, as follows:opc1==0 Debug registers.opc1==1 Trace registers.opc1==6 ThumbEE registers.opc1==7 Jazelle registers. Can include Jazelle SUBARCHITECTURE DEFINED registers B3.17 Organization of the CP15 registers in a VMSA implementationMore precisely, the ordered set of values {CRn, opc1, CRm, opc2} determined the register order. B3.17.1 CP15 register summary by coprocessor register numberFixme [Figure B3-26 CP15 register grouping by primary coprocessor register, CRn, VMSA implementation] Page 1470 VMSA CP15 c0 register summary, identification registersFixme [Figure B3-27 CP15 c0 registers in a VMSA implementation] Page 1471 VMSA CP15 c1 register summary, system control registersFixme [Figure B3-28 CP15 c1 registers in a VMSA implementation] Page 1472 VMSA CP15 c2 and c3 register summary, Memory protection and control registersFixme [Figure B3-29 CP15 32-bit c2 and c3 registers] Page 1473 Fixme [Figure B3-30 CP15 64-bit c2 registers] Page 1473 VMSA CP15 c5 and c6 register summary, Memory system fault registersFixme [Figure B3-31 CP15 c5 and c6 registers in a VMSA implementation] Page 1474 VMSA CP15 c7 register summary, Cache maintenance, address translation, and other functionsFixme [Figure B3-32 CP15 32-bit c7 registers in a VMSA implementation] Page 1475 VMSA CP15 c8 register summary, TLB maintenance operationsFixme [Figure B3-34 CP15 c8 registers in a VMSA implementation] Page 1476 VMSA CP15 c9 register summary, reserved for cache and TCM control and performance monitorsFixme [Figure B3-35 Reserved CP15 c9 encodings] Page 1477 VMSA CP15 c10 register summary, memory remapping and TLB control registersFixme [Figure B3-36 CP15 c10 registers in a VMSA implementation] Page 1478 VMSA CP15 c11 register summary, reserved for TCM DMA registersFixme [Figure B3-37 Reserved CP15 c11 encodings] Page 1478 VMSA CP15 c12 register summary, Security Extensions registersFixme [Figure B3-38 Security Extensions CP15 c12 registers] Page 1479 VMSA CP15 c13 register summary, Process, context and thread ID registersOn an ARMv7-A implementation, the CP15 c13 registers provide:• an FCSE Process ID Register, that indicates whether the implementation includes the FCSE• a Context ID Register• Software Thread ID Registers.Fixme [Figure B3-39 CP15 c13 registers in a VMSA implementation] Page 1479 VMSA CP15 c14, reserved for Generic Timer ExtensionFixme [Figure B3-40 CP15 32-bit c14 registers in a VMSA implementation that includes the Generic Timer Extension] Page 1480Fixme [Figure B3-41 CP15 64-bit c14 registers in a VMSA implementation that includes the Generic Timer Extension] Page 1480 VMSA CP15 c15 register summary, IMPLEMENTATION DEFINED registers B3.17.2 Full list of VMSA CP15 registers, by coprocessor register numberFixme [Table B3-42 Summary of VMSA CP15 register descriptions, in coprocessor register number order] Page 1481 B3.18 Functional grouping of VMSAv7 system control registersB3.18.1 Identification registers, functional groupFixme [Table B3-44 Identification registers, VMSA] Page 1492 B3.18.2 Virtual memory control registers, functional groupFixme [Table B3-45 Virtual memory control registers, VMSA only] Page 1493 B3.18.3 PL1 Fault handling registers, functional groupFixme [Table B3-46 Fault handling registers, VMSA] Page 1494 B3.18.4 Other system control registers, functional groupFixme [Table B3-47 Other system control registers, VMSA] Page 1494 B3.18.5 Lockdown, DMA, and TCM features, functional group, VMSAFixme [Table B3-48 Lockdown, DMA, and TCM features, VMSA] Page 1495 B3.18.6 Cache maintenance operations, functional group, VMSAFixme [Table B3-49 Cache and branch predictor maintenance operations, VMSA] Page 1496 B3.18.7 TLB maintenance operations, functional groupFixme [Table B3-50 TLB maintenance operations, VMSA only] Page 1497 B3.18.8 Address translation operations, functional groupFixme [Table B3-51 Address translation operations, VMSA only] Page 1498 B3.18.9 Miscellaneous operations, functional groupFixme [Table B3-52 Miscellaneous system control operations, VMSA only] Page 1499 B3.18.10 Performance Monitors, functional groupFixme [Table B3-53 Performance monitors, VMSA] Page 1500 B3.18.11 Security Extensions registers, functional groupFixme [Table B3-54 Security Extensions registers, VMSA only] Page 1500 B3.18.12 Virtualization Extensions registers, functional groupFixme [Table B3-55 Virtualization Extensions registers, VMSA with Virtualization Extensions only] Page 1501 Fixme [Table B3-56 Hyp mode TLB maintenance operations, VMSA with Virtualization Extensions only] Page 1502 B3.18.13 Generic Timer Extension registersB3.18.14 IMPLEMENTATION DEFINED registers, functional groupTypically, an implementation uses CP15 c15 to provide test features, and any required configuration options thatare not covered by this manual. B4 System Control Registers in a VMSA implementationSkip B5 Protected Memory System Architecture (PMSA)Skip B6 System Control Registers in a PMSA implementationSkip B7 The CPUID Identification SchemeB7.1 Introduction to the CPUID schemeBefore ARMv7, using Main ID Register:• MIDR, Main ID Register, VMSA on page B4-1649• MIDR, Main ID Register, PMSA on page B6-1894. The ARMv7 architecture implements an extended processor, using a number of registers in CP15 c0.ARMv7 requires the use of this scheme, and use of the scheme is indicated by a value of 0xF in the Architecture field of the Main ID Register. The CPUID scheme provides information about the implemented:• processor features• debug features• auxiliary features, in particular IMPLEMENTATION DEFINED features• memory model features• instruction set features. B7.2 The CPUID registersB7.2.1 Organization of the CPUID registersFixme[Figure B7-1 CPUID register encodings] Page 1951 Fixme[Table B7-1 CPUID register summary] Page 1952 B7.2.2 About the Instruction Set Attribute registersFixme[Table B7-2 Alphabetic list of Instruction Set Attribute registers attribute fields] Page 1954 B8. The Generic TimerB8.1 About the Generic TimerFixme[Figure B8-1 Generic Timer example] page1960 8.1.1 System counterThe Generic Timer provides a system counter with the following specification:WidthAt least 56 bits wide.The value returned by any 64-bit read of the counter is zero-extended to 64 bits. FrequencyIncrements at a fixed frequency, typically in the range 1-50MHz.Can support one or more alternative operating modes in which it increments by larger amounts at alower frequency, typically for power-saving.Roll-over Roll-over time of not less than 40 years. AccuracyARM does not specify a required accuracy, but recommends that the counter does not gain or losemore than ten seconds in a 24-hour period.Use of lower-frequency modes must not affect the implemented accuracy. Start-upStarts operating from zero. The system counter must be implemented in an always-on power domain. Initializing and reading the system counter frequencyTypically, the system drives the system counter at a fixed frequency and the CNTFRQ register must be programmedto this value during the system boot process. In an implementation that supports the ARM Security Extensions, onlysoftware executing in a Secure PL1 mode can write to CNTFRQ. Software can read the CNTFRQ register, to determine the current system counter frequency, in the following statesand modes:• Non-secure PL2 mode.• Secure and Non-secure PL1 modes.• When CNTKCTL.PL0PCTEN is set to 1, Secure and Non-secure PL0 modes. 8.1.2 The physical counterThe processor provides a physical counter that contains the count value of the system counter. The CNTPCT registerholds the current physical counter value. In an implementation that includes the Virtualization Extensions, CNTPCT:• Is always accessible from Secure PL1 modes, and from Non-secure Hyp mode.• Is accessible from Non-secure PL1 modes only when CNTHCTL.PL1PCTEN is set to 1. WhenCNTHCTL.PL1PCTEN is set to 0, any attempt to access CNTPCT from a Non-secure PL1 mode generatesa Hyp Trap exception, see Hyp Trap exception on page B1-1209. 8.1.3 The virtual counterAn implementation of the Generic Timer always includes a virtual counter, that indicates virtual time:• In a processor implementation that does not include the Virtualization Extensions, virtual time is identical tophysical time, and the virtual counter contains the same value as the physical counter.• In a processor implementation that includes the Virtualization Extensions, the virtual counter contains thevalue of the physical counter minus a 64-bit virtual offset. When execu CNTVCT is always accessible from Secure PL1 modes, and from Non-secure PL1 and PL2 modes 8.1.5 TimersThe number of timers provided by an implementation of the Generic Timer depends on whether the implementationincludes the Security Extensions and the Virtualization Extensions, as follows: Security Extensions not implementedThe implementation provides a physical timer and a virtual timer. Security Extensions implemented, Virtualization Extensions not implementedThe implementation provides: A Non-secure physical timer. A Secure physical timer. A virtual timer. Virtualization Extensions implementedThe implementation provides: A Non-secure PL1 physical timer. A Secure PL1 physical timer. A Non-secure PL2 physical timer. A virtual timer Each timer is implemented as three registers: A 64-bit CompareValue register, that provides a 64-bit unsigned upcounter. A 32-bit TimerValue register, that provides a 32-bit signed downcounter. A 32-bit Control register. Fixme[Table B8-1 Timer registers summary for the Generic Timer] page1965 8.2 Generic Timer registers summaryFixme[Table B8-2 Generic Timer registers] page1969]]></content>
      <categories>
        <category>arm</category>
      </categories>
      <tags>
        <tag>arm</tag>
        <tag>spec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arm arm]]></title>
    <url>%2F2019%2F05%2F28%2Farm_arm%2F</url>
    <content type="text"><![CDATA[Part A. Application Level Architecture A1. Introduction to the ARM Architecture A1.4 Architecture extensionsJazelleIs the Java bytecode execution extension that extended ARMv5TE to ARMv5TEJ. FromARMv6, the architecture requires at least the trivial Jazelle implementation, but a Jazelleimplementation is still often described as a Jazelle extension.The Virtualization Extensions require that the Jazelle implementation is the trivial Jazelleimplementation. ThumbEEIs an extension that provides the ThumbEE instruction set, a variant of the Thumbinstruction set that is designed as a target for dynamically generated code. In the originalrelease of the ARMv7 architecture, the ThumbEE extension was:• A required extension to the ARMv7-A profile.• An optional extension to the ARMv7-R profile. From publication of issue C.a of this manual, ARM deprecates any use of ThumbEEinstructions. However, ARMv7-A implementations must continue to include ThumbEEsupport, for backwards compatibility. Floating-pointIs a floating-point coprocessor extension to the instruction set architectures. For historicreasons, the Floating-point Extension is also called the VFP Extension. Advanced SIMDIs an instruction set extension that provides Single Instruction Multiple Data (SIMD)integer and single-precision floating-point vector operations on doubleword and quadwordregisters. A1.4.2 Architecture extensionsThis manual also describes the following extensions to the ARMv7 architecture:Security Extensions Multiprocessing ExtensionsAre an OPTIONAL set of extensions to the ARMv7-A and ARMv7-R profiles, that provides a set offeatures that enhance multiprocessing functionality. Large Physical Address ExtensionIs an OPTIONAL extension to VMSAv7 that provides an address translation system supportingphysical addresses of up to 40 bits at a fine grain of translation.The Large Physical Address Extension requires implementation of the Multiprocessing Extensions. Virtualization ExtensionsAre an OPTIONAL set of extensions to VMSAv7 that provides hardware support for virtualizing theNon-secure state of a VMSAv7 implementation. This supports system use of a virtual machinemonitor, also called a hypervisor. Generic Timer ExtensionIs an OPTIONAL extension to any ARMv7-A or ARMv7-R, that provides a system timer, and alow-latency register interface to it. Performance Monitors ExtensionThe ARMv7 architecture:• reserves CP15 register space for IMPLEMENTATION DEFINED performance monitors• defines a recommended performance monitors implementation. A2. Application Level Programmers’ ModelA2.1 About the Application level programmers’ modelDepending on the implemented architecture extensions, the architecture supports multiple levels of executionprivilege, that number upwards from PL0, where PL0 is the lowest privilege level and is often described asunprivileged. When an operating system supports execution at both PL1 and PL0, an application usually runs unprivileged. This:• permits the operating system to allocate system resources to an application in a unique or shared manner• provides a degree of protection from other processes and tasks, and so helps protect the operating systemfrom malfunctioning applications. A2.2 ARM core data types and arithmeticAll ARMv7-A and ARMv7-R processors support the following data types in memory:Byte 8 bitsHalfword 16 bitsWord 32 bitsDoubleword 64 bits. Processor registers are 32 bits in size. The instruction set contains instructions supporting the following data typesheld in registers:• 32-bit pointers• unsigned or signed 32-bit integers• unsigned 16-bit or 8-bit integers, held in zero-extended form• signed 16-bit or 8-bit integers, held in sign-extended form• two 16-bit integers packed into a register• four 8-bit integers packed into a register• unsigned or signed 64-bit integers held in two registers. A2.3 ARM core registersIn the application level view, an ARM processor has:• thirteen general-purpose 32-bit registers, R0 to R12• three 32-bit registers with special uses, SP, LR, and PC, that can be described as R13 to R15.The special registers are:SP, the stack pointerThe processor uses SP as a pointer to the active stack.In the Thumb instruction set, most instructions cannot access SP. The only instructions that canaccess SP are those designed to use SP as a stack pointer.The ARM instruction set provides more general access to the SP, and it can be used as ageneral-purpose register. However, ARM deprecates the use of SP for any purpose other than as astack pointer.Software can refer to SP as R13. LR, the link registerThe link register is a special register that can hold return link information. Some cases described inthis manual require this use of the LR. When software does not require the LR for linking, it can useit for other purposes. It can refer to LR as R14. PC, the program counter• When executing an ARM instruction, PC reads as the address of the current instruction plus 8.（PC始终指向你要取的指令的地址。ARM三级流水线，下一条指令是包含了预取指令，执行指令）• When executing a Thumb instruction, PC reads as the address of the current instruction plus 4.• Writing an address to PC causes a branch to that address.Most Thumb instructions cannot access PC.The ARM instruction set provides more general access to the PC, and many ARM instructions canuse the PC as a general-purpose register. However, ARM deprecates the use of PC for any purposeother than as the program counter. Software can refer to PC as R15. A2.3.1 Writing to the PCIn ARMv7, many data-processing instructions can write to the PC. Writes to the PC are handled as follows:• The B, BL, CBNZ, CBZ, CHKA, HB, HBL, HBLP, HBP, TBB, and TBH instructions remain in the same instruction set stateand branch to the value written to the PC.The definition of each of these instructions ensures that the value written to the PC is correctly aligned forthe current instruction set state. • The BLX (immediate) instruction switches between ARM and Thumb states and branches to the value writtento the PC. Its definition ensures that the value written to the PC is correctly aligned for the new instructionset state. • The following instructions write a value to the PC, treating that value as an interworking address to branchto, with low-order bits that determine the new instruction set state: — BLX (register), BX, and BXJ — LDR instructions with equal to the PC — POP and all forms of LDM except LDM (exception return), when the register list includes the PC — in ARM state only, ADC, ADD, ADR, AND, ASR (immediate), BIC, EOR, LSL (immediate), LSR (immediate), MOV, MVN, ORR, ROR (immediate), RRX, RSB, RSC, SBC, and SUB instructions with equal to the PC and without flag-setting specified. A2.4 The Application Program Status Register (APSR)Fixme [APSR] Page49 • Bits that can be set by many instructions:— The Condition flags: N, bit[31] Negative condition flag. Set to bit[31] of the result of the instruction. If the result is regarded as a two’s complement signed integer, then the processor sets N to 1 if the result is negative, and sets N to 0 if it is positive or zero. Z, bit[30] Zero condition flag. Set to 1 if the result of the instruction is zero, and to 0 otherwise. A result of zero often indicates an equal result from a comparison. C, bit[29] Carry condition flag. Set to 1 if the instruction results in a carry condition, for example an unsigned overflow on an addition. V, bit[28] Overflow condition flag. Set to 1 if the instruction results in an overflow condition, for example a signed overflow on an addition. — The Overflow or saturation flag: Q, bit[27] Set to 1 to indicate overflow or saturation occurred in some instructions, normally related to digital signal processing (DSP). For more information, see Pseudocode details of saturation on page A2-44. — The Greater than or Equal flags: GE[3:0], bits[19:16] The instructions described in Parallel addition and subtraction instructions on page A4-171 update these flags to indicate the results from individual bytes or halfwords of the operation. These flags can control a later SEL instruction. For more information, see SEL on page A8-602. In ARMv7-A and ARMv7-R, the APSR is the same register as the CPSR, but the APSR must be used only to accessthe N, Z, C, V, Q, and GE[3:0] bits. A2.5 Execution state registersThe execution state registers modify the execution of instructions. They control:• Whether instructions are interpreted as Thumb instructions, ARM instructions, ThumbEE instructions, orJava bytecodes. For more information, see Instruction set state register, ISETSTATE. • In Thumb state and ThumbEE state only, the condition codes that apply to the next one to four instructions.For more information, see IT block state register, ITSTATE on page A2-51. • Whether data is interpreted as big-endian or little-endian. For more information, see Endianness mappingregister, ENDIANSTATE on page A2-53. In ARMv7-A and ARMv7-R, the execution state registers are part of the Current Program Status Register. For moreinformation, see Program Status Registers (PSRs) on page B1-1147. A2.5.1 Instruction set state register, ISETSTATEThe instruction set state register, ISETSTATE, format is:The J bit and the T bit determine the current instruction set state for the processor. Table A2-1 shows the encodingof these bits. Fixme [Table A2-1 J and T bit encoding in ISETSTATE]Page50 A2.5.2 IT block state register, ITSTATEFixme [Table A2-2 Effect of IT execution state bits]Page52 A2.5.3 Endianness mapping register, ENDIANSTATEFixme [Table A2-3 ENDIANSTATE encoding of endianness]Page53 A2.6 Advanced SIMD and Floating-point ExtensionsAdvanced SIMD and Floating-point (VFP) are two OPTIONAL extensions to ARMv7. The Advanced SIMD Extension performs packed Single Instruction Multiple Data (SIMD) operations, eitherinteger or single-precision floating-point. …. A2.11 Jazelle direct bytecode execution supportThe Jazelle extension provides architectural support for hardware acceleration of bytecode execution by a Java VirtualMachine (JVM). These requirements for the Jazelle extension mean a JVM can be written to both:• function correctly on all processors that include a Jazelle extension implementation• automatically take advantage of the accelerated bytecode execution provided by a processor that includes anon-trivial implementation. The required features of a non-trivial implementation are:• provision of the Jazelle state• a new instruction, BXJ, to enter Jazelle state• system support that enables an operating system to regulate the use of the Jazelle extension hardware• system support that enables a JVM to configure the Jazelle extension hardware to its specific needs. … A3 Application Level Memory Model… A3.2 Alignment supportInstructions in the ARM architecture are aligned as follows:• ARM instructions are word-aligned• Thumb and ThumbEE instructions are halfword-aligned• Java bytecodes are byte-aligned.In the ARMv7 architecture, some load and store instructions support unaligned data accesses, as described inUnaligned data access. A3.2.1 Unaligned data accessAn ARMv7 implementation must support unaligned data accesses to Normal memory by some load and storeinstructions. Software can set the SCTLR.A bit to control whether a misaligned access to Normal memory by one of these instructions causes an Alignment fault Data Abort exception. Unaligned access operations must not be used for accessing memory-mapped registers in a Device or Strongly-ordered memory region. Fixme [Table A3-1 Alignment requirements of load/store instructions] page108 A3.3 Endian supportData support big-endian or little-endian. A3.3.1 Instruction endiannessIn ARMv7-A, the mapping of instruction memory is always little-endian. In ARMv7-R, instruction endianness canbe controlled at the system level, In ARMv7-A, the mapping of instruction memory is always little-endian. In ARMv7-R, instruction endianness can be controlled at the system level, see Instruction endianness static configuration, ARMv7-R only on page A3-112. A3.3.2 Element size and endiannessFixme [Table A3-2 Element size of load/store instructions] page112 A3.3.4 Endianness in Advanced SIMDAdvanced SIMD element load/store instructions transfer vectors of elements between memory and the AdvancedSIMD register bank.An instruction specifies both the length of the transfer and the size of the data elements beingtransferred. This information is used by the processor to load and store data correctly in both big-endian andlittle-endian systems. 处理器根据提供的信息，能保证在Advanced SIMD register bank 中的数据是一样的，不论它是否是大端，小端Fixme [Figure A3-2 Advanced SIMD byte order example] page113 A3.4 Synchronization and semaphoresIn architecture versions before ARMv6, support for the synchronization of shared memory depends on the SWP andSWPB instructions.These are read-locked-write operations that swap register contents with memory, and aredescribed in SWP, SWPB on page A8-722. These instructions support basic busy/free semaphore mechanisms, butdo not support mechanisms that require calculation to be performed on the semaphore between the read and writephases. ARMv7 extends support forthis mechanism, and provides the following synchronization primitives in the ARM and Thumb instruction sets:• Load-Exclusives: — LDREX, see LDREX on page A8-432 — LDREXB, see LDREXB on page A8-434 — LDREXD, see LDREXD on page A8-436 — LDREXH, see LDREXH on page A8-438• Store-Exclusives: — STREX, see STREX on page A8-690 — STREXB, see STREXB on page A8-692 — STREXD, see STREXD on page A8-694 — STREXH, see STREXH on page A8-696• Clear-Exclusive, CLREX, see CLREX on page A8-360. Note• ARM strongly recommends that all software uses the synchronization primitives described in this section,rather than SWP or SWPB. A3.4.1 Exclusive access instructions and Non-shareable memory regionsFor memory regions that do not have the Shareable attribute, the exclusive access instructions rely on a local monitor that tags any address from which the processor executes a Load-Exclusive. Any non-aborted attempt by thesame processor to use a Store-Exclusive to modify any address is guaranteed to clear the tag. A Load-Exclusive performs a load from memory, and:• the executing processor tags the physical memory address for exclusive access• the local monitor of the executing processor transitions to the Exclusive Access state. A Store-Exclusive performs a conditional store to memory, that depends on the state of the local monitor:If the local monitor is in the Exclusive Access state • If the address of the Store-Exclusive is the same as the address that has been tagged in the monitor by an earlier Load-Exclusive, then the store occurs, otherwise it is IMPLEMENTATION DEFINED whether the store occurs. • A status value is returned to a register: — if the store took place the status value is 0 — otherwise, the status value is 1. • The local monitor of the executing processor transitions to the Open Access state.If the local monitor is in the Open Access state • no store takes place • a status value of 1 is returned to a register. • the local monitor remains in the Open Access state. Fixme [Figure A3-3 Local monitor state machine diagram]Page 116 Fixme [Table A3-3 Effect of Exclusive instructions and write operations on the local monitor]Page 116 A3.4.2 Exclusive access instructions and Shareable memory regionsFor memory regions that have the Shareable attribute, exclusive access instructions rely on:• A local monitor for each processor in the system, that tags any address from which the processor executes aLoad-Exclusive. The local monitor can ignore accesses from other processors in the system. • A global monitor that tags a physical address as exclusive access for a particular processor. This tag is usedlater to determine whether a Store-Exclusive to that address that has not been failed by the local monitor canoccur. Any successful write to the tagged address by any other observer in the shareability domain of thememory location is guaranteed to clear the tag. For each processor in the system, the global monitor: — can hold at least one tagged address — maintains a state machine for each tagged address it can hold. Operation of the global monitorA Load-Exclusive from Shareable memory performs a load from memory, and causes the physical address of the access to be tagged as exclusive access for the requesting processor. This access also causes the exclusive access tag to be removed from any other physical address that has been tagged by the requesting processor. The global monitor only supports a single outstanding exclusive access to Shareable memory per processor. ALoad-Exclusive by one processor has no effect on the global monitor state for any other processor. Fixme [Table A3-4 Effect of load/store operations on global monitor for processor(n)] Page120 A3.4.3 Tagging and the size of the tagged memory blockTagged_address = Memory_address[31:a]The value of a in this assignment is IMPLEMENTATION DEFINED, between a minimum value of 3 and a maximumvalue of 11. For example, in an implementation where a is 4, a successful LDREX of address 0x000341B4 gives a tagvalue of bits[31:4] of the address, giving 0x000341B. This means that the four words of memory from 0x000341B0 to0x000341BF are tagged for exclusive access. The size of the tagged memory block is called the Exclusives Reservation Granule. The Exclusives ReservationGranule is IMPLEMENTATION DEFINED in the range 2-512 words:• 2 words in an implementation where a is 3• 512 words in an implementation where a is 11. A3.4.4 Context switch supportAfter a context switch, software must ensure that the local monitor is in the Open Access state. This requires it toeither:• execute a CLREX instruction• execute a dummy STREX to a memory address allocated for this purpose. Note:Using a dummy STREX for this purpose is backwards-compatible with the ARMv6 implementation of theexclusive operations. The CLREX instruction is introduced in ARMv6K. A3.4.5 Load-Exclusive and Store-Exclusive usage restrictionsThe Load-Exclusive and Store-Exclusive instructions are intended to work together, as a pair, for example aLDREX/STREX pair or a LDREXB/STREXB pair. • An implementation of the Load-Exclusive and Store-Exclusive instructions can require that, in any thread ofexecution, the transaction size of a Store-Exclusive is the same as the transaction size of the precedingLoad-Exclusive executed in that thread. • An implementation might clear an exclusive monitor between the LDREX and the STREX, without anyapplication-related cause. Software written for such an implementation must, in any single thread of execution, avoid having any explicit memory accesses, System control register updates, or cache maintenance operations between the LDREX instruction and the associated STREX instruction. • In some implementations, an access to Strongly-ordered or Device memory might clear the exclusivemonitor. Therefore, software must not place a load or a store to Strongly-ordered or Device memory between an LDREX and an STREX in a single thread of execution. • Implementations can benefit from keeping the LDREX and STREX operations close together in a single thread ofexecution. This minimizes the likelihood of the exclusive monitor state being cleared between the LDREXinstruction and the STREX instruction. Therefore, for best performance, ARM strongly recommends a limit of 128 bytes between LDREX and STREX instructions in a single thread of execution. • After taking a Data Abort exception, the state of the exclusive monitors is UNKNOWN. Therefore ARMstrongly recommends that the abort handling software performs a CLREX instruction, or a dummy STREXinstruction, to clear the monitor state. • The effect of a data or unified cache invalidate, cache clean, or cache clean and invalidate instruction on alocal or global exclusive monitor that is in the Exclusive Access state is UNPREDICTABLE. Execution of theinstruction might clear the monitor, or it might leave it in the Exclusive Access state. • For the memory location being accessed by a LoadExcl/StoreExcl pair, if the memory attributes for theLoadExcl instruction differ from the memory attributes for the StoreExcl instruction, behavior isUNPREDICTABLE. A3.4.6 SemaphoresThe Swap (SWP) and Swap Byte (SWPB) instructions must be used with care to ensure that expected behavior isobserved. NoteFrom ARMv6, ARM deprecates use of the Swap and Swap Byte instructions, and strongly recommends that all newsoftware uses the Load-Exclusive and Store-Exclusive synchronization primitives A3.4.7 Synchronization primitives and the memory order modelThe synchronization primitives follow the memory order model of the memory type accessed by the instructions.For this reason:• Portable software for claiming a spin-lock must include a Data Memory Barrier (DMB) operation, performedby a DMB instruction, between claiming the spin-lock and making any access that makes use of the spin-lock.• Portable software for releasing a spin-lock must include a DMB instruction before writing to clear the spin-lock.This requirement applies to software using:• the Load-Exclusive/Store-Exclusive instruction pairs, for example LDREX/STREX• the deprecated synchronization primitives, SWP/SWPB. ISB &gt; DSB &gt; DMB A3.4.8 Use of WFE and SEV instructions by spin-locksARMv7 and ARMv6K provide Wait For Event and Send Event instructions, WFE and SEV, that can assist withreducing power consumption and bus contention caused by processors repeatedly attempting to obtain a spin-lock.These instructions can be used at the application level, but a complete understanding of what they do depends onsystem level understanding of exceptions. A3.5 Memory types and attributes and the memory order modelA3.5.1 Memory typesexclusive memory types:• Normal• Device• Strongly-ordered. A3.5.2 Summary of ARMv7 memory attributesShareabilityApplies only to Normal memory, and to Device memory in an implementation that does not include the Large Physical Address Extension. In an implementation that includes the Large PhysicalAddress Extension, Device memory is always Outer Shareable,When it is possible to assign a shareability attribute to Device memory, ARM deprecates assigningany attribute other than Shareable or Outer Shareable, see Shareable attribute for Device memoryregions on page A3-137Whether an ARMv7 implementation distinguishes between Inner Shareable and Outer Shareablememory is IMPLEMENTATION DEFINED. CacheabilityApplies only to Normal memory, and can be defined independently for Inner and Outer cacheregions. Some cacheability attributes can be complemented by a cache allocation hint. This is anindication to the memory system of whether allocating a value to a cache is likely to improveperformance. Fixme [Table A3-5 Memory attribute summary] page127 A3.5.3 Atomicity in the ARM architectureAtomicity is a feature of memory accesses, described as atomic accesses. The ARM architecture description refersto two types of atomicity, defined in:• Single-copy atomicity• Multi-copy atomicity on page A3-130. Single-copy atomicityIn ARMv7, the single-copy atomic processor accesses are:• All byte accesses.• All halfword accesses to halfword-aligned locations.• All word accesses to word-aligned locations.• Memory accesses caused by a LDREXD/STREXD to a doubleword-aligned location for which the STREXD succeedscause single-copy atomic updates of the doubleword being accessed.NoteThe way to atomically load two 32-bit quantities is to perform a LDREXD/STREXD sequence, reading and writingthe same value, for which the STREXD succeeds, and use the read values Multi-copy atomicityIn a multiprocessing system, writes to a memory location are multi-copy atomic Writes to Normal memory are not multi-copy atomic. (有缓存机制以及SNOOP等)All writes to Device and Strongly-ordered memory that are single-copy atomic are also multi-copy atomic. A3.5.4 Concurrent modification and execution of instructionsThe ARMv7 architecture limits the set of instructions that can be executed by one thread of execution as they arebeing modified by another thread of execution without requiring explicit synchronization. Except for the instructions identified in this section, the effect of the concurrent modification and execution of aninstruction is UNPREDICTABLE. （无条件跳转等命令，不受这个限制） In the Thumb instruction setThe 16-bit encodings of the B, NOP, BKPT, and SVC instructions In the ARM instruction setThe B, BL, NOP, BKPT, SVC, HVC, and SMC instructions. A3.5.5 Normal memoryAccesses to normal memory region are idempotent, meaning that they exhibit the following properties:• read accesses can be repeated with no side-effects• repeated read accesses return the last value written to the resource being read• read accesses can fetch additional memory locations with no side-effects• write accesses can be repeated with no side-effects in the following cases: — if the contents of the location accessed are unchanged between the repeated writes — as the result of an exception, as described in this section• unaligned accesses can be supported• accesses can be merged before accessing the target memory system. Normal memory can be read/write or read-only, and a Normal memory region is defined as being either Shareableor Non-shareable. Non-shareable Normal memoryFor a Normal memory region, the Non-shareable attribute identifies Normal memory that is likely to be accessedonly by a single processor. Shareable, Inner Shareable, and Outer Shareable Normal memoryFor Normal memory, the Shareable and Outer Shareable memory attributes describe Normal memory that isexpected to be accessed by multiple processors or other system masters:• In a VMSA implementation, Normal memory that has the Shareable attribute but not the Outer Shareableattribute assigned is described as having the Inner Shareable attribute.• In a PMSA implementation, no distinction is made between Inner Shareable and Outer Shareable Normalmemory. VMSA: Virtual Memory System ArchitecturePMSA: Protected Memory System Architecture Write-Through Cacheable, Write-Back Cacheable and Non-cacheable Normal memoryThe cacheability attributes provide a mechanism of coherency control with observers that lie outside the shareabilitydomain of a region of memory.• Write-Through Cacheable• Write-Back Cacheable• Non-cacheable. The cacheability attributes provide a mechanism of coherency control with observers that lie outside the shareabilitydomain of a region of memory. In some cases, the use of Write-Through Cacheable or Non-cacheable regions ofmemory might provide a better mechanism for controlling coherency than the use of hardware coherencymechanisms or the use of cache maintenance routines. A3.5.6 Device and Strongly-ordered memoryExamples of memory regions normally marked as being Device or Strongly-ordered memory are Memory-mappedperipherals and I/O locations. Address locations marked as Device or Strongly-ordered are never held in a cache. The architecture permits an Advanced SIMD element or structure load instruction to access bytes in Device orStrongly-ordered memory. The architecture does not permit unaligned accesses to Strongly-ordered or Device memory. Shareable attribute for Device memory regionsIn an implementation that does not include the Large Physical Address Extension, Device memory regions can begiven the Shareable attribute. When a Device memory region is give the Shareable attribute it can also be given theOuter Shareable attribute. This means that a region of Device memory can be described as one of:• Outer Shareable Device memory• Inner Shareable Device memory• Non-shareable Device memory. ARM deprecates the marking of Device memory with a shareability attribute other than Outer Shareable orShareable. This means ARM strongly recommends that Device memory is never assigned a shareability attribute of Non-shareable or Inner Shareable. Device and Strongly-ordered memory shareability, Large Physical Address ExtensionIn an implementation that includes the Large Physical Address Extension, the Long-descriptor translation tableformat does not distinguish between Shareable and Non-shareable Device memory. In an implementation that includes the Large Physical Address Extension and is using the Short-descriptortranslation table format:• An address-based cache maintenance operation for an addresses in a region with the Strongly-ordered orDevice memory type applies to all processors in the same Outer Shareable domain, regardless of anyshareability attributes applied to the region.• Device memory transactions to a single peripheral must not be reordered, regardless of any shareabilityattributes that are applied to the corresponding Device memory region.Any single peripheral has an IMPLEMENTATION DEFINED size of not less than 1KB. A3.5.7 Memory access restrictionsThe following restrictions apply to memory accesses:• For accesses to any two bytes, p and q, that are generated by the same instruction: — The bytes p and q must have the same memory type and shareability attributes — Except for possible differences in the cache allocation hints, ARM deprecates having different cacheability attributes for the bytes p and q. • Unaligned data access on page A3-108 identifies the instructions that can make an unaligned memoryaccess,If such an access is to Device or Strongly-ordered memory then: — if the implementation does not include the Virtualization Extensions, the effect is UNPREDICTABLE — if the implementation includes the Virtualization Extensions, the access generates an Alignment fault • The accesses of an instruction that causes multiple accesses to Device or Strongly-ordered memory must not cross a 4KB address boundary • Any instruction fetch must access only Normal memory. If it accesses Device or Strongly-ordered memory,the result is UNPREDICTABLE. A3.5.8 The effect of the Security ExtensionsThe Security Extensions can be included as part of an ARMv7-A implementation, with a VMSA. They provide twodistinct 4GByte virtual memory spaces:• a Secure virtual memory space• a Non-secure virtual memory space.The Secure virtual memory space is accessed by memory accesses in the Secure state, and the Non-secure virtualmemory space is accessed by memory accesses in the Non-secure state.By providing different virtual memory spaces, the Security Extensions permit memory accesses made from theNon-secure state to be distinguished from those made from the Secure state. A3.6 Access rightsA3.6.1 Processor privilege levels, execution privilege, and access privilegeARMv7 architecture defines different levels of execution privilege:• in Secure state, the privilege levels are PL1 and PL0• in Non-secure state, the privilege levels are PL2, PL1, and PL0. PL0The privilege level of application software, that executes in User mode. Therefore, softwareexecuted in User mode is described as unprivileged software. This software cannot access somefeatures of the architecture. In particular, it cannot change many of the configuration settings.Software executing at PL0 makes only unprivileged memory accesses. PL1Software execution in all modes other than User mode and Hyp mode is at PL1. Normally, operatingsystem software executes at PL1. Software executing at PL1 can access all features of thearchitecture, and can change the configuration settings for those features, except for some featuresadded by the Virtualization Extensions that are only accessible at PL2.NoteIn many implementation models, system software is unaware of the PL2 level of privilege, and ofwhether the implementation includes the Virtualization Extensions.The PL1 modes refers to all the modes other than User mode and Hyp mode.Software executing at PL1 makes privileged memory accesses by default, but can also makeunprivileged accesses. PL2Software executing in Hyp mode executes at PL2.Software executing at PL2 can perform all of the operations accessible at PL1, and can access someadditional functionality.Hyp mode is normally used by a hypervisor, that controls, and can switch between, Guest OSs, thatexecute at PL1. Hyp mode is implemented only as part of the Virtualization Extensions, and only in Non-securestate. This means that:• implementations that do not include the Virtualization Extensions have only two privilegelevels, PL0 and PL1• execution in Secure state has only two privilege levels, PL0 and PL1 A3.8 Memory access orderA3.8.1 Reads and writesThe following can cause memory accesses that are not explicit:• instruction fetches• cache loads and write-backs• translation table walks. ReadsReads are defined as memory operations that have the semantics of a load.The memory accesses of the following instructions are reads:• LDR, LDRB, LDRH, LDRSB, and LDRSH.• LDRT, LDRBT, LDRHT, LDRSBT, and LDRSHT.• LDREX, LDREXB, LDREXD, and LDREXH.• LDM, LDRD, POP, and RFE.• LDC, LDC2, VLDM, VLDR, VLD1, VLD2, VLD3, VLD4, and VPOP.• The return of status values by STREX, STREXB, STREXD, and STREXH.• SWP and SWPB. These instructions are available only in the ARM instruction set.• TBB and TBH. These instructions are available only in the Thumb instruction set.Hardware-accelerated opcode execution by the Jazelle extension can cause a number of reads to occur, accordingto the state of the operand stack and the implementation of the Jazelle hardware acceleration. WritesWrites are defined as memory operations that have the semantics of a store.The memory accesses of the following instructions are Writes:• STR, STRB, and STRH.• STRT, STRBT, and STRHT.• STREX, STREXB, STREXD, and STREXH.• STM, STRD, PUSH, and SRS.• STC, STC2, VPUSH, VSTM, VSTR, VST1, VST2, VST3, and VST4.• SWP and SWPB. These instructions are available only in the ARM instruction set.Hardware-accelerated opcode execution by the Jazelle extension can cause a number of writes to occur, accordingto the state of the operand stack and the implementation of the Jazelle hardware acceleration. Synchronization primitivesSynchronization primitives must ensure correct operation of system semaphores in the memory order model. They are the following instructions:• LDREX, STREX, LDREXB, STREXB, LDREXD, STREXD, LDREXH, STREXH.• SWP, SWPB. From ARMv6, ARM deprecates the use of these instructions. A3.8.3 Memory barriersMemory barrier is the general term applied to an instruction, or sequence of instructions, that forces synchronizationevents by a processor with respect to retiring load/store instructions. The ARM architecture defines a number of memory barriers that provide a range of functionality, including:• ordering of load/store instructions• completion of load/store instructions• context synchronization. In ARMv7 the memory barriers are provided as instructions that are available in the ARM and Thumbinstruction sets, and in ARMv6 the memory barriers are performed by CP15 register writes. The three memorybarriers are:• Data Memory Barrier, see Data Memory Barrier (DMB) on page A3-152• Data Synchronization Barrier, see Data Synchronization Barrier (DSB) on page A3-153• Instruction Synchronization Barrier, see Instruction Synchronization Barrier (ISB) on page A3-153. Data Memory Barrier (DMB)The DMB instruction is a data memory barrier. DMB only affects memory accesses and data and unified cache maintenance operations, It has no effect on the ordering of any other instructions executing on the processor. Data Synchronization Barrier (DSB)The DSB instruction is a special memory barrier, that synchronizes the execution stream with memory accesses. In addition, no instruction that appears in program order after the DSB instruction can execute until the DSB completes. Instruction Synchronization Barrier (ISB)An ISB instruction flushes the pipeline in the processor, so that all instructions that come after the ISB instruction in program order are fetched from cache or memory only after the ISB instruction has completed. Using an ISB ensures that the effects of context-changing operations executed before the ISB are visible to the instructions fetched after the ISB instruction. Examples of context-changing operations that require the insertion of an ISB instruction to ensurethe effects of the operation are visible to instructions fetched after the ISB instruction are:• completed cache, TLB, and branch predictor maintenance operations• changes to system control registers. A3.9 Caches and memory hierarchyA3.9.1 Introduction to cachesA cache is a block of high-speed memory that contains a number of entries, each consisting of:• main memory address information, commonly called a tag• the associated data A3.9.2 Memory hierarchyMemory close to a processor has very low latency, but is limited in size and expensive to implement.To optimize overallperformance, an ARMv7 memory system can include multiple levels of cache in a hierarchical memory system. Fixme[Figure A3-6 Multiple levels of cache in a memory hierarchy] page 157 A3.9.4 Preloading cachesThe ARM architecture provides memory system hints PLD (Preload Data), PLDW (Preload Data with intent to write),and PLI (Preload Instruction) to permit software to communicate the expected use of memory locations to thehardware. A4. The Instruction SetsA4.1 About the instruction setsARMv7 contains two main instruction sets, the ARM and Thumb instruction sets. The ARM and Thumb instruction sets can interwork freely, that is, different procedures can be compiled or assembled to different instruction sets, and still be able to call each other efficiently. ThumbEE is a variant of the Thumb instruction set that is designed as a target for dynamically generated code.However, it cannot interwork freely with the ARM and Thumb instruction sets. The two instruction sets differ in how instructions are encoded:• Thumb instructions are either 16-bit or 32-bit, and are aligned on a two-byte boundary. 16-bit and 32-bitinstructions can be intermixed freely. Many common operations are most efficiently executed using 16-bitinstructions. However: — Most 16-bit instructions can only access the first eight of the ARM core registers, R0-R7. These are called the low registers. A small number of 16-bit instructions can also access the high registers, R8-R15. — Many operations that would require two or more 16-bit instructions can be more efficiently executed with a single 32-bit instruction. — All 32-bit instructions can access all of the ARM core registers, R0-R15. • ARM instructions are always 32-bit, and are aligned on a four-byte boundary A4.1.1 Changing between Thumb state and ARM stateThumb to ARM stateA processor in Thumb state can enter ARM state by executing any of the following instructions: BX, BLX, or an LDR or LDM that loads the PC. ARM to Thumb stateA processor in ARM state can enter Thumb state by executing any of the same instructions. In ARMv7, a processor in ARM state can also enter Thumb state by executing an ADC, ADD, AND, ASR, BIC, EOR, LSL,LSR, MOV, MVN, ORR, ROR, RRX, RSB, RSC, SBC, or SUB instruction that has the PC as destination register and does not set the condition flags. othersThe target instruction set is either encoded directly in the instruction (for the immediate offset version of BLX), or isheld as bit[0] of an interworking address. For details, see the description of the BXWritePC() function in Pseudocodedetails of operations on ARM core registers on page A2-47.bit[0] 1 thumb thumb is 2 bytes boundary but ARM some support Jazella extensionbit[1:0] 00 arm arm is 4 bytes boundarybit[1:0] 10 unknown Exception entries and returns can also change between ARM and Thumb states. For details see Exception handlingon page B1-1165. A4.1.2 Conditional executionIn the ARM and Thumb instruction sets, most instructions can be conditionally executed In the ARM instruction set, has its normal effect on the programmers’ model operation, memory and coprocessors if the N, Z, C and V condition flags in the APSR satisfy. If the flags do not satisfy this condition, the instruction acts as a NOP. In the Thumb instruction set, different mechanisms control conditional execution:• For the following Thumb encodings, conditional execution is controlled in a similar way to the ARMinstructions: — A 16-bit conditional branch instruction encoding, with a branch range of –256 to +254 bytes. Before ARMv6T2, this was the only mechanism for conditional execution in Thumb code. — A 32-bit conditional branch instruction encoding, with a branch range of approximately ±1MB. • The CBZ and CBNZ instructions, Compare and Branch on Zero and Compare and Branch on Nonzero, are 16-bitconditional instructions with a branch range of +4 to +130 bytes. • The 16-bit If-Then instruction makes up to four following instructions conditional, and can make most otherThumb instructions conditional. For details see IT on page A8-390. A4.3 Branch instructionsFixme [Table A4-1 Branch instructions] Page164 A4.4 Data-processing instructionsA4.4.1 Standard data-processing instructionsFixme [Table A4-2 Standard data-processing instructions] Page166 A4.4.2 Shift instructionsFixme [Table A4-3 Shift instructions] Page167 A4.4.3 Multiply instructionsThese instructions can operate on signed or unsigned quantities. In some types of operation, the results are samewhether the operands are signed or unsigned. Fixme [Table A4-4 General multiply instructions] Page167 Fixme [Table A4-5 Signed multiply instructions] Page168 Fixme [Table A4-6 Unsigned multiply instructions] Page168 A4.4.4 Saturating instructions饱和指令： 将超出unsigned, signed 的值限制到本身支持的最大值或最小值 A4.4.5 Saturating addition and subtraction instructionsA4.4.6 Packing and unpacking instructions扩展指令： 将[半]字节扩展到[有/无]32位 A4.4.7 Parallel addition and subtraction instructionsThese instructions perform additions and subtractions on the values of two registers and write the result to adestination register, treating the register values as sets of two halfwords or four bytes. That is, they perform SIMDadditions or subtractions on the registers. A4.4.8 Divide instructionsFor descriptions of the instructions see:• SDIV on page A8-600• UDIV on page A8-760 In the ARMv7-R profile, the SCTLR.DZ bit enables divide by zero fault detection:SCTLR.DZ == 0 Divide-by-zero returns a zero result.SCTLR.DZ == 1 SDIV and UDIV generate an Undefined Instruction exception on a divide-by-zero.The SCTLR.DZ bit is cleared to zero on reset A4.4.9 Miscellaneous data-processing instructionsFixme [Table A4-11 Miscellaneous data-processing instructions] page173 A4.5 Status register access instructionsThe MRS and MSR instructions move the contents of the Application Program Status Register (APSR) to or from anARM core register, see:• MRS on page A8-496• MSR (immediate) on page A8-498• MSR (register) on page A8-500. At system level, software can also:• use these instructions to access the SPSR of the current mode• use the CPS instruction to change the CPSR.M field and the CPSR.{A, I, F} interrupt mask bits. A4.6 Load/store instructionsFixme [Table A4-12 Load/store instructions] Page175 A4.7 Load/store multiple instructionsLoad Multiple instructions load a subset, or possibly all, of the ARM core registers from memory.Store Multiple instructions store a subset, or possibly all, of the ARM core registers to memory. Fixme [Table A4-13 Load/store multiple instructions] Page177 A4.8 Miscellaneous instructionsFixme [Table A4-14 Miscellaneous instructions] Page178 A4.9 Exception-generating and exception-handling instructionsThe following instructions are intended specifically to cause a synchronous processor exception to occur:• The SVC instruction generates a Supervisor Call exception. For more information, see Supervisor Call (SVC)exception on page B1-1210.• The Breakpoint instruction BKPT provides software breakpoints. For more information, see About debugevents on page C3-2038.• In a processor that implements the Security Extensions, when executing at PL1 or higher, the SMC instructiongenerates a Secure Monitor Call exception. For more information, see Secure Monitor Call (SMC) exceptionon page B1-1211.• In a processor that implements the Virtualization Extensions, in software executing in a Non-secure PL1mode, the HVC instruction generates a Hypervisor Call exception. For more information, see Hypervisor Call(HVC) exception on page B1-1212. Fixme [Table A4-15 Exception-generating and exception-handling instructions] Page179 A4.10 Coprocessor instructionsThere are three types of instruction for communicating with coprocessors. These permit the processor to:• Initiate a coprocessor data-processing operation. For details see CDP, CDP2 on page A8-358.• Transfer ARM core registers to and from coprocessor registers. For details, see: — MCR, MCR2 on page A8-476 — MCRR, MCRR2 on page A8-478 — MRC, MRC2 on page A8-492 — MRRC, MRRC2 on page A8-494.• Load or store the values of coprocessor registers. For details, see: — LDC, LDC2 (immediate) on page A8-392 — LDC, LDC2 (literal) on page A8-394 — STC, STC2 on page A8-662. A4.11 Advanced SIMD and Floating-point load/store instructionsFixme [Table A4-16 Extension register load/store instructions] Page181Fixme [Table A4-17 Element and structure load/store instructions] Page181 A4.12 Advanced SIMD and Floating-point register transfer instructionsFixme [Table A4-18 Extension register transfer instructions] Page183 A4.13 Advanced SIMD data-processing instructionsAdvanced SIMD data-processing instructions process registers containing vectors of elements of the same typepacked together, enabling the same operation to be performed on multiple items in parallel. Fixme [Figure A4-2 Advanced SIMD instruction operating on 64-bit registers] Page184 A4.13.1 Advanced SIMD parallel addition and subtractionFixme [Table A4-19 Advanced SIMD parallel add and subtract instructions] Page185 A4.13.2 Bitwise Advanced SIMD data-processing instructionsFixme [Table A4-20 Bitwise Advanced SIMD data-processing instructions] Page186 A4.13.3 Advanced SIMD comparison instructionsFixme [Table A4-21 Advanced SIMD comparison instructions] Page186 A4.13.4 Advanced SIMD shift instructionsFixme [Table A4-22 Advanced SIMD shift instructions] Page187 A4.13.5 Advanced SIMD multiply instructionsFixme [Table A4-23 Advanced SIMD multiply instructions] Page188 A4.13.6 Miscellaneous Advanced SIMD data-processing instructionsFixme [Table A4-24 Miscellaneous Advanced SIMD data-processing instructions] Page189 A4.14 Floating-point data-processing instructionFixme [Table A4-25 Floating-point data-processing instructions] Page191 A5. ARM Instruction Set EncodingA5.1 ARM instruction set encodingThe ARM instruction stream is a sequence of word-aligned words. Each ARM instruction is a single 32-bit word inthat stream. The encoding of an ARM instruction is: Fixme [32 bits instruction structure] page194 Fixme [Table A5-1 ARM instruction encoding] page194 A5.1.1 The condition code fieldThis field contains one of the values 0b0000-0b1110, as shown in Table A8-1 on page A8-288.Fixme [Table A8-1 Condition codes]page288 A5.2 Data-processing and miscellaneous instructionsFixme [data process instructions structure]page196 Fixme [Table A5-2 Data-processing and miscellaneous instructions]page196 其余指令可参照此命令，只是op 的不同。 A6. Thumb Instruction Set EncodingA6.1 Thumb instruction set encodingThe Thumb instruction stream is a sequence of halfword-aligned halfwords. Each Thumb instruction is either asingle 16-bit halfword in that stream, or a 32-bit instruction consisting of two consecutive halfwords in that stream.If the value of bits[15:11] of the halfword being decoded is one of the following, the halfword is the first halfwordof a 32-bit instruction:• 0b11101• 0b11110• 0b11111.Otherwise, the halfword is a 16-bit instruction 疑问点：thumb 是16bit 或32bit对齐，那怎么与32 bit的ARM 指令集怎么区分？当ARM 处于ARM state，CPU 将会按照32 bit ARM指令集去取指并执行，反之使用16、32bit 的thumb 指令集解析。 A6.2 16-bit Thumb instruction encodingFixme [16-bit thumb instruction encoding]page223 Fixme [Table A6-1 16-bit Thumb instruction encoding]page223 A6.3 32-bit Thumb instruction encodingFixme [ 32-bit Thumb instruction encoding]page230 Fixme [Table A6-9 32-bit Thumb instruction encoding]page230 A7 Advanced SIMD and Floating-point Instruction Encodingskip A9 The ThumbEE Instruction SetA9.1 About the ThumbEE instruction setIn general, instructions in ThumbEE are identical to Thumb instructions, with the following exceptions:• A small number of instructions are affected by modifications to transitions from ThumbEE state. For moreinformation, see ThumbEE state transitions. • A substantial number of instructions have a null check on the base register before any other operation takesplace, but are identical (or almost identical) in all other respects. For more information, see Null checking onpage A9-1113. • A small number of instructions are modified in additional ways. See Instructions with modifications onpage A9-1113. • Three Thumb instructions, BLX (immediate), 16-bit LDM, and 16-bit STM, are removed in ThumbEE state.The encoding corresponding to BLX (immediate) in Thumb is UNDEFINED in ThumbEE state.16-bit LDM and STM are replaced by new instructions, for details see Additional ThumbEE instructions onpage A9-1123. • Two new 32-bit instructions, ENTERX and LEAVEX, are introduced in both the Thumb instruction set and theThumbEE instruction set. See Additional instructions in Thumb and ThumbEE instruction sets onpage A9-1116. These instructions use previously UNDEFINED encodings. Attempting to execute ThumbEE instructions at PL2 is UNPREDICTABLE. A9.1.1 ThumbEE state transitionsInstruction set state transitions to ThumbEE state can occur implicitly as part of a return from exception, orexplicitly on execution of an ENTERX instruction. Instruction set state transitions from ThumbEE state can only occur due to an exception, or due to a transition toThumb state using the LEAVEX instruction. Return from exception instructions (RFE and SUBS PC, LR, #imm) areUNPREDICTABLE in ThumbEE state. A9.1.2 Null checkingA null check is performed for all load/store instructions when they are executed in ThumbEE state. If the value inthe base register is zero, execution branches to the NullCheck handler at HandlerBase – 4. A9.2 ThumbEE instruction set encodingIn general, instructions in the ThumbEE instruction set are encoded in exactly the same way as Thumb instructionsdescribed in Chapter A6 Thumb Instruction Set Encoding. The differences are as follows:• There are no 16-bit LDM or STM instructions in the ThumbEE instruction set.• The 16-bit encodings used for LDM and STM in the Thumb instruction set are used for different 16-bitinstructions in the ThumbEE instruction set. For details, see 16-bit ThumbEE instructions.• There are two new 32-bit instructions in both Thumb state and ThumbEE state. For details, see Additionalinstructions in Thumb and ThumbEE instruction sets on page A9-1116. A9.2.1 16-bit ThumbEE instructionsFixme [Table A9-2 16-bit ThumbEE instructions]page1115 A9.3 Additional instructions in Thumb and ThumbEE instruction setsOn a processor with the ThumbEE Extension, there are two additional 32-bit instructions, ENTERX and LEAVEX. Theseare available in both Thumb state and ThumbEE state. A9.3.1 ENTERX, LEAVEXENTERX causes a change from Thumb state to ThumbEE state, or has no effect in ThumbEE state.ENTERX is UNDEFINED in Hyp mode.LEAVEX causes a change from ThumbEE state to Thumb state, or has no effect in Thumb state. A8 Instruction DescriptionsA8.2 Standard assembler syntax fieldsThe following assembler syntax fields are standard across all or most instructions: Is an optional field. It specifies the condition under which the instruction is executed. See Conditional execution on page A8-288 for the range of available conditions and their encoding. If is omitted, it defaults to always (AL). Specifies optional assembler qualifiers on the instruction. The following qualifiers are defined: .N Meaning narrow, specifies that the assembler must select a 16-bit encoding for the instruction. If this is not possible, an assembler error is produced. .W Meaning wide, specifies that the assembler must select a 32-bit encoding for the instruction. If this is not possible, an assembler error is produced. A8.3 Conditional executionMost ARM instructions, and most Thumb instructions from ARMv6T2 onwards, can be executed conditionally,based on the values of the APSR condition flags. Fixme [Table A8-1 Condition codes]page288]]></content>
      <categories>
        <category>arm</category>
      </categories>
      <tags>
        <tag>arm</tag>
        <tag>spec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[钱:7步创造终生收入]]></title>
    <url>%2F2019%2F05%2F12%2F%E9%92%B1%EF%BC%9A7%E6%AD%A5%E5%88%9B%E9%80%A0%E7%BB%88%E7%94%9F%E6%94%B6%E5%85%A5%2F</url>
    <content type="text"><![CDATA[托尼·罗宾斯 推荐理财是继健康、家庭、工作之后，我个人认为的第四件人生大事。 为钱工作，你是钱的奴隶，为爱工作，钱是你的奴隶。 你做投资理财，目的不是积累更多的钱，而是自由–为了财务自由、为了心灵自由、为了灵魂自由。 未来唯一确定的事是不确定。 最大的财富不在过去而在未来。 对于我们每个人来说，最大的财富不是金钱，而是激情。感受到生命的激情，才是最大的财富。 你活着不是为了钱，而是要用钱活的更好更幸福。(明确使用钱的目的，而不是刻意仅仅为了赚钱，变成葛朗台) 1. 基本原理弗朗西斯.培根爵士： 钱做仆人很好，钱做主人很糟。 预测是终极力量。 预测前方的路是掌握人生获得财富和成功的最大秘诀。 你必须掌握并利用复利让财富指数化增长的神奇力量。（山顶上的人不是从天上落到山顶上的。） 承诺遵守一个非常简单却十分坚定的存储原则，每一次拿到工资，先从中拿出一部分存储，这就是你首先付给自己最求未来梦想的投资寂静，利用复利让你的储蓄投资不断升值。(最困难的事是下决心行动，之后的事只要坚持就行了。坚持就是最好的策略) 终极目标生命的意义不在于你得到了什么，而在于你给予了什么。 另外，你会对什么充满感激？对谁充满感激？你会对自己一路尽力的那些问题和痛苦充满感激？__如果你有了新的信念，你相信自己生命中发生的每一件事，都是为了服务你，帮助你。 2. 了解游戏规则关键点事投资指数基金，不用再付钱给专业投资者帮你选股了。例如标准普尔公司选择的500只成分股，就已经选择了表现最好的500家上市公司。 2.1. 基金公司的把戏基金公司的套路是设立多只新基金，看哪一只表现好就重点扶持，大力宣传，其他表现不佳的基金全部安乐死。 投资内行都知道，追逐业绩排名很高的基金就像追逐风险一样，最后会落得一场空。但是羊群心里最终导致数百万的家庭的财富毁灭。 投资指数是一个很好的解决之道，但并非最佳策略，你不能把所有的寂静都投到指数基金上。大师的方法是投资多种不同的指数，让投资分散化、多元化。 2.2. 费用问题你需要弄清楚你付的费用是多少。 主动管理型基金收取了我们超高的费用（平均每年超过了3%），我们选择低成本的指数基金就可以把投资费用减少80%。 知识就是力量，但是执行力远远胜过知识的力量。（说一千万遍，不如踏踏实实做一次） 2.3. 收益率你在基金公司看到的广告宣传册上投资收益率是时间加权收益率，而现实世界真实的业绩是资金加权收益率。 3. 实现财务自由3.1. 心态生活重要的不是钱，而是心情。真正的目标是拥有你想要的生活方式，而不是你想要的东西。 奥普拉·温弗瑞： 你都能得到，只是不能一下都能得到。 要给自己增加价值，先给别人增加价值。 生活的关键是，要相信最好的还在后面。 3.2. 减少费用，减少纳税留在你口袋你的钱，才是你赚到的钱。 指数基金并不经常交易个股，而是长期持有这些股票。这样并不会像公墓基金经理每天，每个季度频繁交易，继而产生更多的交易税。 省的钱更多，把多省出来的钱做投资，让你的投资本金更多 赚的钱更多（为别人增加更多价值），把多赚的钱拿去投资，让你的投资本金更多 减少费用和税收，把省下来的钱做投资，让你的投资本金更多。 3.3. 投资策略3.3.1. 风险-收益不对称上行空间（收益）明显大于下行空间（风险），风险-收益不对称。 寻找并利用风险-收益不对称的机会不断的投资。（这种一般是市场的先机，信息或预测等得到） 3.3.2. 资产配置做房地产的人一定知道：地段，地段，还是地段。 做投资，要获得更高的投资收益率，同时又要降低风险，有一句神奇的魔咒是：分散，分散，还是分散。 要成为一个成功的投资者，你必须报投资组合定期再平衡。它能让你的利润最大化，它不能让你每次赢，但是再平衡意味着你赢的次数更多一些。 大多数投资者每年一次或者每年两次进行再平衡。 3.3.3. 粗略的估计方法你的年龄有多大，投资债券的比例就有多大。换句话讲，用100减去你的年龄，就是你可以投资到股票上的资产比例。 例如你现在40岁： 60% 股票基金 —— 风险/成长水桶 40% 债券 —— 安全/安心水桶 3.3.4. 选时投资与其让暴跌吓呆，完全崩溃，不如跟自己的恐惧做斗争，多学学那些咋故事崩溃时期做的很好的大师。 约翰.邓普顿爵士 好的机会来自悲观情绪最严重的时候 巴菲特 在别人都贪婪的时候恐惧，在别人都恐惧的时候贪婪。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[财务自由之路]]></title>
    <url>%2F2019%2F04%2F24%2F%E8%B4%A2%E5%8A%A1%E8%87%AA%E7%94%B1%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[博多·舍费尔 一旦金钱开始流动，它就会快速且大量地流入你的口袋，以至于你很惊讶以前你的钱都藏到哪儿去了。 1. 了解自己乐观主义让你看到实物的积极面，而自信给你一种战胜实物黑暗面的信心。 将自己的事业建立在自己最大的爱好之上。 2. 怎样创造奇迹2.1. 五个层次 意识到对现状的不满，为了改变，采取行动 以解决困难最为目标导向 学习新技能、技巧并起到帮助 与他人打交道时的世界观，许多人带着自身的有色眼镜，将美好的世界扭曲 改变自身认知 （将自己置于不同的角度、身份看待问题） 2.2. 学习持续不断地学习和成长，例如书籍中学到的新词汇，都可能意味着一个新的思想。思想是无价的。 如果有机会结实有趣的人， 一定要好好利用，不要浪费时间在闲聊上，让此人推荐两三本他认为最好的书，并问问为什么觉得这些书好。 将自己看作一个足够重要的人，开始记录关于自己的日记。 讲座也可以有很好的效果。我们的感官接受的刺激越多，获得的学习效果越好。 至少为自己找到一个能模仿的榜样，在以下每个领域找到一个榜样： 健康 关系 财务 人生意义 情感 绝对没有理由听从没有亲身经历过的人给出的建议。 2.3. 勇气 大多数人都高估了自己1年内能做到的事情，也低估了自己10年内能做到的事情。（坚持是最好的策略） 在这个星球上，没有“必胜”， 只有“机会” 立即采取行动，你永远不能为成功最好完美的准备（现在就是开始的最好的时机，什么都不会迟，现在就行动） 2.4. 运气惊人的好运， 通常只是多年准备的结果。 好运的组成成分： 存储资本 识别机会 果断地作出决定并采取行动 2.5. 梦想我们无法预测未来，但是我们能塑造自己的未来。 人在顺境的时候，很容易积极展望未来。 所有你给自己或他人描述的未来，都只是一个童话故事。因此，你最好给自己编织一个美好的童话。当童话故事实现时，你才会生活在美梦里，而不是生活在噩梦里。(给自己描绘一个美梦, 让自己也相信（潜意识的作用），积极展望，努力塑造未来。) 3. 反思为什么不富有你有能力是你的目标成为绝对必须品。 不实现这些目标你无法幸福，一成不变的生活对你是痛苦的，你一定要实现自己的目标，然后你便可以将自己要变得富裕的计划呈现在众人面前。（潜意识的重要性，自我洗脑。:) ） 自我承担责任，不要让别人替你承担责任的情况出现。 许多人将100%看作自己的目标，但是只能做到80%。如果你将110%看作自己的目标，那么做到110%对你来说，就相对轻松一些。 当你为自己设立了极限，你就会设法达到你的极限。 一个付出110%努力，主动摒弃所有的借口必能成功。 将90%精力放在“为什么”， 只将10%的精力放在“怎么做”上。 （90% foucs on Why, 10% focus on How!） 4. 第一个1000万4.1. 愚蠢的债务与明智的债务负有消费债是一种非常危险的行为。我们想要的东西并不等同于我们需要的东西. （最好的并不一定是好的，适合自己的才是对的。） 4.2. 增加收入每个人获得东西都恰好是他值得获得的东西。（收入与你在市场中创造的价值有关, 如果你做的所有人都能做的事情，你将只会获得所有人都有的东西。) 金钱和机遇并不会应需求而产生，而是应能力而产生。 你的付出应该对于别人对你的期望，让你周围的人都感到惊讶吧。 完美意味着停滞不前，你需要的是最求卓越。 4.3. 开源与节流生活的水平是随着收入的增加而提高的。(适当提升，度量的把控) 没有人能仅仅通过挣很多钱就变得富有。 长期以来，有形资产一直都胜过货币资产投资。主要原因就是通货膨胀。你的货币怎么贬值，有形资产就怎么升值 投资不是为了亏钱，而是为了赚钱。 （内心观念的转换，潜意识告诉自己赚钱） 投资公式：100 - &lt;年龄&gt; = &lt;股票、基金最大份额百分比&gt; 经济是有周期的，在经济衰退期投资是最好的时期。 康波周期理论简介 4.4. 财务保障遭遇突如其来的经济变故，我们需要财务保障， 公司也是需要。（备用启动金，保证自己3~6个月暂时没有基本经济压力） 计算基本情况：生活、房租、贷款 =&gt; (2000 + 1500 + 2500) * 6 = 3,6000 (至少有这么多的备用金并平时不动用他)]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arm gicv2]]></title>
    <url>%2F2019%2F04%2F20%2Farm_gic%2F</url>
    <content type="text"><![CDATA[GICv2 ##1. IntroductionAbout the Generic Interrupt Controller architectureThe Generic Interrupt Controller (GIC) architecture defines:• the architectural requirements for handling all interrupt sources for any processor connected to a GIC• a common interrupt controller programming interface applicable to uniprocessor or multiprocessor systems The architecture describes a GIC designed for use with one or more processors that comply with the ARM A and Rarchitecture profiles. The GIC is a centralized resource for supporting and managing interrupts in a system that includes at least oneprocessor. It provides:• registers for managing interrupt sources, interrupt behavior, and interrupt routing to one or more processors• support for: — the ARM architecture Security Extensions — the ARM architecture Virtualization Extensions — enabling, disabling, and generating processor interrupts from hardware (peripheral) interrupt sources — Software-generated Interrupts (SGIs) — interrupt masking and prioritization — uniprocessor and multiprocessor environments — wakeup events in power-management environments. The GIC includes interrupt grouping functionality that supports:• configuring each interrupt as either Group 0 or Group 1• signaling Group 0 interrupts to the target processor using either the IRQ or the FIQ exception request• signaling Group 1 interrupts to the target processor using the IRQ exception request only• a unified scheme for handling the priority of Group 0 and Group 1 interrupts• optional lockdown of the configuration of some Group 0 interrupts. fiq 优先级比 irq 高fiq 模式下寄存器 比 irq 模式多（R8 ~ R12）http://blog.chinaunix.net/attachment/201302/21/28458801_1361445566H9Z3.png 1.2. Security Extensions supportThe ARM processor Security Extensions are an optional extension to the ARMv7-A architecture profile. ARM Security Extensions facilitate the development of secure applications by:• integrating hardware security features into the architecture• providing Secure virtual memory space that is accessed by memory accesses in the Secure state• providing Non-secure virtual memory space that is accessed by memory accesses in the Non-secure state. When a GIC that implements the GIC Security Extensions is connected to a processor that implements the ARMSecurity Extensions:• Group 0(IRQ/FIQ) interrupts are Secure interrupts, and Group 1(IRQ) interrupts are Non-secure interrupts. Processor security state and Secure and Non-secure GIC accesses：• a processor in Non-secure state can make only Non-secure accesses to a GIC• a processor in Secure state can make both Secure and Non-secure accesses to a GIC 1.3. Virtualization supportThe ARM processor Virtualization Extensions are optional extensions to the ARMv7-A architecture profile. The GIC Virtualization Extensions provide mechanisms to minimize the hypervisor overhead of routing interrupts to virtual machines. The processor Virtualization Extensions provide hardware support for virtualizing the Non-secure state of anVMSAv7 implementation. The extensions support system use of a virtual machine monitor, known as thehypervisor, to switch guest operating systems. Whether implemented in a uniprocessor or in a multiprocessor system, the processor Virtualization Extensionssupport running multiple virtual machines on a single processor. The hypervisor can either handle a physical interrupt itself, or generate a corresponding virtual interrupt that is signaled to a virtual machine. It is also possible for the hypervisor to generate virtual interrupts that do not correspond to physical interrupts. 1) physical interrupt =&gt; virtual machine =&gt; virtual interrupt （产生与硬件相应的虚拟中断）2) virtual machine =&gt; virtual interrupt （也可以产生与硬件中断没有关的虚拟中断） 1.4. Terminology （专用名词）1.4.1. Interrupt statesInactive An interrupt that is not active or pending. Pending An interrupt from a source to the GIC that is recognized as asserted in hardware, or generated by software, and is waiting to be serviced by a target processor. Active An interrupt from a source to the GIC that has been acknowledged by a processor, and is being serviced but has not completed. Active and pending A processor is servicing the interrupt and the GIC has a pending interrupt from the samesource. 1.4.2. Interrupt typesPeripheral interrupt Private Peripheral Interrupt (PPI) This is a peripheral interrupt that is specific to a single processor. Shared Peripheral Interrupt (SPI) This is a peripheral interrupt that the Distributor can route to any of a specified combination of processors. Each peripheral interrupt is either: Edge-triggered This is an interrupt that is asserted on detection of a rising edge of an interrupt signal and then, regardless of the state of the signal, remains asserted until it is cleared by the conditions defined by this specification. Level-sensitive This is an interrupt that is asserted whenever the interrupt signal level is active, and deasserted whenever the level is not active. Software-generated interrupt (SGI) This is an interrupt generated by software writing to a GICD_SGIR register in the GIC.The system uses SGIs for interprocessor communication. When an SGI occurs in a multiprocessor implementation, the CPUID field in the Interrupt Acknowledge Register, GICC_IAR, or the Aliased Interrupt Acknowledge Register, GICC_AIAR, identifies the processor that requested the interrupt. __An SGI has edge-triggered properties__. （边缘触发） In an implementation that includes the GIC Virtualization Extensions: • when an SGI occurs, management registers in the GIC virtualization Extensions enable the requesting processor to be reported to the Guest OS, as required by the GIC specifications • by writing to the management registers in the GIC Virtualization Extensions, a hypervisor can generate a virtual interrupt that appears to a virtual machine as an SGI. Virtual interrupt In a GIC that implements the GIC Virtualization Extensions, an interrupt that targets a virtual machine running on a processor, and is typically signaled to the processor by the connected virtual CPU interface. Maintenance interrupt In a GIC that implements the GIC Virtualization Extensions, a level-sensitive interrupt that is used to signal key events, such as a particular group of interrupts becoming enabled or disabled. See Maintenance interrupts on page 5-164 for more information. 1.4.3. Models for handling interrupts1-N model 常规硬件中断，单个的SPI， PPI Only one processor handles this interrupt. The system must implement a mechanism to determine which processor handles an interrupt that is programmed to target more than one processor. N-N model 主要SGI， SPI可能会出现 All processors receive the interrupt independently. When a processor acknowledges the interrupt, the interrupt pending state is cleared only for that processor. The interrupt remains pending for the other processors. 1.4.4. Spurious interrupts （假的中断）It is possible that an interrupt that the GIC has signaled to a processor is no longer required.If this happens, whenthe processor acknowledges the interrupt, the GIC returns a special Interrupt ID(1020 ~ 1023) that identifies the interrupt as aspurious interrupt. Example reasons for spurious interrupts are:• prior to the processor acknowledging an interrupt:— software changes the priority of the interrupt— software disables the interrupt— software changes the processor that the interrupt targets• for a 1-N interrupt, another target processor has previously acknowledged that interrupt. 2. GIC Partitioning2.1 About GIC partitioningThe GIC architecture splits logically into a Distributor block and one or more CPU interface blocks. The GICVirtualization Extensions add one or more virtual CPU interfaces to the GIC. GIC 架构有1个GIC Distributor, 一个或多个CPU Interface， 一个或多个virtual CPU interface（GIC Virtualization Extensions support） Distributor The Distributor block performs interrupt prioritization and distribution to the CPU interface blocks that connect to the processors in the system. The Distributor block registers are identified by the GICD_ prefix. CPU interfaces Each CPU interface block performs priority masking and preemption handling for a connected processor in the system. When describing a GIC that includes the GIC Virtualization Extensions, a CPU interface is sometimes called a physical CPU interface, to avoid possible confusion with a virtual CPU interface. CPU interface block registers are identified by the GICC_ prefix. Virtual CPU interfaces Each virtual CPU interface is partitioned into the following blocks: Virtual interface control The main component of the virtual interface control block is the GIC virtual interface control registers, that include a list of active and pending virtual interrupts for the current virtual machine on the connected processor. Typically, these registers are managed by the hypervisor that is running on that processor. Virtual interface control block registers are identified by the GICH_ prefix. Virtual CPU interface Each virtual CPU interface block provides physical signaling of virtual interrupts to the connected processor. The ARM processor Virtualization Extensions signal these interrupts to the current virtual machine on that processor. The GIC virtual CPU interface registers, accessed by the virtual machine, provide interrupt control and status information for the virtual interrupts. The format of these registers is similar to the format of the physical CPU interface registers. Virtual CPU interface block registers are identified by the GICV_ prefix. Note: The virtual CPU interface does not support the power management functionality described A GIC can implement up to eight CPU interfaces, numbered from 0-7. In a GIC that implements the GIC Virtualization Extensions, virtual CPU interface numbering corresponds to the CPU interface numbering, so thatCPU interface 0 and virtual CPU interface 0 connect to the same processor. 一个GIC 最多支持8个CPU， 而 physical CPU interface 与virtual CPU interface 个数对应一样多。 FixMe： 补上GIC logical partitioning 2.2. The DistributorThe Distributor provides a programming interface for: • Globally enabling the forwarding of interrupts to the CPU interfaces. • Enabling or disabling each interrupt. • Setting the priority level of each interrupt. • Setting the target processor list of each interrupt. • Setting each peripheral interrupt to be level-sensitive or edge-triggered. • Setting each interrupt as either Group 0 or Group 1. • Forwarding an SGI to one or more target processors.In addition, the Distributor provides: • visibility of the state of each interrupt • a mechanism for software to set or clear the pending state of a peripheral interrupt. 2.2.1 Interrupt IDsGICv2 - The GIC assigns interrupt ID numbers ID0-ID1019 as follows: 具有唯一标示 SPI: 32 ~ 1019 banked interrupt 可重入或重复的中断， 每个CPU 的中断号可相同 PPI: 16 ~ 31 SGI: 0 ~ 15 In any system that implements the ARM Security Extensions, to support a consistent model for message passingbetween processors, ARM strongly recommends that all processors reserve: • ID0-ID7 for Non-secure interrupts • ID8-ID15 for Secure interrupts. Interrupt numbers ID1020-ID1023 are reserved for special purposes, 2.3. CPU interfacesEach CPU interface block provides the interface for a processor that is connected to the GIC. • enabling the signaling of interrupt requests to the processor • acknowledging an interrupt • indicating completion of the processing of an interrupt • setting an interrupt priority mask for the processor • defining the preemption policy for the processor • determining the highest priority pending interrupt for the processor. GCI CPU interfaces是否拉起中断信号给处理器流程Signal interrupt request flow: take the highest priorty pending interrupt(read GICC_HPPIR) -&gt; check interrupt priority mask and the preemption settings -&gt; signal or ignore interrupt request CPU获取中断IDThe processor acknowledges the interrupt request by reading the CPU interface Interrupt Acknowledge Register.This read returns one of: • The ID number of the highest priority pending interrupt, if that interrupt is of sufficient priority for it to be signaled to the processor. This is the normal response to an interrupt acknowledge. • Exceptionally, an ID number that indicates a spurious interrupt(1020 ~ 1023) 中断处理完成后There are two stages to interrupt completion: • priority drop, meaning the priority of the processed interrupt can no longer prevent the signaling of another interrupt to the processor • interrupt deactivation, meaning the Distributor removes the active state of the interrupt. In a GICv1 implementation, these two stages always happen together, when the processor writes to the CPUinterface End of Interrupt register. In a GICv2 implementation, the GICC_CTLR.EOImode bit determines whether: • the two stages happen together, when the processor writes to the CPU interface End of Interrupt register • the two stages are separated, so that: — priority drop happens when the processor writes to the CPU interface End of Interrupt register — interrupt deactivation happens later, when the processor writes to the CPU interface Deactivate Interrupt register. 2.3.1 Interrupt signal bypass, and GICv2 bypass disableIn all GIC implementations, a CPU interface optionally includes interrupt signal bypass, so that, when the signalingof an interrupt by the interface is disabled, a system legacy interrupt signal is passed to the interrupt request inputon the processor, bypassing the GIC functionality.中断信号旁路，主要支援legacy interrupt 不会受到CPU interface disable的影响，GICv2 must also provide disable bits for the interruptsignal bypass operation. FixMe 增加Interrupt signal bypass, GICv1 without Security Extensions 图片 2.3.2 Power management, GIC v2The GICv2 architecture supports wakeup events in implementations that require power management.These signals are available even when both interrupt signaling by the GIC, and interrupt bypass, are disabled. 为软件提供预留或回复状态寄存器the GICC_APRn registers provide support for preserving and restoring state in power-managementapplicationsHowever, to ensure that Non-secure accesses do not interfere with Secure operation, Secure andNon-secure copies of these registers are provided. 3 Interrupt Handling and Prioritization3.1 About interrupt handling and prioritizationInterrupt handling describes: • how the GIC recognizes interrupts • how software can program the GIC to configure and control interrupts • the state machine the GIC maintains for each interrupt on each CPU interface • how the exception model of a processor interacts with the GIC. Prioritization describes: • the configuration and control of interrupt priority • the order of execution of pending interrupts • the determination of when interrupts are visible to a target processor, including: — interrupt priority masking — priority grouping — preemption of an active interrupt. all implementations of the GIC architecture support interrupt grouping. With interrupt grouping: • by default, all interrupts are Group 0 interrupts, and are signaled to a connected processor using the IRQ interrupt request • each interrupt can be configured as Group 1 interrupt, or as a Group 0 interrupt • a CPU interface can be configured to signal Group 0 interrupts to a connected processor using the FIQ interrupt request. 3.1.1 About interrupt handling and prioritization可以参看 1.4.2. Interrupt types节中断类型主要有四种：物理中断：SPI，PPI （可边缘，电平触发）软中断：SGI虚拟中断：virtual interrupt维护中断：maintenance interrupt (电平触发)，用于发送key events(具备virtualization extensions GIC) 参看 1.4.3. Models for handling interrupts 节SGI 使用GIC N-N模型物理中断 SPI，PPI 使用GIC 1-N 模型 3.1.2 Identifying the supported interrupts中断号的分段参看2.2.1 Interrupt IDs节 软件获知enable 中断Software can use the GICD_ISENABLERns to discover what interrupt IDs are supported by the GIC。 GICD_ISENABLER0 provides the Set-enable bits for both: • SGIs, using interrupt IDs 15-0, corresponding to register bits [15:0] • PPIs, using interrupt IDs 31-16, corresponding to register bits [31:16]. The remaining GICD_ISENABLERns, from GICD_ISENABLER1, provide the Set-enable bits for the SPIs,starting at interrupt ID 32. Software discovers the interrupts that are supported by: Reading the GICD_TYPER. The GICD_TYPER.ITLinesNumber field identifies the number of implementedGICD_ISENABLERns, and therefore the maximum number of SPIs that might be supported. （获取supported interrupt 总数） Writing to the GICD_CTLR to disable forwarding of interrupts from the distributor to the CPU interfaces.For more information, see Enabling and disabling the Distributor and CPU interfaces on page 4-77. For each implemented GICD_ISENABLERn, starting with GICD_ISENABLER0: • Writing 0xFFFFFFFF to the GICD_ISENABLERn. • Reading the value of the GICD_ISENABLERn. Bits that read as 1 correspond to supported interrupt IDs. 永久使能中断Software uses the GICD_ICENABLERns to discover the interrupts that are permanently enabled. For eachimplemented GICD_ICENABLERn, starting with GICD_ICENABLER0, software: Writes 0xFFFFFFFF to the GICD_ICENABLERn. This disables all interrupts that can be disabled. Reads the value of the GICD_ICENABLERn. Bits that read as 1 correspond to interrupts that arepermanently enabled. Writes 1 to any GICD_ISENABLERn bits corresponding to interrupts that must be re-enabled. The GIC implements the same number of GICD_ISENABLERns and GICD_ICENABLERns. 3.2 General handling of interrupts中断状态分为：(detail see 3.2.4 Interrupt handling state machine) inactive pending active active and pending Group, security extension 中断参看 3.4 The effect of interrupt grouping on interrupt handlingvirtualization extension 中断处理参看 5 GIC Support for Virtualization. 通用中断处理流程：When the GIC recognizes an interrupt request, it marks its state as pending. Regenerating a pending interrupt doesnot affect the state of the interrupt. The GIC interrupt handling sequence is: The GIC determines the interrupts that are enabled. For each pending interrupt, the GIC determines the targeted processor or processors. For each CPU interface, the Distributor forwards the highest priority pending interrupt that targets thatinterface. Each CPU interface determines whether to signal an interrupt request to its processor, and if required, does so. The processor acknowledges the interrupt, and the GIC returns the interrupt ID and updates the interruptstate. After processing the interrupt, the processor signals End of Interrupt (EOI) to the GIC. In more detail, these steps are as follows: The GIC determines whether each interrupt is enabled. An interrupt that is not enabled has no effect on the GIC. For each enabled interrupt that is pending, the Distributor determines the targeted processor or processors. For each processor, the Distributor determines the highest priority pending interrupt, based on the priority information it holds for each interrupt, and forwards the interrupt to the targeted CPU interfaces. If the distributor is forwarding an interrupt request to a CPU interface, the CPU interface determines whether the interrupt has Sufficient priority to be signaled to the processor. If the interrupt has sufficient priority, the GIC signals an interrupt request to the processor. When a processor takes the interrupt exception, it reads the GICC_IAR of its CPU interface to acknowledge the interrupt. This read returns an Interrupt ID, and for an SGI, the source processor ID, that the processor uses to select the correct interrupt handler. When it recognizes this read, the GIC changes the state of the interrupt as follows: • if the pending state of the interrupt persists when the interrupt becomes active, or if the interrupt is generated again, from pending to active and pending. • otherwise, from pending to active Note: • A level-sensitive peripheral interrupt persists when it is acknowledged by the processor, because the interrupt signal to the GIC remains asserted until the Interrupt Service Routine (ISR) running on the processor accesses the peripheral asserting the signal. • In a multiprocessor implementation, the GIC handles: — PPIs and SGIs using the GIC N-N model, where the acknowledgement of an interrupt by one processor has no effect on the state of the interrupt on other CPU interfaces — SPIs using the GIC 1-N model, where the acknowledgement of an interrupt by one processor removes the pending status of the interrupt on any other targeted processors, see Implications of the 1-N model on page 3-41. • In GICv2, when using a software model with the GICC_CTLR.AckCtl bit set to 0, separate registers are used to manage Group 0 and Group 1 interrupts, as follows: — GICC_IAR, GICC_EOIR, and GICC_HPPIR for Group 0 interrupts — GICC_AIAR, GICC_AEOIR, and GICC_AHPPIR for Group 1 interrupts. ARM deprecates the use of GICC_CTLR.AckCtl, and strongly recommends using a software model where GICC_CTLR.AckCtl is set to 0, see [3.4.3 The effect of interrupt grouping on interrupt acknowledgement] When the processor has completed handling the interrupt, it must signal this completion to the GIC. Asdescribed in [3.2.1 Priority drop and interrupt deactivation], this: (通知GIC， EOI 并改写状态到inactive) • always requires a valid write to an end of interrupt register (EOIR) • might also require a subsequent write to the deactivate interrupt register, GICC_DIR. 写向EOIR 的值是从GICC_IAR 或 GICC_AIAR得到的最近处理的中断号For each CPU interface, the GIC architecture requires the order of the valid writes to an EOIR to be thereverse of the order of the reads from the GICC_IAR or GICC_AIAR, so that each valid EOIR write refersto the most recent interrupt acknowledge. A CPU interface never signals to the connected processor any interrupt that is active and pending. It onlysignals interrupts that are pending and have sufficient priority: • For PPIs and SGIs, the active status of particular interrupt ID is banked between CPU interfaces. This means that if a particular interrupt ID is active or active and pending on a CPU interface, then no interrupt with that same ID is signaled on that CPU interface. • For SPIs, the active status of an interrupt is common to all CPU interfaces. This means that if an interrupt is active or active and pending on one CPU interface then it is not signaled on any CPU interface. 3.2.1 Priority drop and interrupt deactivationWhen a processor completes the processing of an interrupt, it must signal this completion to the GIC. Interruptcompletion requires the following changes to the GIC state: Priority dropPriority drop is the drop in the Running priority that occurs on a valid write to an EOIR, either theGICC_EOIR or the GICC_AEOIR. Interrupt deactivationInterrupt deactivation is the change of the state of an interrupt, either: • from active and pending, to pending • from active, to idle 在GICv1 中Priority drop 与 Interrupt deactivation 是同时的。在GICv2 中可以设定setting GICC_CTLR.EOImode to 1 separates the priority drop and interrupt deactivation operations， and interrupt handling software must: 1. Perform a valid EOIR write, to cause priority drop on the GIC CPU interface. 2. Subsequently, write to the GICC_DIR, to deactivate the interrupt. The GIC architecture specification requires that valid EOIR writes are ordered, so that:• a valid GICC_EOIR write corresponds to the most recently acknowledged interrupt• a valid GICC_AEOIR write corresponds to the most recently acknowledged Group 1 interrupt.• whether a GICC_EOIR write affects Group 0 or Group 1 interrupts depends on both: — the value of the GICC_CTLR. AckCtl bit — if the GIC implements the GIC Security Extensions, whether the write is Secure or Non-secure. Note：In a GICv2 implementation that includes the Security Extensions:• GICC_AEOIR is an alias of the Non-secure copy of GICC_EOIR• GICC_AIAR is an alias of the Non-secure copy of GICC_IAR• GICC_AIAR and GICC_AEOIR are Secure registers, meaning they are accessible only by Secure accesses. 3.2.2 Interrupt controls in the GICInterrupt enablesFor peripheral interrupts, a processor:• enables an interrupt by writing to the appropriate GICD_ISENABLERn bit• disables an interrupt by writing to the appropriate GICD_ICENABLERn bit. Setting and clearing pending state of an interruptFor peripheral interrupts, a processor can:• set the pending state by writing to the appropriate GICD_ISPENDRn bit• clear the pending state by writing to the appropriate GICD_ICPENDRn bit. For a level-sensitive interrupt:• If the hardware signal of an interrupt is asserted when a processor writes to the correspondingGICD_ICPENDRn bit then the write to the register has no effect on the pending state of the interrupt.• If a processor writes a 1 to an GICD_ISPENDRn bit then the corresponding interrupt becomes pendingregardless of the state of the hardwaremore detail see [Control of the pending status of level-sensitive interrupts] For SGIs, the GIC ignores writes to the corresponding GICD_ISPENDRn and GICD_ICPENDRn bits. A processorcannot change the state of a software-generated interrupt by writing to these registers.Typically, an SGI is made pending by writing to the GICD_SGIR. In GICv2, the pending state of SGIs can also be modified directly using theGICD_SPENDSGIRn and GICD_CPENDSGIRn bits. Finding the active or pending state of an interruptA processor can find:• the pending state of an interrupt by reading the corresponding GICD_ISPENDRn or GICD_ICPENDRn bit• the active state of an interrupt by reading the corresponding GICD_ISACTIVERn or GICD_ICACTIVERnbit. In GICv2, the processor that issues the SGI can also be determined by reading thecorresponding GICD_SPENDSGIRn or GICD_CPENDSGIRn bits. Generating an SGIA processor generates an SGI by writing to an GICD_SGIR.The GICD_SGIR includes optimization for:• interrupting only the processor that writes to the GICD_SGIR• interrupting all processors other than the one that writes to the GICD_SGIR. GICD_SGIR 大致包含:• interrupt ID• source processor• target processor. SGIs from different processors use the same interrupt IDs. Therefore, any target processor can receive SGIs withthe same interrupt ID from different processors. Only one interrupt with a specific interrupt ID can be active on a CPU interface at any time. This means that a CPUinterface cannot have two SGIs with the same interrupt ID active at the same time, even if different processors havesignaled SGIs with the same interrupt ID to that processor. On the CPU interface of the target processor, reading the GICC_IAR for an SGI returns both the interrupt ID andthe CPU ID of the processor that generated the interrupt, the source processor for the interrupt.The combination ofinterrupt ID and source CPU ID uniquely identifies the interrupt to the target processor. In a multiprocessor implementation, the interrupt priority of each SGI interrupt ID is defined independently for eachtarget processor。For each CPU interface, all SGIs with a particular interrupt ID that are pending on that interface have the same priority and must be handled serially. 3.2.3 Implications of the 1-N modelwhen the GIC recognizes an interrupt acknowledge from one of the target processors it clears the pending state of the interrupt on all the other targeted processors. A GIC implementation must ensure that any interrupt being handled using the 1-N model is only acknowledged by one CPU interface, and that all other interfaces return a spuriousinterrupt ID. When multiple target processors attempt to acknowledge the interrupt, the following can occur:• A processor reads the GICC_IAR and obtains the interrupt ID of the interrupt to be serviced. Note: (在多核情况下，通过share memory, lock形式，确保只有一个core 处理中断) In GICv1, more than one target processor might have obtained this interrupt ID, if the processors read their GICC_IAR registers at very similar times. The system might require software on the target processors to ensure that only one processor runs its interrupt service routine. A typical mechanism to achieve this is implementing, in shared memory, a lock on the interrupt service routine (ISR). • A processor reads the GICC_IAR and obtains the interrupt ID 1023, indicating a spurious interrupt. The processor can return from its interrupt service routine without writing to its GICC_EOIR.The spurious interrupt ID indicates that the original interrupt is no longer pending, typically because another target processor is handling it. Note • A GICv1 implementation might ensure that only one processor can make a 1-N interrupt active, removing the requirement for a lock on the ISR. This is not required by the architecture, and generic GIC code must not rely on this behavior.（GICv1 不要求在ISR 中lock） • For any processor, if an interrupt is active and pending, the GIC does not signal an interrupt exception request for the interrupt to any processor until the active status is cleared. （如果中断是active且pending 状态，GIC 不会触发此中断给任何processor 直到active 状态清除） 3.2.3 Interrupt handling state machineFixme 【中断状态机】 Transition A1 or A2, add pending stateFor an SGI, occurs if either:• Software writes to a GICD_SGIR that specifies the processor as a target.• Software on the target processor writes to the GICD_SPENDSGIRn bit that corresponds tothe required source processor and interrupt ID For an SPI or PPI, occurs if either:• a peripheral asserts an interrupt request signal• software writes to an GICD_ISPENDRn Transition B1 or B2, remove pending stateFor an SGI, occurs if software on the target processor writes to the relevant bit of theGICD_CPENDSGIRn. 物理中断 电平触发，pending 会一直拉高直到处理 边缘触发，写GICD_ICPENDRn 寄存器清pending 状态 For an SPI or PPI, occurs if either:• the level-sensitive interrupt is pending only because of the assertion of an input signal, andthat signal is deasserted• the interrupt is pending only because of the assertion of an edge-triggered interrupt signal, ora write to an GICD_ISPENDRn, and software writes to the correspondingGICD_ICPENDRn. Transition C, pending to activeIf the interrupt is enabled and of Sufficient priority to be signaled to the processor, occurs whensoftware reads from the GICC_IAR. Transition D, pending to active and pendingFor an SGI, this transition occurs in either of the following circumstances:• If a write to set the SGI state to pending occurs at approximately the same time as a read ofGICC_IAR.• When two or more pending SGIs with the same interrupt ID originate from the same sourceprocessor and target the same processor. If one of the SGIs follows transition C, the otherSGIs follow transition D For an SPI or PPI this transition occurs if all the following apply:• The interrupt is enabled.• Software reads from the GICC_IAR. This read adds the active state to the interrupt.• In addition, one of the following conditions applies: — For a level-sensitive interrupt, the interrupt signal remains asserted. This is usually the case, because the peripheral does not deassert the interrupt until the processor has serviced the interrupt. — For an edge-triggered interrupt, whether this transition occurs depends on the timing of the read of the GICC_IAR relative to the detection of the reassertion of the interrupt. Otherwise the read of the GICC_IAR causes transition C, possibly followed by transition A2. Transition E1 or E2, remove active stateOccurs when software deactivates an interrupt by writing to either GICC_EOIR or GICC_DIR.In a GICimplementation the includes the Virtualization Extensions, also occurs if the virtual CPU interfacesignals that the corresponding physical interrupt has been deactivated 3.3 Interrupt prioritizationSoftware configures interrupt prioritization in the GIC by assigning a priority value to each interrupt source. Priorityvalues are 8-bit unsigned binary.A GIC supports a minimum of 16 and a maximum of 256 priority levels. If theGIC implements fewer than 256 priority levels, low-order bits of the priority fields are RAZ/WI.In the GIC prioritization scheme, lower numbers have higher priority, Implemented priority bits Possible priority field values Number of priority levels [7:0] 0x00-0xFF (0-255), all values 256 [7:1] 0x00-0xFE, (0-254), even values only 128 [7:2] 0x00-0xFC (0-252), in steps of 4 64 [7:3] 0x00-0xF8 (0-248), in steps of 8 32 [7:4] 0x00-0xF0 (0-240), in steps of 16 16 The GICD_IPRIORITYRn registers hold the priority value for each supported interrupt. To determine the number of priority bits implemented, software can write 0xFF to a writable GICD_IPRIORITYRnpriority field, and read back the value stored.Note:ARM recommends that, before checking the priority range in this way:• for a peripheral interrupt, software first disables the interrupt• for an SGI, software first checks that the interrupt is inactive 3.3.1 PreemptionA CPU interface supports signaling of higher priority pending interrupts to a target processor before an activeinterrupt completes. A pending interrupt is only signaled if both:• Its priority is higher than the priority mask for that CPU interface, see [Priority masking].• Its group priority is higher than that of the Running priority on the CPU interface, see [Priority grouping] and[Running Priority Register, GICC_RPR] For a processor that complies with the ARM architecture: — The value of the I or F bit in the CPSR determines whether the processor responds to the signaled interrupt by starting the interrupt acknowledge procedure. — When processing a preempting interrupt, the processor must save and later restore the context of the previously active ISR. 3.3.2 Priority maskingCPU Interface 选择高于中断阀门优先级的中断給处理器。The GICC_PMR for a CPU interface defines a priority threshold.The GIC only signalspending interrupts with a higher priority than this threshold value to the target processor. A value of zero, the registerreset value, masks all interrupts from being signaled to the associated processor. The GIC does not use prioritygrouping when comparing the priority of a pending interrupt with the priority threshold. 3.3.3 Priority grouping一组相同优先级的中断。Priority grouping uses the Binary Point Register, GICC_BPR, to split a priority value into two fields, the grouppriority and the subpriority.When determining preemption, all interrupts with the same group priority areconsidered to have equal priority, regardless of the subpriority. This means that there can only be one interrupt activeat each group priority. The active group priority is also known as the Preemption level. 主要是用过GICC_BPR 0~2 划分出 GICC_PMR 两个部分：Group priority field 和Subpriority fieldFixME [Table 3-2 Priority grouping by binary point] 图片page 46 3.4 The effect of interrupt grouping on interrupt handlingA GICv1 implementation that includes the GIC Security Extensions, or any GICv2 implementation, provides twointerrupt output signals for IRQ and FIQ exception requests:• The CPU interface always uses the IRQ exception request for Group 1 interrupts• Software can configure the CPU interface to use either IRQ or FIQ exception requests for Group 0 interrupts 3.4.1 GIC interrupt grouping supportThe GICD_IGROUPRn registers configure each interrupt as Group 0 or Group 1. FixMe [CPU interface control of Group 0 and Group 1 interrupts, GICv2] 图片 Page48 In an implementation that includes the GIC Security Extensions, the alias registers:• typically represent aliases of the Non-secure copy of the Group 0 registers, for example GICC_ABPR is analias of the Non-Secure copy of GICC_BPR• are accessible only by Secure accesses. In an implementation that supports interrupt grouping, GICC_CTLR contains additional fields, including fields tocontrol the handling of the grouped interrupts:• Separate enable bits to control the signaling of Group 0 and Group 1 interrupts to the connected processor: （是否支持组中断） — bit[0], the Enable bit in a GIC that does not support interrupt grouping, becomes the EnableGrp0 bit, and controls whether Group 0 interrupts are signaled to the processor — the EnableGrp1 bit is added, to control whether Group 1 interrupts are signaled to the processor.• The FIQEn bit, that controls whether the interface signals Group 0 interrupts to the processor using the IRQor FIQ interrupt request. （Group0 是否支持FIQ）• The CBPR bit, that controls whether GICC_BPR or GICC_ABPR is used when determining possibleinterrupt preemption by Group 1 interrupts, see [Control of preemption by Group 1 interrupts] （是否支持抢占）• The AckCtl bit, that controls whether a read of the GICC_IAR, or the Secure GICC_IAR if the GICimplements the Security Extensions, can acknowledge a Group 1 interrupt.（是否支持Group1 能从GICC_IAR 读取中断ID，value 0 读到1022保留中断号，否则真实值） 3.4.2 Special interrupt numbers when a GIC supports interrupt grouping1020-1021 Reserved. 1022 Used only if the GIC supports interrupt grouping.The GIC returns this value to a processor in response to an interrupt acknowledge only when all ofthe following apply:• the interrupt acknowledge is a read of GICC_IAR• the highest priority pending interrupt is a Group 1 interrupt• GICC_CTLR.AckCtl is set to 0• the priority of the interrupt is sufficient for it to be signaled to the processor. Note: • Interrupt ID 1022 indicates that there is a Group 1 interrupt of sufficient priority to be signaled to the processor, that must be acknowledged by a read of the GICC_AIAR, or in an implementation that includes the GIC Security Extensions, by a read of the Non-secure GICC_IAR. 1023 This value is returned to a processor, in response to an interrupt acknowledge, if there is no pendinginterrupt with sufficient priority for it to be signaled to the processor.On a processor that supports interrupt grouping, values of 1022 and 1023 are spurious interrupt IDs. 3.4.3 The effect of interrupt grouping on interrupt acknowledgementWhen the GICC_CTLR.AckCtl bit is set to 0, to ensure system correctness, every Group 0 interrupt must have a higher priority than any Group 1 interrupt. When the GICC_CTLR.AckCtl bit is set to 1, a read of GICC_IAR acknowledges the highest-priority pendinginterrupt on the CPU interface, regardless of whether it is a Group 0 or a Group 1 interrupt. （ARM 极不推荐GICC_CTLR.AckCtl 设定为1） In a GIC implementation that supports interrupt grouping, ARM strongly recommends setting GICC_CTLR.AckCtlto 0, meaning:• for a GICv2 implementation: — a group 0 interrupt is acknowledged by a read of GICC_IAR, or a Secure read of GICC_IAR if the implementation includes the GIC Security Extensions — a group 1 interrupt is acknowledged by a read of GICC_AIAR, or a Non-secure read of GICC_IAR if the implementation includes the GIC Security Extensions• for a GICv1 implementation: — a group 0 interrupt must be acknowledged by a read of the Secure GICC_IAR — a group 1 interrupt must be acknowledged by a read of Non-secure GICC_IAR. If the Interrupt Acknowledge register access does not correspond to the highest-priority pending interrupt on the CPU interface then:• a read of GICC_IAR when the highest-priority pending interrupt is a Group 1 interrupt returns the spuriousinterrupt value 1022• a read of GICC_AIAR when the highest-priority pending interrupt is a Group 0 interrupt returns the spuriousinterrupt value 1023. 3.4.4 GIC power on or reset configurationOn power-up, or after a reset, a GIC implementation that supports interrupt grouping is configured with:• all interrupts assigned to Group 0• the FIQ exception request disabled. FixMe [Reset configuration of a GIC that includes the FIQ exception request] 图片 page52 3.5 Interrupt grouping and interrupt prioritizationARM strongly recommends that: • Group 0 interrupts are always assigned priority values in the lower half of the supported priority value range. These values correspond to the higher-priority interrupts • Group 1 interrupts are always assigned priority values in the upper half of the supported priority value range. These values correspond to the lower-priority interrupts. This ensures that every Group 1 interrupt is of lower priority than any Group 0 interrupt. 3.5.1 Software views of interrupt priority in a GIC that includes the Security ExtensionsWhen a processor reads the priority value of a Group 1 interrupt, the GIC returns either the Secure or the Non-secureview of that value, depending on whether the access is Secure or Non-secure. This is for a GIC that implements the maximum range of priority values.FixMe [Figure 3-7 Software views of the priorities of Group 1 and Group 0 interrupts]图片 Page55 FixMe [Table 3-6 Effect of not implementing some priority field bits, with GIC Security Extensions]图片 Page56 Recommendations for managing priority valuesARM strongly recommends that:• for a Group 0 interrupt, software sets bit [7] of the priority value field to 0• if using a Secure write to set the priority of a Group 1 interrupt, software sets bit [7] of the priority value fieldto 1. 3.5.2 Control of preemption by Group 1 interruptsWhen a GIC implementation supports interrupt grouping, the GICC_BPR is always used to determine whether aGroup 0 interrupt is signaled to the processor, for possible preemption.By default, the GICC_ABPR is used todetermine whether a Group 1 interrupt is signaled for possible preemption. However, when GICC_CTLR.CBPR is set to 1, GICC_BPR is used for determining possible preemption, for both Group 0 and Group 1 interrupts. Priority grouping for Group 1 interrupts when GICC_CTLR.CBPR==0 情况与 [Priority grouping] 类似 3.6 Additional features of the GIC Security ExtensionsSoftware can detect support for the GIC Security Extensions by reading the GICD_TYPER.SecurityExtn bit, seeInterrupt Controller Type Register, GICD_TYPER on page 4-88. 3.6.1 Access from processors not implementing the ARM Security ExtensionsWhen connecting a processor that does not support the ARM Security Extensions to a GIC that implements the GICSecurity Extensions, typically all processor accesses to the GIC are assigned as either Secure or Non-secure:• For a processor making Secure accesses: — The processor can control all aspects of the GIC, and therefore can make configuration changes that might affect Secure software running on other processors. — In a GICv2 implementation, the processor uses Secure accesses to aliased registers, such as the GICC_AIAR, to process Group 1 interrupts. — Because GICv1 implementations do not include the aliased registers, if the implementation uses interrupt grouping the processor might have to use the deprecated GICC_CTLR.AckCtl bit to enable Group 1 interrupts to be processed using the standard CPU interface registers. • For a processor making Non-secure accesses: — The processor cannot control Group 0 interrupts. For the GIC to be programmed, the system implementation must include at least one processor that can make Secure accesses. A system might use a Secure processor to perform Secure accesses on behalf of a Non-secure processor. This usage model is possible if the GIC or the system provides a method for the Secure processor to access processor-banked copies of registers that belong to the Non-secure processor. — To permit a Non-secure processor to control its own Group 0 interrupts, a GICv2 implementation can implement the GICD_NSACRn registers. An implementation of these registers might permit a Secure processor to permit the use of Non-secure accesses from a particular processor to control some aspects of the operation of some Group 0 SGIs and SPIs. — A GIC implementation can configure the GICD_IGROUPRn reset value so that interrupts are Group 1 on reset. see GICD_IGROUPR0 reset value on page 4-92 for more information 3.7 Pseudocode details of interrupt handling and prioritizationskip, see spec 3.8 The effect of the Virtualization Extensions on interrupt handlingsee Chapter 5 GIC Support for Virtualization 3.9 Example GIC usage modelsFixMe [Figure 3-8 Generic GIC usage model]图片page 68 3.9.1 Using IRQs and FIQs to provide Non-secure and Secure interruptsFixMe [Figure 3-9 Using the GIC to route Secure and Non-secure interrupts]图片page 69 shows a system that implements the GIC Security Extensions, connected to a processor thatimplements the ARM processor Security Extensions. This implementation:• uses Group 0 interrupts as Secure interrupts, signaled as FIQs• uses Group 1 interrupts as Non-secure interrupts, signaled as IRQs.This means that, on the processor, FIQ interrupts are never routed to Non-secure software, and IRQ interrupts arenever routed to Secure software. Note：The use of Group 0 and Group 1 interrupts to signal Secure interrupts as FIQs, and Non-secure interrupts as IRQs,requires the processor to:• route FIQs to be taken in Secure Monitor mode• prevent Non-secure software from masking FIQs• ensure that IRQs are masked whenever it is operating in Secure state. On a GIC reset, all interrupts are assigned to Group 0, making them Secure interrupts. Secure software on theprocessor:• programs the GICD_IGROUPRn registers to indicate which interrupts are Group 1, Non-secure• sets the Secure GICC_CTLR.FIQEn bit to 1 to configure the CPU interface to use FIQ for Group 0 interrupts.• must enable Group 0 interrupts and Group 1 interrupts, independently, in the Distributor: （配置GIC） — GICD_CTLR.EnableGrp0 enables Group 0 interrupts — GICD_CTLR.EnableGrp1 enables Group 1 interrupts.• must enable Group 0 interrupts and Group 1 interrupts, independently, in the CPU interface: （配置CPU Interface） — GICC_CTLR.EnableGrp0 enables Group 0 interrupts — GICC_CTLR.EnableGrp1 enables Group 1 interrupts. 3.9.2 Supporting IRQs and FIQs when not using the processor Security ExtensionsFixMe [Figure 3-10 Using interrupt grouping to route IRQs and FIQs] Page70 On a GIC reset, for a GIC implementation that supports interrupt grouping, all interrupts are assigned to Group 0.Therefore, to use this configuration, software executing on the processor must:• Program the GICD_IGROUPRn registers to assign IRQ interrupts to Group 1.• Set GICC_CTLR.FIQEn to 1, to assign Group 0 interrupts to FIQ.• Set GICC_CTLR.AckCtl to 0, so that both FIQ and IRQ interrupts are acknowledged from the single addressspace, using: — the GICC_IAR to acknowledge a Group 0 interrupt — the GICC_AIAR to acknowledge a Group 1 interrupt — the GICC_EOIR to indicate completion of a Group 0 interrupt — the GICC_AEOIR to indicate completion of a Group 1 interrupt.However, GICC_AIAR and GICC_AEOIR are implemented only in a GICv2 implementation. A processoroperating with a GICv1 implementation might have to use the deprecated mode of operation withGICC_CTLR.AckCtl set to 1(意味着GRP0 GRP1 都是用GICC_IAR, GICC_EOIR).• Configure the required binary point support model, by either: — setting GICC_CTLR.CBPR to 0, so that Group 0 uses GICC_BPR, and Group 1 uses GICC_ABPR — setting GICC_CTLR.CBPR to 1, so that Group 0 and Group 1 use a common binary point register, GICC_BPR. 由于没有security, 我们只是人为的将IRQ 分配到GRP1中，将FIQ 分配到GRP0中。因此，并不需要使能GICD_CTLR.EnableGrp0/1 GICC_CTLR.EnableGrp0/1 来让GIC与CPU 支持真正的Group 即security，我们只是使用不同的寄存器 GICC_IAR &amp;&amp; GICC_AIAR获知ID GICC_EOIR &amp;&amp; GICC_AEOIR 结束中断 GICC_CTLR.CBPR &amp;&amp; GICC_CTLR.ABPR 3.9.3 Supporting IRQs and FIQs in a virtualized processor environmentFixme [Figure 3-11 Using the GIC in a virtualized system] page72 • Secure software assigns: — Secure interrupts to Group 0, signaled to the processor as FIQs — Non-secure interrupts to Group 1, signaled to the processor as IRQs • A hypervisor: — Implements a virtual distributor, using features of the Virtualization Extension on the GIC. This virtual distributor can virtualize IRQ interrupts from the GIC as Virtual IRQ and Virtual FIQ interrupts, that it routes to an appropriate virtual machine. — Routes physical IRQs to Hyp mode, so they can be serviced by the virtual distributor • A Guest OS running on a virtual machine assigns interrupts to Group 0 or Group 1, to assign them as FIQsor IRQs, using the model described in [Supporting IRQs and FIQs when not using the processor SecurityExtensions] When the GIC signals an IRQ to the processor, the interrupt is routed to Hyp mode. The hypervisor determineswhether the interrupt is for itself, or for a Guest OS. If it is for a Guest OS it determines:• which Guest OS must handle the interrupt• whether that Guest OS has configured the interrupt as an FIQ or as an IRQ• the interrupt priority, based on the priority configuration by the target Guest OS. Note: (Guest OS 可能不止一个)• On receiving an IRQ that cannot be handled by the current Guest OS, the hypervisor can either:— transfer control to a Guest OS that can handle the interrupt— mark the interrupt as pending, as part of the saved context of the appropriate Guest OS.• A system can have some interrupts that can be handled by more that one Guest OS, and other interrupts thatmust be routed to a specific Guest OS. A Guest OS handles a virtual interrupt exactly as it would handle the corresponding physical interrupt. The Guest OS cannot detect that it is handling a virtual interrupt rather than a physical interrupt. Guest OS 并不知道处理的是虚拟中断。 4. Programmers’ Model4.1.1 GIC register namesAll of the GIC registers have names that provide a short mnemonic for the function of the register. In these names:• the first three letters are GIC, indicating a GIC register• the fourth letter is one of: — D, indicating a Distributor register — C, indicating a CPU interface register — H, indicating a virtual interface control register, typically accessed by a hypervisor — V, indicating a virtual CPU interface register. Note：Chapter 5 GIC Support for Virtualization describes the GICH_ and GICV_ registers. 4.1.2 Distributor register mapFixme [Table 4-1 Distributor register map] page74 4.1.3 CPU interface register mapFor a multiprocessor implementation, the GIC implements a set of CPU interface registers for each CPU interface.ARM strongly recommends that each processor has the same CPU interface base address for the CPU interface that connects it to the GIC. This is the private CPU interface base address for that processor. Fixme [Table 4-2 CPU interface register map] page76 4.1.4 GIC register accessNote:In the GIC architecture, all registers that are halfword-accessible or byte-accessible use a little endian memory order model. If the GIC implements the GIC Security Extensions these affect register accesses as follows:• some registers are banked, see Register banking• some registers are accessible only using Secure accesses• optionally, the GIC supports lockdown of the values of some registers Register bankingRegister banking refers to providing multiple copies of a register at the same address. The GIC banks registers in the following cases:• If the GIC implements the Security Extensions, some registers are banked to provide separate Secure andNon-secure copies of the registers. The Secure and Non-secure register bit assignments can differ. A Secureaccess to the register address accesses the Secure copy of the register, and a Non-secure access accesses theNon-secure copy. • If the GIC is implemented as part of a multiprocessor system: — Some registers are banked to provide a separate copy for each connected processor. These include the registers associated with PPIs and SGIs, and the GICD_NSACRn, when implemented. — The GIC implements the CPU interface registers independently for each CPU interface, and each connected processor accesses these registers for the interface it connects to. 4.1.5 Enabling and disabling the Distributor and CPU interfacesImplementations that support interrupt groupingIn a GIC that supports interrupt grouping:• the GICD_CTLR.EnableGrp0 bit• the GICD_CTLR.EnableGrp1 bit• the GICC_CTLR.EnableGrp0 bit• the GICC_CTLR.EnableGrp1 bit For the Distributor:• If the GICD_CTLR.EnableGrp0 and GICD_CTLR.EnableGrp1 bits are both 0: — the Distributor does not forward pending interrupts to the CPU interfaces — it is IMPLEMENTATION DEFINED whether an edge-triggered interrupt signal sets the interrupt to the pending state. — reads of GICC_IAR, GICC_AIAR, GICC_HPPIR, or GICC_AHPPIR return a spurious interrupt ID — software can read or write the Distributor registers — it is IMPLEMENTATION DEFINED whether SGIs can be set pending using GICD_SGIR • If either, but not both, of the GICD_CTLR.EnableGrp0 and GICD_CTLR.EnableGrp1 bits is set to — GICD_CTLR.EnableGrp0 set to 0 and GICD_CTLR.EnableGrp1 set to 1, and the highest priority pending interrupt is in group 0 — GICD_CTLR.EnableGrp0 set to 1 and GICD_CTLR.EnableGrp1 set to 0, and the highest priority pending interrupt is in group 1. (ARM 强烈不推荐这样，这样GRP0 优先级是小于GRP1) ARM strongly recommends that all Group 0 interrupts are assigned a higher priority than all Group 1 interrupts. For a CPU interface, when GICC_CTLR.AckCtl == 0:• When GICC_CTLR.EnableGrp0 == 0 — Group 0 interrupts forwarded from the Distributor are not signaled to the processor — any read of GICC_IAR returns a spurious interrupt ID• When GICC_CTLR.EnableGrp0 == 1, Group 0 interrupts forwarded from the Distributor are signaled to theprocessor.• When GICC_CTLR.EnableGrp1 == 0 — Group 1 interrupts forwarded from the Distributor are not signaled to the processor — any read of GICC_AIAR returns a spurious interrupt ID• When GICC_CTLR.EnableGrp1 == 1, Group 1 interrupts forwarded from the Distributor are signaled to theprocessor• if either GICC_CTLR.EnableGrp0 or GICC_CTLR.EnableGrp1 is set to 0, and there is a pending interruptof sufficient priority in the disabled group, it is IMPLEMENTATION DEFINED whether a read of GICC_HPPIRreturns the ID of that interrupt, or a spurious interrupt ID For a CPU interface, when GICC_CTLR.AckCtl == 1:• When GICC_CTLR.EnableGrp1 == 0, any Non-secure read of GICC_IAR returns a spurious interrupt ID• When GICC_CTLR.EnableGrp0 == 0:— if GICC_CTLR.EnableGrp1 == 0, any Secure read of GICC_AIAR returns a spurious interrupt ID— if GICC_CTLR.EnableGrp1 == 1, Group 0 interrupts are ignored and GICC_IAR behaves asGICC_AIAR• When GICC_CTLR.EnableGrp1 == 0, a Secure read of GICC_AIAR always returns a spurious interrupt ID• if either GICC_CTLR.EnableGrp0 or GICC_CTLR.EnableGrp1 is set to 0, and there is a pending interruptof sufficient priority in the disabled group, it is IMPLEMENTATION DEFINED whether a read of GICC_HPPIRreturns the ID of that interrupt, or a spurious interrupt ID. Note:ARM deprecates use of GICC_CTLR.AckCtl, and strongly recommends using a software model where GICC_CTLR.AckCtl is set to 0. Implementations that do not support interrupt groupingIn a GIC that does not support interrupt grouping:• the GICD_CTLR.Enable bit controls the forwarding of interrupts from the Distributor to the CPU interfaces• the GICC_CTLR.Enable bit controls the signaling of interrupts by the CPU interface to the connected processor. For the Distributor:• When GICD_CTLR.Enable is set to 1, the Distributor forwards the highest priority pending interrupt for eachCPU interface, subject to the prioritization rules.• When GICD_CTLR.Enable is set to 0: — the Distributor does not forward pending interrupts to the CPU interfaces — it is IMPLEMENTATION DEFINED whether an edge-triggered interrupt signal sets the interrupt to the pending state. — reads of GICC_IAR, GICC_AIAR, GICC_HPPIR, or GICC_AHPPIR return a spurious interrupt ID — software can read or write the Distributor registers — it is IMPLEMENTATION DEFINED whether SGIs can be set pending using GICD_SGIR. For a CPU interface:• When GICC_CTLR.Enable is set to 1, the highest priority pending interrupt forwarded from the Distributorto the CPU interface is signaled to the connected processor• When GICC_CTLR.Enable is set to 0: — any pending interrupts forwarded from the Distributor are not signaled to the processor — software can read or write the CPU interface registers — any read of the GICC_IAR returns a spurious interrupt ID — if the Distributor is forwarding an interrupt to the CPU interface, that the interface cannot signal because GICC_CTLR.Enable is set to 0, it is IMPLEMENTATION DEFINED whether a read of GICC_HPPIR returns the ID of that interrupt, or a spurious interrupt ID. 4.2 Effect of the GIC Security Extensions on the programmers’ modelIf the GIC implements the Security Extensions, the GICD_TYPER.SecurityExtn bit is RAO.. The GIC Security Extensions provide the following features:• The GIC must support interrupt grouping.• Register implementations that are consistent with those on a processor that implements the ARM SecurityExtensions, with banked. The ARM Architecture Reference Manual, ARMv7-A and ARMv7-R edition defines the following ARM SecurityExtensions register types: Banked The device implements Secure and Non-secure copies of the register. The register bit assignments can differ in the Secure and Non-secure copies of a register. A Secure access always accesses the Secure copy of the register, and a Non-secure access always accesses the Non-secure copy.Note The GIC can also bank registers when implemented as part of a multiprocessor system, where registers associated with PPIs or SGIs are banked to provide a separate copy for each connected processor. Secure The register is accessible only from a Secure access. The address of a Secure register is RAZ/WI to any Non-secure access. Common The register is accessible from both Secure and Non-secure accesses. The access permissions of some or all fields in the register might depend on whether the access is Secure or Non-secure. Register Type Description GICD_CTLR Banked Distributor Control Register GICD_TYPER Common Interrupt Controller Type Register GICD_IGROUPRn Secure Interrupt Group Registers GICD_SGIR Common Software Generated Interrupt Register GICC_CTLR Banked CPU Interface Control Register GICC_BPR Banked Binary Point Register GICC_ABPR Secure Aliased Binary Point Register GICC_AIAR Secure Aliased Interrupt Acknowledge Register GICC_AEOIR Secure Aliased End of Interrupt Register GICC_AHPPIR Secure Aliased Highest Priority Pending Interrupt Register GICC_NSAPRn Secure Non-secure Active Priorities Registers 4.2.1 Non-secure access to register fields for Group 0 interrupt prioritiesNon-secure access to a priority field in the GICD_IPRIORITYRnIf the priority field corresponds to a Group 1 interrupt, the access operates as defined by theNon-secure view of interrupt priority, see[Software views of interrupt priority in a GIC that includesthe Security Extensions] Non-secure access to the GICC_PMR and GICC_RPR• If the current priority mask value is in the range 0x00-0x7F: — a read access returns the value 0x00 — the GIC ignores a write access to the GICC_PMR.• If the current priority mask value is in the range 0x80-0xFF: — A read access returns the Non-secure view of the current value. — A write access to the GICC_PMR succeeds, based on the Non-secure view of the priority mask value written to the register. This means a Non-secure write cannot set a priority mask value in the rage 0x00-0x7F. 4.2.2 Configuration lockdownThis provides a control signal that the system can assert to prevent write access to:• the register fields controlling a configured range of SPIs, when those SPIs are configured as Group 0interrupts• some configuration registers. When the control signal is asserted, the affected register fields and registers are described as being locked down.Lockdown is controlled by an active HIGH disable signal, CFGSDISABLE. That is, the system assertsCFGSDISABLE HIGH to disable write access to the register fields and registers. The SPIs that can be locked down are called lockable SPIs (LSPIs).• The GICD_TYPER.LSPI field defines the maximum number of LSPIs. If GICD_TYPER.LSPI is greaterthan 0 then the possible LSPIs have interrupt IDs 32 to (31+(GICD_TYPER.LSPI)). Note: GICD_TYPER.LSPI only defines the range of possible LSPIs. The GIC might not support all the interrupts in this range. If GICD_TYPER.LSPI is 0 lockdown is not supported. When the SPI control fields and configuration registers are locked down, the GIC prevents write accesses to:• The EnableGrp0 bit of the Secure copy of GICD_CTLR.• The following bits in the Secure copy of GICC_CTLR: — EOImodeS — IRQBypDisGrp0 — FIQBypDisGrp0 — CBPR — FIQEn — AckCtl — EnableGrp0• Fields in the GICD_ISENABLERn, GICD_ICENABLERn, GICD_ISPENDRn, GICD_ICPENDRn,GICD_ISACTIVERn, GICD_ICACTIVERn, GICD_IPRIORITYRn, GICD_ITARGETSRn, andGICD_ICFGRn registers that correspond to Lockable SPIs that are configured as Group 0:• Fields in the GICD_IGROUPRn registers that correspond to lockable SPIs that are configured as Group 0. Ifa lockable SPI is reconfigured from Group 1 to Group 0 while CFGSDISABLE remains HIGH, the GICprevents any more writes to GICD_IGROUPRn fields that correspond to that SPI, and the SPI becomeslocked. 4.3 Distributor register descriptionsThe following sections describe the Distributor registers:• Distributor Control Register, GICD_CTLR on page 4-85• Interrupt Controller Type Register, GICD_TYPER on page 4-88• Distributor Implementer Identification Register, GICD_IIDR on page 4-90• Interrupt Group Registers, GICD_IGROUPRn on page 4-91• Interrupt Set-Enable Registers, GICD_ISENABLERn on page 4-93• Interrupt Clear-Enable Registers, GICD_ICENABLERn on page 4-95• Interrupt Set-Pending Registers, GICD_ISPENDRn on page 4-97• Interrupt Clear-Pending Registers, GICD_ICPENDRn on page 4-99• Interrupt Set-Active Registers, GICD_ISACTIVERn on page 4-102• Interrupt Clear-Active Registers, GICD_ICACTIVERn on page 4-103• Interrupt Priority Registers, GICD_IPRIORITYRn on page 4-104• Interrupt Processor Targets Registers, GICD_ITARGETSRn on page 4-106• Interrupt Configuration Registers, GICD_ICFGRn on page 4-109• Non-secure Access Control Registers, GICD_NSACRn on page 4-111• Software Generated Interrupt Register, GICD_SGIR on page 4-113• SGI Clear-Pending Registers, GICD_CPENDSGIRn on page 4-115• SGI Set-Pending Registers, GICD_SPENDSGIRn on page 4-117• Identification registers on page 4-119. 4.3.1 Distributor Control Register, GICD_CTLREnables the forwarding of pending interrupts from the Distributor to the CPU interfaces. Fixme [Figure 4-1 GICD_CTLR bit assignments, GICv1 without Security Extensions or Non-secure]图片 Page85 Fixme [Figure 4-2 GICD_CTLR bit assignments, GICv2, and GICv1 Secure copy]图片 Page85 4.3.2 Interrupt Controller Type Register, GICD_TYPERProvides information about the configuration of the GIC. It indicates:• whether the GIC implements the Security Extensions• the maximum number of interrupt IDs that the GIC supports• the number of CPU interfaces implemented• if the GIC implements the Security Extensions, the maximum number of implemented Lockable Shared Peripheral Interrupts (LSPIs). Fixme [Figure 4-3 GICD_TYPER bit assignments] 图片Page88 [15:11] LSPI If the GIC implements the Security Extensions, the value of this field is the maximum number of implemented lockable SPIs, from 0 (0b00000) to 31 (0b11111). If this field is 0b00000 then the GIC does not implement configuration lockdown. If the GIC does not implement the Security Extensions, this field is reserved. [10] SecurityExtn Indicates whether the GIC implements the Security Extensions. 0 Security Extensions not implemented. 1 Security Extensions implemented. [7:5] CPUNumber Indicates the number of implemented CPU interfaces. The number of implemented CPU interfaces is one more than the value of this field, for example if this field is 0b011, there are four CPU interfaces. If the GIC implements the Virtualization Extensions, this is also the number of virtual CPU interfaces [4:0] ITLinesNumber Indicates the maximum number of interrupts that the GIC supports.If ITLinesNumber=N, the maximum number of interrupts is 32 * (N+1). interrupt IDs 1020-1023 are reserved for special purposes The ITLinesNumber field only indicates the maximum number of SPIs that the GIC might support. This valuedetermines the number of implemented interrupt registers, that is, the number of instances of the following registers:• GICD_IGROUPRn• GICD_ISENABLERn• GICD_ICENABLERn• GICD_ISPENDRn• GICD_ICPENDRn• GICD_ISACTIVERn• GICD_IPRIORITYRn• GICD_ITARGETSRn• GICD_ICFGRn. 4.3.3 Distributor Implementer Identification Register, GICD_IIDRProvides information about the implementer and revision of the Distributor.主要用于记录GIC 的产品ID， 变体ID， 实现公司IDFixme [Figure 4-4 GICD_IIDR bit assignments] 图片Page90 4.3.4 Interrupt Group Registers, GICD_IGROUPRnThe GICD_IGROUPR registers provide a status bit for each interrupt supported by the GIC.Each bit controls whether the corresponding interrupt is in Group 0 or Group 1.Fixme [Figure 4-5 GICD_IGROUPR bit assignments] 图片Page91 [31:0] Group status bits， For each bit: 0 The corresponding interrupt is Group 0. 1 The corresponding interrupt is Group 1. Reset ValueOn start-up or reset, each interrupt with ID32 or higher resets as Group 0 and therefore all SPIs are Group 0. 4.3.5 Interrupt Set-Enable Registers, GICD_ISENABLERnThe GICD_ISENABLERs provide a Set-enable bit for each interrupt supported by the GIC.Writing 1 to a Set-enable bit enables forwarding of the corresponding interrupt from theDistributor to the CPU interfaces. Reading a bit identifies whether the interrupt is enabled. These registers are available in all configurations of the GIC. If the GIC implements theSecurity Extensions these registers are Common In a multiprocessor implementation, GICD_ISENABLER0 is banked for each connectedprocessor. This register holds the Set-enable bits for interrupts 0-31. 4.3.6 Interrupt Clear-Enable Registers, GICD_ICENABLERnThe GICD_ICENABLERs provide a Clear-enable bit for each interrupt supported by theGIC. Writing 1 to a Clear-enable bit disables forwarding of the corresponding interrupt fromthe Distributor to the CPU interfaces. In a multiprocessor implementation, GICD_ICENABLER0 is banked for each connectedprocessor. This register holds the Clear-enable bits for interrupts 0-31. 4.3.7 Interrupt Set-Pending Registers, GICD_ISPENDRnThe GICD_ISPENDRs provide a Set-pending bit for each interrupt supported by the GIC.Writing 1 to a Set-pending bit sets the status of the corresponding peripheral interrupt topending. Reading a bit identifies whether the interrupt is pending. In a multiprocessor implementation, GICD_ISPENDR0 is banked for each connectedprocessor. This register holds the Set-pending bits for interrupts 0-31. For SPIs and PPIsWrites0 Has no effect.1 The effect depends on whether the interrupt is edge-triggered or level-sensitive. Edge-triggeredChanges the status of the corresponding interrupt to:• pending if it was previously inactive• active and pending if it was previously active.Has no effect if the interrupt is already pendinga. Level sensitiveIf the corresponding interrupt is not pendinga, changes the statusof the corresponding interrupt to:• pending if it was previously inactive• active and pending if it was previously active. If the interrupt is already pendinga:• because of a write to the GICD_ISPENDR, the write hasno effect• because the corresponding interrupt signal is asserted, thewrite has no effect on the status of the interrupt, but theinterrupt remains pendinga if the interrupt signal isdeasserted. 4.3.8 Interrupt Clear-Pending Registers, GICD_ICPENDRnThe GICD_ICPENDRs provide a Clear-pending bit for each interrupt supported by the GIC.Writing 1 to a Clear-pending bit clears the pending state of the corresponding peripheralinterrupt. Reading a bit identifies whether the interrupt is pending In a multiprocessor implementation, GICD_ICPENDR0 is banked for each connectedprocessor. This register holds the Clear-pending bits for interrupts 0-31. 4.3.9 Interrupt Set-Active Registers, GICD_ISACTIVERnThe GICD_ISACTIVERs provide a Set-active bit for each interrupt that the GIC supports.Writing to a Set-active bit Activates the corresponding interrupt. These registers are used when preserving and restoring GIC state In a multiprocessor implementation, GICD_ISACTIVER0 is banked for each connectedprocessor. This register holds the Set-active bits for interrupts 0-31. 4.3.10 Interrupt Clear-Active Registers, GICD_ICACTIVERnThe GICD_ICACTIVERs provide a Clear-active bit for each interrupt that the GICsupports. Writing to a Clear-active bit Deactivates the corresponding interrupt. Theseregisters are used when preserving and restoring GIC state. In a multiprocessor implementation, GICD_ICACTIVER0 is banked for each connectedprocessor. This register holds the Clear-active bits for interrupts 0-31. 4.3.11 Interrupt Priority Registers, GICD_IPRIORITYRnThe GICD_IPRIORITYRs provide an 8-bit priority field for each interrupt supported by theGIC. This field stores the priority of the corresponding interrupt. A GIC might implement fewer than eight priority bits, but must implement at least bits [7:4]of each field. In each field, unimplemented bits are RAZ/WI. see [3.3 Interrupt prioritization]我们可以实现CPU Interface 的Group level. In a multiprocessor implementation, GICD_IPRIORITYR0 to GICD_IPRIORITYR7 arebanked for each connected processor. These registers hold the Priority fields for interrupts0-31. Fixme [Figure 4-13 GICD_IPRIORITYR bit assignments] 图片Page104 4.3.12 Interrupt Processor Targets Registers, GICD_ITARGETSRnThe GICD_ITARGETSRs provide an 8-bit CPU targets field for each interrupt supportedby the GIC. This field stores the list of target processors for the interrupt. That is, it holdsthe list of CPU interfaces to which the Distributor forwards the interrupt if it is asserted andhas sufficient priority. In a multiprocessor implementation, GICD_ITARGETSR0 to GICD_ITARGETSR7 arebanked for each connected processor. These registers hold the CPU targets fields forinterrupts 0-31. Fixme [Figure 4-14 GICD_ITARGETSR bit assignments] 图片Page106 Table 4-17 shows how each bit of a CPU targets field targets the interrupt at one of the CPU interfaces.Fixme [Table 4-17 Meaning of CPU targets field bit values] 图片Page107 Software can write to an GICD_ITARGETSR at any time. （对Active无效，对pending 的有效）Any change to a CPU targets field value:• Has no effect on any active interrupt. This means that removing a CPU interface from a targets list does notcancel an active state for that interrupt on that CPU interface.• Has an effect on any pending interrupts. This means: — adding a CPU interface to the target list of a pending interrupt makes that interrupt pending on that CPU interface — removing a CPU interface from the target list of a pending interrupt removes the pending state of that interrupt on that CPU interface• If it applies to an interrupt that is active and pending, does not change the interrupt targets until the activestatus is cleared. 4.3.13 Interrupt Configuration Registers, GICD_ICFGRnThe GICD_ICFGRs provide a 2-bit Int_config field for each interrupt supported by the GIC.This field identifies whether the corresponding interrupt is edge-triggered or level-sensitive. Fixme [Figure 4-15 GICD_ICFGR bit assignments] 图片Page109 For SGIs, Int_config fields are read-only, meaning that GICD_ICFGR0 is read-only.Before changing the value of a programmable Int_config field, software must disable thecorresponding interrupt, otherwise GIC behavior is UNPREDICTABLE. These registers are available in all configurations of the GIC. If the GIC implements theSecurity Extensions these registers are Common.In a multiprocessor implementation, if bit[1] of the Int_config field for any PPI isprogrammable then GICD_ICFGR1 is banked for each connected processor. This registerholds the Int_config fields for the PPIs, interrupts 16-31. BITS Name Function[2F+1:2F] Int_config, field F For Int_config[1], the most significant bit, bit [2F+1], the encoding is: 0 Corresponding interrupt is level-sensitive. 1 Corresponding interrupt is edge-triggered. Int_config[0], the least significant bit, bit [2F], is reserved, but see Table 4-19 for the encoding of this bit on some early implementations of this GIC architecture. For SGIs: Int_config[1] Not programmable, RAO/WI. For PPIs and SPIs: Int_config[1] For SPIs, this bit is programmable.a For PPIs it is IMPLEMENTATION DEFINED whether this bit is programmable. A read of this bit always returns the correct value to indicate whether the corresponding interrupt is level-sensitive or edge-triggered. 4.3.14 Non-secure Access Control Registers, GICD_NSACRnThe GICD_NSACRs enable Secure software to permit Non-secure software on a particularprocessor to create and manage Group 0 interrupts. They provide an access control for eachimplemented interrupt. The GICD_NSACRn registers do not support PPI accesses, meaning that GICD_NSACR0 bits [31:16] areRAZ/WI. Fixme [Figure 4-16 GICD_NSACR bit assignments] 图片Page111 BITS Name Function[2F+1:2F] NS_access, Field F If the corresponding interrupt does not support configurable Non-secure access, the field is RAZ/WI. Otherwise, the field is RW and configures the level of Non-secure access permitted when the interrupt is in Group 0. If the interrupt is in Group 1, this field is ignored. The possible values of the field are: 0b00 No Non-secure access is permitted to fields associated with the corresponding interrupt. 0b01 Non-secure write access is permitted to fields associated with the corresponding interrupt in the GICD_ISPENDRn registers. A Non-secure write access to GICD_SGIR is permitted to generate a Group 0 SGI for the corresponding interrupt. 0b10 Adds Non-secure write access permission to fields associated with the corresponding interrupt in the GICD_ICPENDRn registers. Also adds Non-secure read access permission to fields associated with the corresponding interrupt in the GICD_ISACTIVERn and GICD_ICACTIVERn registers. 0b11 Adds Non-secure read and write access permission to fields associated with the corresponding interrupt in the GICD_ITARGETSRn registers 4.3.15 Software Generated Interrupt Register, GICD_SGIRThis register is available in all configurations of the GIC. If the GIC implements theSecurity Extensions(read GICD_TYPER) this register is Common.The NSATT field, bit [15], is implemented only if the GIC implements the SecurityExtensions. Fixme [Figure 4-17 GICD_SGIR bit assignments] 图片Page113 Bits Name Function[31:26] - reserved.[25:24] TargetListFilter Determines how the distributor must process the requested SGI: 0b00 Forward the interrupt to the CPU interfaces specified in the CPUTargetList fielda. 0b01 Forward the interrupt to all CPU interfaces except that of the processor that requested the interrupt. 0b10 Forward the interrupt only to the CPU interface of the processor that requested the interrupt. 0b11 Reserved.[23:16] CPUTargetList When TargetList Filter = 0b00, defines the CPU interfaces to which the Distributor must forward the interrupt. Each bit of CPUTargetList[7:0] refers to the corresponding CPU interface, for example CPUTargetList[0] corresponds to CPU interface 0. Setting a bit to 1 indicates that the interrupt must be forwarded to the corresponding interface. If this field is 0x00 when TargetListFilter is 0b00, the Distributor does not forward the interrupt to any CPU interface.[15] NSATT Implemented only if the GIC includes the Security Extensions. Specifies the required security value of the SGI: 0 Forward the SGI specified in the SGIINTID field to a specified CPU interface only if the SGI is configured as Group 0 on that interface. 1 Forward the SGI specified in the SGIINTID field to a specified CPU interfaces only if the SGI is configured as Group 1 on that interface. This field is writable only by a Secure access. Any Non-secure write to the GICD_SGIR generates an SGI only if the specified SGI is programmed as Group 1, regardless of the value of bit[15] of the write. See SGI generation when the GIC implements the Security Extensions for more information. Note If GIC does not implement the Security Extensions, this field is reserved.[3:0] SGIINTID The Interrupt ID of the SGI to forward to the specified CPU interfaces. The value of this field is the Interrupt ID, in the range 0-15, for example a value of 0b0011 specifies Interrupt ID 3. SGI generation when the GIC implements the Security ExtensionsIf the GIC implements the Security Extensions, whether an SGI is forwarded to a processor specified in the writeto the GICD_SGIR depends on:• whether the write to the GICD_SGIR is Group 0 (Secure) or Group 1 (Non-secure)• for a Secure write to the GICD_SGIR, the value of the GICD_SGIR.NSATT bit• whether the specified SGI is configured as Group 0 (Secure) or Group 1 (Non-secure) on the targetedprocessor. Fixme [Table 4-22 Truth table for sending an SGI to a target processor] Page 114 4.3.16 SGI Clear-Pending Registers, GICD_CPENDSGIRnThe GICD_CPENDSGIRs provide a clear-pending bit for each supported SGI and sourceprocessor combination. When a processor writes a 1 to a clear-pending bit, the pending stateof the corresponding SGI for the corresponding source processor is removed, and no longertargets the processor performing the write. Note• In a multiprocessor implementation, the processor accessing the register can change the SGI pending status only on the corresponding interface. Changing the pending status of an SGI for one target processor does not affect the status of that SGI on any other processor.• PPIs and SPIs both use the Interrupt Clear-Pending registers, GICD_ICPENDRn These registers are present only in GICv2. The register locations are reserved in GICv1.In a multiprocessor implementation, the GICD_CPENDSGIRn registers are banked for each connected processor. Four SGI Clear-Pending registers are implemented.each register contains eight clear-pending bits for each of four SGIs.In a multiprocessor implementation, the GICD_CPENDSGIRn registers are banked for each connected processor. 一共四个 GICD_CPENDSGIR寄存器，每个寄存器含有四个8 bits，分别代表了四个SGIs。 Fixme [Figure 4-18 GICD_CPENDSGIR bit assignments] Page 115 Bits Name Function[8y+7:8y], for y=0 to 3 SGI x Clear-pending bits For each bit: Reads 0 SGI x from the corresponding processor is not pendinga. 1 SGI x from the corresponding processor is pendinga. Writes 0 Has no effect. 1 Removes the pending state of SGI x for the corresponding processor Note All accesses relate only to SGIs that target the processor making the access. 4.3.17 SGI Set-Pending Registers, GICD_SPENDSGIRnThe GICD_SPENDSGIRn registers provide a set-pending bit for each supported SGI andsource processor combination. When a processor writes a 1 to a set-pending bit, the pendingstate is applied to the corresponding SGI for the corresponding source processor. Fixme [Figure 4-19 GICD_SPENDSGIR bit assignments] page 117 Bits Name Function[8y+7:8y], for y=0 to 3 SGI x Set-pending bits For each bit: Reads 0 SGI x for the corresponding processor is not pendinga. 1 SGI x for the corresponding processor is pendinga. Writes 0 Has no effect. 1 Adds the pending state of SGI x for the corresponding processor, if it is not already pending. If SGI x is already pending for the corresponding processor then the write has no effect. Note All accesses relate only to SGIs that target the processor making the access. 4.3.18 Identification registersThis architecture specification defines offsets 0xFD0-0xFFC in the Distributor register map as a read-onlyidentification register space. Fixme [Table 4-25 The GIC identification register space] page119 Peripheral ID2 Register, ICPIDR2Fixme [Figure 4-20 ICPIDR2 bit assignments] page119 Bits Name Function[7:4] ArchRev Revision field for the GIC architecture. The value of this field depends on the GIC architecture version: • 0x1 for GICv1 • 0x2 for GICv2. 4.4 CPU interface register descriptions4.4.1 CPU Interface Control Register, GICC_CTLREnables the signaling of interrupts by the CPU interface to the connected processor, andprovides additional top-level control of the CPU interface. In a GICv2 implementation, thisincludes control of the end of interrupt (EOI) behavior. 有几种类型的结构：for a GICv1 implementation, for• an implementation that does not include the Security Extensions• the Non-secure copy of the register, in an implementation that includes the Security Extensions.Fixme [Figure 4-22 GICC_CTLR bit assignments, GICv1 without Security Extensions or Non-secure] page 126 a GIC v2 implementation that includes the Security Extensions, for the Non-secure copy of the registerFixme [Figure 4-23 GICC_CTLR bit assignments, GICv2 with Security Extensions, Non-secure copy] page 126 Bits Name Function[9] EOImodeNS Controls the behavior of Non-secure accesses to the GICC_EOIR and GICC_DIR registers: 0 GICC_EOIR has both priority drop and deactivate interrupt functionality. Accesses to the GICC_DIR are UNPREDICTABLE. 1 GICC_EOIR has priority drop functionality only. The GICC_DIR register has deactivate interrupt functionality. [6] IRQBypDisGrp1 When the signaling of IRQs by the CPU interface is disabled, this bit partly controls whether the bypass IRQ signal is signaled to the processor: 0 Bypass IRQ signal is signaled to the processor 1 Bypass IRQ signal is not signaled to the processor. [5] FIQBypDisGrp1 When the signaling of FIQs by the CPU interface is disabled, this bit partly controls whether the bypass FIQ signal is signaled to the processor: 0 Bypass FIQ signal is signaled to the processor 1 Bypass FIQ signal is not signaled to the processor. [0] EnableGrp1 Enable for the signaling of Group 1 interrupts by the CPU interface to the connected processor. 0 Disable signaling of interrupts 1 Enable signaling of interrupts. Note When this bit is set to 0, the CPU interface ignores any pending Group 1 interrupt forwarded to it. When this bit is set to 1, the CPU interface starts to process pending Group 1 interrupts that are forwarded to it. There is a small but finite time required for a change to take effect. Security Extensions, for the Secure copy of the register• a GICv2 implementation, for:— an implementation that does not include the Security Extensions— the Secure copy of the register, in an implementation that includes the Security Extensions• a GICv1 implementation that includes the Security Extensions, for the Secure copy of the register Fixme [Figure 4-24 GICC_CTLR bit assignments, GICv2 without Security Extensions or Secure] page 128 Bits Name Function[10] EOImodeNS Alias of EOImodeNS from the Non-secure copy of this register, see Table 4-30 on page 4-126. In a GICv2 implementation that does not include the Security Extensions, and in a GICv1 implementation, this bit is reserved. [9] EOImodeS Controls the behavior of accesses to GICC_EOIR and GICC_DIR registers. In a GIC implementation that includes the Security Extensions, this control applies only to Secure accesses, and the EOImodeNS bit controls the behavior of Non-secure accesses to these registers: 0 GICC_EOIR has both priority drop and deactivate interrupt functionality. Accesses to the GICC_DIR are UNPREDICTABLE. 1 GICC_EOIR has priority drop functionality only. GICC_DIR has deactivate interrupt functionality. Note This bit is called EOImode in a GIC implementation that does not include the Security Extensions. In a GICv1 implementation, this bit is reserved. [8] IRQBypDisGrp1 Alias of IRQBypDisGrp1 from the Non-secure copy of this register, see Table 4-30 on page 4-126. In a GICv1 implementation, this bit is reserved [7] FIQBypDisGrp1 Alias of FIQBypDisGrp1 from the Non-secure copy of this register, see Table 4-30 on page 4-126. In a GICv1 implementation, this bit is reserved. [6] IRQBypDisGrp0 When the signaling of IRQs by the CPU interface is disabled, this bit partly controls whether the bypass IRQ signal is signaled to the processor: 0 Bypass IRQ signal is signaled to the processor 1 Bypass IRQ signal is not signaled to the processor. In a GICv1 implementation, this bit is reserved. [5] FIQBypDisGrp0 When the signaling of FIQs by the CPU interface is disabled, this bit partly controls whether the bypass FIQ signal is signaled to the processor: 0 Bypass FIQ signal is signaled to the processor 1 Bypass FIQ signal is not signaled to the processor. In a GICv1 implementation, this bit is reserved. [4] CBPR Controls whether the GICC_BPR provides common control to Group 0 and Group 1 interrupts. 0 To determine any preemption, use: • the GICC_BPR for Group 0 interrupts • the GICC_ABPR for Group 1 interrupts. 1 To determine any preemption use the GICC_BPR for both Group 0 and Group 1 interrupts. [3] FIQEn Controls whether the CPU interface signals Group 0 interrupts to a target processor using the FIQ or the IRQ signal. 0 Signal Group 0 interrupts using the IRQ signal. 1 Signal Group 0 interrupts using the FIQ signal. The GIC always signals Group 1 interrupts using the IRQ signal. [2] AckCtl When the highest priority pending interrupt is a Group 1 interrupt, determines both: • whether a read of GICC_IAR acknowledges the interrupt, or returns a spurious interrupt ID • whether a read of GICC_HPPIR returns the ID of the highest priority pending interrupt, or returns a spurious interrupt ID. 0 If the highest priority pending interrupt is a Group 1 interrupt, a read of the GICC_IAR or the GICC_HPPIR returns an Interrupt ID of 1022. A read of the GICC_IAR does not acknowledge the interrupt, and has no effect on the pending status of the interrupt. 1 If the highest priority pending interrupt is a Group 1 interrupt, a read of the GICC_IAR or the GICC_HPPIR returns the Interrupt ID of the Group 1 interrupt. A read of GICC_IAR acknowledges and Activates the interrupt. In a GIC implementation that includes the Security Extensions, this control affects only the behavior of Secure register accesses. For more information, see: • The effect of interrupt grouping on interrupt acknowledgement on page 3-50 • Interrupt grouping and interrupt prioritization on page 3-53 • Behavior of writes to GICC_EOIR, GICv1 with Security Extensions on page 4-139 • Effect of interrupt grouping and the Security Extensions on reads of the GICC_HPPIR on page 4-143. Note ARM deprecates use of GICC_CTLR.AckCtl, and strongly recommends using a software model where GICC_CTLR.AckCtl is set to 0. See Enabling and disabling the Distributor and CPU interfaces on page 4-77 for more information about the effects of setting this bit. [1] EnableGrp1 Enable for the signaling of Group 1 interrupts by the CPU interface to the connected processor: 0 Disable signaling of Group 1 interrupts. 1 Enable signaling of Group 1 interrupts. [0] EnableGrp0 Enable for the signaling of Group 0 interrupts by the CPU interface to the connected processor: 0 Disable signaling of Group 0 interrupts. 1 Enable signaling of Group 0 interrupts. 4.4.2 Interrupt Priority Mask Register, GICC_PMRProvides an interrupt priority filter. Only interrupts with higher priority than the value in this register are signaled to the processor Fixme [Figure 4-25 GICC_PMR bit assignments] page131 4.4.3 Binary Point Register, GICC_BPRThe register defines the point at which the priority value fields split into two parts, the group priority field and the subpriority field. The group priority field is used to determine interrupt preemption. Fixme [Figure 4-26 GICC_BPR bit assignments] page133 see:Table 3-2 Priority grouping by binary pointTable 3-7 Priority grouping for Group 1 interrupts when GICC_CTLR.CBPR==0 4.4.4 Interrupt Acknowledge Register, GICC_IARThe processor reads this register to obtain the interrupt ID of the signaled interrupt. Thisread acts as an acknowledge for the interrupt. When GICC_CTLR.AckCtl is set to 0 in a GICv2 implementation that does not include theSecurity Extensions, if the highest priority pending interrupt is in Group 1, the interrupt ID1022 is returned. Fixme [Figure 4-27 GICC_IAR bit assignments] page135. Bit Name Function[31:13] - Reserved.[12:10] CPUID For SGIs in a multiprocessor implementation, this field identifies the processor that requested the interrupt. It returns the number of the CPU interface that made the request, for example a value of 3 means the request was generated by a write to the GICD_SGIR on CPU interface 3. For all other interrupts this field is RAZ.[9:0] Interrupt ID The interrupt ID. The read returns a spurious interrupt ID of 1023 if any of the following apply:• forwarding of interrupts by the Distributor to the CPU interface is disabled• signaling of interrupts by the CPU interface to the connected processor is disabled• no pending interrupt on the CPU interface has sufficient priority for the interface to signal it to the processor A non-spurious interrupt ID returned by a read of the GICC_IAR is called a valid interrupt ID.When the GIC returns a valid interrupt ID to a read of the GICC_IAR it treats the read as an acknowledge of that interrupt and, as a side-effect of the read, changes the interrupt status from pending to active, or to active and pending if the pending state of the interrupt persists. Note• For compatibility with possible extensions to the GIC architecture specification, ARM recommends thatsoftware preserves the entire register value read from the GICC_IAR, and writes that value back to theGICC_EOIR when it has completed its processing of the interrupt.• Although multiple target processors might attempt to read the GICC_IAR at any time, in GICv2 only oneprocessor can obtain a valid interrupt ID, see Implications of the 1-N model on page 3-41 for moreinformation. Fixme [Table 4-35 Effect of interrupt grouping and the Security Extensions on reads of GICC_IAR]Page136 4.4.5 End of Interrupt Register, GICC_EOIRA processor writes to this register to inform the CPU interface either:• that it has completed the processing of the specified interrupt• in a GICv2 implementation, when the appropriate GICC_CTLR.EOImode bit is setto 1, to indicate that the interface should perform priority drop for the specifiedinterrupt. See Priority drop and interrupt deactivation on page 3-38 for more information. Fixme [Figure 4-28 GICC_EOIR bit assignments]Page138 Fixme [Table 4-36 GICC_EOIR bit assignments]Page138 For every read of a valid Interrupt ID from the GICC_IAR, the connected processor must perform a matching writeto the GICC_EOIR. The value written to the GICC_EOIR must be the interrupt ID read from the GICC_IAR.If a read of the GICC_IAR returns the ID of a spurious interrupt, software does not have to make a correspondingwrite to the GICC_EOIR. If software writes the ID of a spurious interrupt to the GICC_EOIR, the GIC ignores thatwrite. Behavior of writes to GICC_EOIR, GICv2In a GICv2 implementation, when GICC_CTLR.AckCtl is set to 0:• GICC_EOIR is used for processing Group 0 interrupts• GICC_AEOIR is used for processing Group 1 interrupts. In a GICv2 implementation that includes the GIC Security Extensions:• GICC_CTLR.EOImodeS controls the behavior of Secure accesses to GICC_EOIR and GICC_AEOIR• GICC_CTLR.EOImodeNS controls the behavior of Non-secure accesses to GICC_EOIR• when GICC_CTLR.AckCtl is set to 0: — a Non-secure write to GICC_EOIR must correspond to the most recent Non-secure read of GICC_IAR — a Secure write to the GICC_AEOIR must correspond to the most recent Secure read of the GICC_AIAR. 4.4.6 Running Priority Register, GICC_RPRIndicates the Running priority of the CPU interface Fixme [Figure 4-29 GICC_RPR bit assignments] page142 4.4.7 Highest Priority Pending Interrupt Register, GICC_HPPIRIndicates the Interrupt ID, and processor ID if appropriate, of the highest priority pendinginterrupt on the CPU interface. Fixme [Figure 4-30 GICC_HPPIR bit assignments] Page143 Bit Name Description[31:13] - Reserved.[12:10] CPUID On a multiprocessor implementation, if the PENDINTID field returns the ID of an SGI, this field contains the CPUID value for that interrupt. This identifies the processor that generated the interrupt.[9:0] PENDINTID The interrupt ID of the highest priority pending interrupt. See Table 4-42 on page 4-144 for more information about the result of Non-secure reads of the GICC_HPPIR when the GIC implements the Security Extensions. 4.4.8 Aliased Binary Point Register, GICC_ABPR4.4.9 Aliased Interrupt Acknowledge Register, GICC_AIAR4.4.10 Aliased End of Interrupt Register, GICC_AEOIR4.4.11 Aliased Highest Priority Pending Interrupt Register, GICC_AHPPIR与前面对应相似 4.4.12 Active Priorities Registers, GICC_APRn主要用于做电源管理时，保存与恢复。provide support for preserving and restoring the active priority in power-management implementations. Although the format of these registers is IMPLEMENTATION DEFINED:• because GICv2 guarantees the ability to save and restore all GIC state, theGICC_APRn registers must be present in all GIC implementations• in an implementation that includes the GIC Security Extensions, Non-secureaccesses must not affect Secure operation, and the architecture requires that theseregisters are banked, to provide Secure and Non-secure copies of the registers. 4.4.13 Non-secure Active Priorities Registers, GICC_NSAPRnprovide support for preserving and restoring the active priority in power-management implementation. These are separate registers for Group 1 interrupts. 4.4.14 CPU Interface Identification Register, GICC_IIDRProvides information about the implementer and revision of the CPU interface. Fixme [Figure 4-35 GICC_IIDR bit assignments] Page 152 Fixme [Table 4-48 GICC_IIDR bit assignments] Page 152 4.4.15 Deactivate Interrupt Register, GICC_DIRWhen interrupt priority drop is separated from interrupt deactivation, as described inPriority drop and interrupt deactivation on page 3-38, a write to this register deactivates the specified interrupt. Fixme [Figure 4-36 GICC_DIR bit assignments] Page 153 Fixme [Table 4-49 GICC_DIR bit assignments] Page 153 Fixme [Table 4-50 Behavior of GICC_DIR writes] Page 154 5 GIC Support for Virtualization5.1 About implementing a GIC in a system with processor virtualizationAny ARM processor implementation that includes the Virtualization Extensions must also include the Security Extensions. Fixme [Figure 5-1 Implementing the GIC with an ARM processor that supports virtualization] Page159 5.2 Managing the GIC virtual CPU interfaceThe hypervisor, or similar software, manages the GIC virtual interface control registers, consisting of:List registersUsed to define the active and pending virtual interrupts for the virtual CPU interface. The currentvirtual machine accesses these interrupts indirectly, using the virtual CPU interface. Management registersUsed to manage the virtual CPU interface, and to save and restore settings when switching betweenvirtual machines. The hypervisor runs as Non-secure software in Hyp mode. To maintain the 1-N interrupt handling model, a hypervisor might have to migrate an interrupt from one virtual machine to another. When it receives a physical IRQ, the hypervisor determines the required destination of the interrupt and then either:• Processes the interrupt itself, for example if the IRQ is a maintenance interrupt from the virtual CPUinterface. It then deactivates the physical interrupt.• Generates a virtual interrupt. Depending on the interrupt priority and the targeted virtual machine, thehypervisor takes one of the following actions: — If the interrupt is for the current virtual machine, updates the List registers with details of the interrupt, redefining the interrupts that are visible to the current virtual machine. If there is no space in the List registers, it saves the context to memory so the details can be added at a later stage — Records that the interrupt is for a different virtual machine by saving details of the interrupt as part of the hypervisor state associated with that virtual machine. — Switches to a different virtual machine that can handle the interrupt. In doing so it must save the interrupt state for the current virtual machine, using the information in the List registers, and reprogram the List registers, to indicate the interrupt state for the new virtual machine, including the state for the interrupt that has arrived. The virtual machine accesses the GIC virtual CPU interface registers. These registers have the same general formatas the physical CPU interface registers, and, in a typical implementation the virtual machine believes it is accessinga physical CPU interface. When the virtual machine handles a virtual interrupt, it writes to the virtual CPU interface to indicate when it hasfinished this processing. The virtual CPU interface signals this completion to the physical Distributor and thephysical Distributor then deactivates the interrupt. 5.2.1 List registers and virtual interrupt handlinga hypervisor uses List registers to maintain the list of highest priority virtual interrupts. 记录的数据可以超过List registers数量，多余的数据存储在MEM 中。The total number of interrupts that are either pending, active, or active and pending, can exceed the number of List registers available.If this happens, the hypervisor can save one or more active interrupt entries to memory, and later restore them to the List registers，based on their priority。Therefore:• The List registers might not include all active, or active and pending, interrupts. Virtual CPU interfaceaccesses by the virtual machine update the List registers, and normally an EOI request from the virtualmachine deactivates an interrupt in the list. However, the virtual machine can issue an EOI request for aninterrupt before the hypervisor restores the associated active interrupt entry into a List register. In this case,the EOI request cannot update the List registers. • Although the List registers might include only active interrupts, with the hypervisor maintaining any pendinginterrupts in memory, a pending interrupt cannot be signaled to the virtual machine until the hypervisor addsit to the List registers. Therefore, to minimize interrupt latency and ensure efficient virtual machine operation,ARM strongly recommends that the List registers contain at least one pending interrupt, provided a List register is available for this interrupt. 5.2.2 Completion of virtualized physical interruptsARM recommends that, for each CPU interface that corresponds to aprocessor running virtual machines, the GICC_CTLR.EOImodeNS bit is set to 1. This means that hypervisoraccesses to the GICC_AEOIR register drops the running priority of the CPU interface but does not deactivate theinterrupt. After writing to the EOI register, the running priority level on the CPU interface is lower, so thatsubsequent interrupts can be signaled to the processor. ARM recommends that physical interrupt completion consists of the following separate steps: EOI interrupt deactivation. These steps are explained in more detail as follows: After receiving a physical interrupt, the hypervisor performs an EOI request for the physical interrupt bywriting to the GICC_EOIR or GICC_AEOIR register. After EOI, although the virtual machine has notprocessed the virtual interrupt, the lower running priority of the CPU interface means that the hypervisor canstill receive new physical interrupts. Note The only interrupts that are not signaled to the hypervisor are the physical interrupts most recently subject to EOI. This is because the interrupts have not been deactivated. This prevents the interrupts from being re-signaled to the hypervisor before being processed by the virtual machine. After the virtual machine completes processing the corresponding virtual interrupt, it writes to theGICV_EOIR or GICV_AEOIR to deactivate the interrupt. This deactivates both the virtual interrupt and thecorresponding physical interrupt, provided that both of the following conditions are true:• the GICV_CTLR.EOImode bit is set to 0• the GICH_LRn.HW bit is set to 1. Alternatively, if the GICV_CTLR.EOImode bit is set to 1, the virtual machine writes to the GICV_DIRregister to deactivate the interrupt.If the GICH_LRn.HW bit is set to 0, the hypervisor must deactivate the physical interrupt itself. ARMrecommends one of the following methods for deactivating physical SGIs that are routed to a virtual machine:• the hypervisor deactivates the SGI by writing to the GICC_DIR register after the virtual machinewrites to GICC_EOIR• the hypervisor uses an EOI maintenance interrupt to write to the GICC_DIR register after the virtualmachine writes to GICV_EOIR, see Maintenance interrupts on page 5-164 for more information. 处理大致流程： hypervisor 写GICC_AEOIR，让此IRQ 丢掉优先级，能让其他低优先级的中断能被处理 virtual machine 处理完后，virtual cpu 写GICV_EOIR 或 GICV_AEOIR，再写GICV_DIR （依赖GICV_CTLR.EOImode 设定是否自动完成后一步） 在virtual machine 写 GICV_EOIR 后，hypervisor 用 EOI maintenance interrupt 写 GICC_DIR （GICH_LRn.HW 设定为1，自动完成此步） 5.2.3 Acknowledgement and completion of virtual interruptsTo ensure system correctness when handling virtual interrupts, one of the following conditions must be true:• All Group 0 interrupts must have a higher priority than any Group 1 interrupt. That is, there is no overlap inthe priorities allocated to Group 0 and Group 1 interrupts.• The GICV_CTLR.AckCtl bit must be set to 0. ARM deprecates the use of GICC_CTLR.AckCtl and GICV_CTLR.AckCtl, and strongly recommends using a software model where GICC_CTLR.AckCtl and GICV_CTLR.AckCtl are set to 0. 5.2.4 GIC virtual interface control interface requirementsskip 5.2.5 Maintenance interruptsMaintenance interrupts can signal key events in the operation of a GIC that implements the Virtualization Extensions. Typically, these events are processed by the hypervisor. Note• Maintenance interrupts are generated only when the global interrupt enable bit, GICH_HCR.En, is set to 1. Maintenance interrupts are level-sensitive interrupts. Configuration bits in the GICH_HCR can be set to 1 to enablemaintenance interrupt generation when:• Group 0 virtual interrupts are enabled/disabled• Group 1 virtual interrupts are enabled/disabled• There are no pending interrupts in the List registers.• At least one EOI request occurs with no valid List register entry for the corresponding interrupt.• There are no valid entries, or only one valid entry, in the List registers. This is an underflow condition.• At least one List register entry has received an EOI request. 5.2.6 Software-generated interruptsHypervisor-generated interruptsA hypervisor can generate virtual interrupts that do not have a corresponding physical interrupt, bycreating an entry in the List registers with the GICH_LRn.HW bit cleared to 0. The hypervisor cancontrol how the interrupt appears to a virtual machine reading the GICV_IAR or GICV_AIARregister to acknowledge the interrupt, by presenting the interrupt as:• an SGI, with a CPUID value provided in addition to the interrupt ID• a PPI or SPI, with the CPUID value set to 0. The hypervisor can virtualize the CPUID value, but it must be consistent with the type of interruptindicated by the GICH_LRn.VirtualID field. When the EOI notification is sent to the virtual CPUinterface, only the List registers are affected, and no notification is sent to the Distributor. See ListRegisters, GICH_LRn on page 5-176 for more information. hypervisor 可以产生与硬件中断号不一致的虚拟中断，并且可以控制中断在虚拟机中呈现的形式：SGI，PPI，SPI。 Distributor-generated interruptsBecause the hardware interrupt deactivation mechanism does not support SGIs, the hypervisor mustvirtualize SGIs originating from the Distributor in the same way as hypervisor-generated interrupts.The hypervisor can virtualize the GICH_LRn.CPUID field, because this field is not required to bethe same as that of the original SGI. See Completion of virtualized physical interrupts on page 5-161for more information about deactivating virtualized SGIs. 虚拟中断分发器 产生的虚拟机之间的SGIs。 5.2.7 GIC Virtualization Extensions register mappingThe GIC must make these virtual interface control registers accessible in the following ways:Redirection through a common base addressThe memory map includes a common base address for the virtual interface control registers. Eachprocessor in the system can access its own GIC virtual interface control registers through this baseaddress. The CPUID of the processor requesting access redirects the access to the GIC virtualinterface control registers for that processor. Processor-specific base addressesIn addition to the common base address, the memory map contains, for each processor in the system,a processor-specific base address for the GIC virtual interface control registers. Any processor canuse these addresses to access its own GIC virtual interface control registers, or to access the GICvirtual interface control registers of any other processor in the system. Fixme [Figure 5-2 GIC virtual interface control register mappings] page166 5.3 GIC virtual interface control registersFixme [Table 5-1 GIC virtual interface control register map] page167 5.3.1 Hypervisor Control Register, GICH_HCRThis register contains control bits for the virtual CPU interface. Fixme [Figure 5-3 GICH_HCR bit assignments] page168 Fixme [Table 5-2 GICH_HCR bit assignments] page168 Fixme [Table 5-2 GICH_HCR bit assignments] page169 5.3.2 VGIC Type Register, GICH_VTRThis is a read-only register that provides the following information about theimplementation of the GIC Virtualization Extensions:• number of priority levels supported• number of preemption levels supported• number of implemented List registers. Fixme [Figure 5-4 GICH_VTR bit assignments] page170 Fixme [Table 5-3 GICH_VTR bit assignments] page170 5.3.3 Virtual Machine Control Register, GICH_VMCREnables the hypervisor to save and restore the virtual machine view of the GIC state. Fixme [Figure 5-5 GICH_VMCR bit assignments] page171 The GICH_VMCR is a control register that contains read and write aliases of architecture state in the virtualmachine view, enabling the hypervisor to save and restore this state with a single read or write, without accessingthe GIC virtual CPU interface registers individually. 5.3.4 Maintenance Interrupt Status Register, GICH_MISRIndicates which maintenance interrupts are asserted. Fixme [Figure 5-6 GICH_MISR bit assignments] page172 Fixme [Table 5-5 GICH_MISR bit assignments] page172 5.3.5 End of Interrupt Status Registers, GICH_EISR0 and GICH_EISR1When a maintenance interrupt is received, these registers help determine which Listregisters have outstanding EOI interrupts that require servicing. Fixme [Figure 5-7 GICH_EISR0 bit assignments] page173 Fixme [Table 5-6 GICH_EISR0 bit assignments] page173 5.3.6 Empty List Register Status Registers, GICH_ELRSR0 and GICH_ELRSR1These registers can be used to locate a usable List register when the hypervisor is deliveringan interrupt to a Guest OS. Fixme [Figure 5-8 GICH_ELRSR0 bit assignments] page173 Fixme [Table 5-7 GICH_ELRSR0 bit assignments] page173 5.3.7 Active Priorities Register, GICH_APRThis register tracks which preemption levels are active in the virtual CPU interface, and isused to determine the current active priority. Corresponding bits are set in this register whenan interrupt is acknowledged, based on GICH_LRn.Priority, and the least significant set bitis cleared on EOI. Fixme [Figure 5-9 GICH_APR bit assignments] page175 Fixme [Table 5-8 GICH_APR bit assignments] page175 5.3.8 List Registers, GICH_LRnProvides interrupt context information for the virtual CPU interface. A maximum of 64 List registers can be provided. The GICH_VTR.ListRegs bit defines the actual number implemented. Fixme [Figure 5-10 GICH_LR bit assignments] page176 Fixme [Table 5-9 GICH_LR bit assignments] page176 5.4 The virtual CPU interfaceA GIC virtual CPU interface signals virtual interrupts to a connected processor, The GIC virtual CPU interface registers have the same general format as the GIC physical CPU interface registers and expected behavior is that a virtual machine cannot distinguish between them. In particular, the virtual CPU interface uses the contents of the List registers to determine when to signal virtual interrupts. When a processor accesses the virtual CPU interface the List registers are updated.• Virtual interrupts are always handled through the virtual CPU interfaces.• On the connected processor, if the processor is in a Non-secure PL1 or PL0 mode, virtual interrupts aresignaled to the current virtual machine.• In addition, a virtual machine can receive virtual IRQs and virtual FIQs signaled directly by the hypervisor.These exceptions are outside the scope of this specification. A virtual machine cannot distinguish: — A virtual exception signaled by the GIC from a corresponding virtual exception signaled directly by the hypervisor. — A virtual exception from the corresponding physical exception.• A virtual CPU interface does not require power management support, and therefore GICV_CTLR does notimplement the IRQBypDisGrp1, FIQBypDisGrp1, IRQBypDisGrp0, and FIQBypDisGrp0 bits that aresupported by GICC_CTLR 5.5 GIC virtual CPU interface registersTypically, a virtual machine is unaware of any difference between virtual interrupts and physical interrupts. In general, these registers have the same format as the GIC physical CPU interface registers, but they operate on the interrupt view defined primarily by the List registers. These registers are memory-mapped, The offset of each GICV_* register is the same as the offset of the corresponding register for the physical CPU interface. Fixme [Table 5-10 GIC virtual CPU interface register map] page179]]></content>
      <categories>
        <category>arm</category>
      </categories>
      <tags>
        <tag>arm</tag>
        <tag>spec</tag>
        <tag>GICv2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[史蒂夫.乔布斯传]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%8F%B2%E8%92%82%E5%A4%AB-%E4%B9%94%E5%B8%83%E6%96%AF%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[他去印度追寻过佛，热衷于冥想；他创立了苹果，Next，皮克斯公司；他推出了iMac, iPod, iPhone, iPad，iCloud产品;他创建了iTunes, Apple Stores。 史蒂夫·乔布斯传, 是史蒂夫·乔布斯唯一授权的官方传记。 1. 童年我父亲信奉诚实，极端的诚实。那是他教我的最重要的事。 “他拒绝机械的接受事实，任何事情他都要亲自检验。” (辩证地接受事实) 乔布斯总是有有意识地将自己置身于艺术与科技的交汇处。（紧邻科学与美） “求知若饥，虚心若愚 (Stay hungry, stay foolish) “ (文学翻译的艺术) 印度古老的谚语中： 在人生的头30年里，你培养习惯；在后30年，习惯塑造你。 禅修增强了乔布斯对直觉的信赖，教他如何过滤掉任何分散精力或不必要的事情。 2. Apple I &amp;&amp; Apple II 乔布斯的父亲教导他，最求完美意味着：即便是别人看不到的地方，对其工艺也必须尽心尽力。 （追求完美的执着性，不在于是否有人注意到） 你永远不该怀着赚钱的目的去创办一家公司，你的目标应该是做出让你自己深信不疑的产品，创办一家生命力很强的公司。 创建产品强调的三个点： 共鸣，紧密结合顾客的感受 专注，为了做好我们决定做的事，拒绝所有不重要的激活 灌输，人们是根据公司或产品传达的信号，形成对他的判断（如果我们以创新、专业的方式展示产品，那优秀的形象也被灌输到顾客的思想中） 至繁归于至简(Simple is the best) 天文学家约翰尼斯·开普勒：“自然喜欢简洁与统一”。 预见未来最好的方式就是亲手创造未来（The best way to predict the future is to invent it） 3. 苹果零售店Apple Stores &amp;&amp; iTunes &amp;&amp; iPad 如果你发现有些事做得不对，你不能只是忽略它，然后说：“以后再处理”，这是其他公司的做法。 把关注点放在真正有价值的地方，以及革命性的营销手段。 努力融合科技和人文艺术。 4. 遗产 Legacy乔布斯没有直接发明很多东西，但他用大师级的手法把 理念、艺术和科技融合在一起，就创造了未来。 我的激情所在是打造一家可以传世的公司，这家公司里的人动力十足地创造伟大的产品，其他一切都是第二位的。当然，能赚钱很棒，因为那样你才能制造很伟大的产品。但是动力来自产品，而不是利润。 我们的责任是提前一步搞清他们将来要什么，而不是消费者想要什么就给他什么。(提前准备，塑造、引领未来) 我们试图用我们仅有的天分去表达我们深层的感受，去表达我们对前人所有贡献的感激，去为历史长河加上一点什么，那就是推动我的力量。(感恩，在历史长河上留下自己曾来到这个世界的足迹)]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[富甲美国：沃尔玛创始人山姆.沃尔顿自传]]></title>
    <url>%2F2019%2F04%2F15%2F%E5%AF%8C%E7%94%B2%E7%BE%8E%E5%9B%BD%EF%BC%9A%E6%B2%83%E5%B0%94%E7%8E%9B%E5%88%9B%E5%A7%8B%E4%BA%BA%E5%B1%B1%E5%A7%86-%E6%B2%83%E5%B0%94%E9%A1%BF%E8%87%AA%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[山姆·沃尔顿 序言零售商存在的意义，就是不断提高效率，降低中间环节的费用，为消费者创造价值。 在简单的快捷、方便之外，必须设计更加有温度、有情感的联系。(从单纯的买卖过渡到情感纽带，以及体验式的购物) 平凡人齐心协力，完成非凡之事。（人们往往高估了自己短期的努力效果，远远低估了尝试努力的效果） 我们让自己大吃一惊，而后没过多久，我们就让全世界都大吃一惊。（怀才只有等到十月才会更明显，以及显露） 1.重视每一分钱最不乱花一分钱 我已经对一块钱的价值有一种强烈的、根深蒂固的尊重。 金钱对我的意义从来就没那么大，即使是从账目意义上也是，只要我们有足够的事物、有不错的住处，以及然子女接受良好的教育——这就是有钱了。（每个人富有，金钱自由的定义的不同点） 2. 改变行业面貌的规律 母亲一定是特别能激励他人积极进取的人，因为当她告诉我，无论做什么都应该始终尽力做到最好时，我认真听了她的话。（听取正确的意见并执行） 我终是把麻烦看成挑战 （善于解决问题而不是抱怨问题，积极面对避免拖延处理） 山姆通过待人和善迎来滚滚财源。（做自己喜欢的事，能顺带赚钱更好）]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[褚时健传]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%A4%9A%E6%97%B6%E5%81%A5%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[褚时健（1928年1月23日-2019年3月5日），云南红塔集团有限公司和玉溪红塔烟草（集团）有限责任公司原董事长，褚橙创始人，先后经历两次成功的创业人生，被誉为中国烟草大王、中国橙王。 序言褚时健自我评价: 我觉得我并没有做什么了不起的事情，我所做的，都是尊重规律，恪守本分。做事讲求踏实和认真。 我从来不认为自己是个天才。我一直是个实实在在做事的人，而且有认真的态度，做哪一行就尊重哪一行的规律。学习多，了解多，实践多，心里就有足够的底气。 我自己做的最问心无愧的就是：没有庸庸碌碌地生活。 万科王石评价：面对并不公平的命运，愤然一跃固然悲壮，有原则地隐忍更加可贵。 作者评价：褚时健理解自己的生活很轻，他拥有一颗赤子之心，也有足够的钝感力，同时他对生活有着细节的热情，这些都是他淡定、执着的原动力。 1.少年故事(1927-1948；矣[yi]则，昆明)1942年的滇越铁路，日本人进行了轰炸，将褚开运炸成重伤，随后父亲的早逝，导致褚时健少年酿酒帮贴家用，做什么事都琢磨一下。 做事，把事做好，就会快乐，就会有成就感。 死真的会改变很多东西，以前我没有体会到，死以为着永远离开，意味着你本来正在做，应该做的事情再也办法去做了。 活着每一天，把每件事情做好，就不白白过这一生。不要想太多死亡的事情，他来或不来，谁也控制不了。 做什么事都要学会观察，会总结，找到规律。在1955年部队评军衔的时候，怎么不给骡子评个军衔呢？打仗的时候骡子最辛苦了，井冈山的时候驮枪又驮炮，但它什么也评不到，为什么？它不进步嘛。 “治大国如烹小鲜，小时料理地好，大事才有本事料理。” 2.生活的断层(1959-1979;元江，新平) 一个人，别人把你打倒了不要紧，总有事情是自己控制不了的，但自己不要把自己打倒，不然就真的是测底倒了翻不了身。 西南三大宝：云烟、贵酒、川妹子。 3. 华彩人生(1979-1996；玉溪卷烟厂)做过了你就知道原来可以，你不做就永远都不进步。（勇于尝试，努力试错！） 你怎么知道我不是机会？你敲了三次门，机会只敲一次。 烟叶的生长，你尊重他的生长规律，按规律办事，认真对待，一定会有好回报。 做事抓重点，不然你做的多费力也白做。 4.种橙十年哪一行都是一样，你要做管理工作，首先生产业务就要熟悉，不然话说出来都不对路。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速阅读术]]></title>
    <url>%2F2019%2F04%2F15%2F%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[快速阅读术 多读一些书，看到的世界也会不同。(You are what you read!) 1. 阅读速度缓慢的原因阅读速度与理解程度、记忆效果并不成正比。即使放慢了速度，非常仔细的阅读，也并不意味着能牢记书中的内容。 读书的真正意义，并不在于“复制100%”的原文，而是在于“邂逅1%”的收获。 花一周时间仔细阅读一本书，一个月之后，仅能记住1%的内容。那么，同样花一周的时间，我们快速阅读10本书，一年之后，就能记住全部内容的10%，后者岂不更加理想？并非深入仔细阅读一本书，而是提高阅读量，获取其中的“知识片段”，积少成多，汇小溪已成江海。这样的理念正是阅读速度缓慢的人们所欠缺的。 不奢求通过阅读一本书就获得一个大型积木块，而是先通过多读，让自己积累更多的积木碎块。 记忆音符的排列、能够用乐器完美地再现旋律、背诵歌词——这些都不是聆听音乐的初衷。音乐的根本价值也不在此，而是在于听过音乐之后，对个人产生的影响和带来的改变。 流水式阅读是信息大爆炸时代最合理并且可以“避免堆积”的阅读方式。 2.养成阅读的习惯不仅是读书，任何习惯的养成，最重要的都是在每天同一时间做这件事。 书籍可分为三种类型： 不必读的书 无法快速阅读的书 可以快速阅读的书 故事性强的内容，没有必要快速阅读。 无法快速阅读的书，数量通常不会太多。 丰富多彩的多读生活，9：1原则是关键 不能仅有想要慢慢品读的书籍，还要尽量列入能够快速读完的书籍。 为了享受阅读的过程，我们主张集中阅读一本书的时间不应该超过10天，这是一个原则。想办法避免厌倦，也是养成阅读习惯的必要条件. 3.避免读后忘记只有书评人才知道的唯一妙招，“为了写而读”(输入与输出) 让我们摒弃“将信息印刻在自己心中的”理念，将其转换成“记录在身外”。 令人心动的段落，不要记忆，要记录。 准备好A4纸，读到佳处随时摘录。遇到想记住的内容，就摘抄下来。开头标明页码，之后是文章内容，如此不断累积。最好不要原封不动地抄写整个段落，而是短小精悍，将内容控制在几行之内。一行采集 另外，留住对“那一行”产生共鸣的原因，回味重要段落。 随着时间流逝，就会逐渐遗忘为之心动的原因，这样摘抄失去意义。 仅凭一行感想，唤醒一册记忆。 4.流水式阅读规则跳读，以小标题为单位。小标题用来判断这一章节是否需要阅读 。 仔细阅读序言和目录 仅读开头和结尾的5行 确定关键词在阅读 使用多种阅读节奏 合理利用序言和目录，是确保高效轻松阅读体验的铁则。 确保翻开书之前，明确目的，进行关键词搜索阅读法。 5. 如何与书籍相遇，又如何区分他们打破兴趣壁垒，增加喜欢的书籍。只选择自己想读的书籍，读书就会千篇一律. 最好每隔三个月就整理一次书架。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design_Pattern_IV]]></title>
    <url>%2F2019%2F01%2F28%2FDesign-Pattern-IV%2F</url>
    <content type="text"><![CDATA[1. 行为模式1.1. 模板模式（Template）在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。将通用算法（逻辑）封装起来，而将算法细节让子类实现（多态）。 1234567891011121314151617181920212223242526272829303132333435363738394041class AbstractClass&#123; public: virtual ~AbstractClass(); void TemplatMethod(); protected: virtual void Operation1() = 0; virtual void Operation2() = 0;&#125;class ConcreteClass1: public AbstractClass&#123; public: ConcreteClass1(); ~ConcreteClass1(); protected: void Operation1() &#123;cout&lt;&lt;"ConcreteClass1 Operation1"&lt;&lt;endl;&#125; void Operation2()&#123;cout&lt;&lt;"ConcreteClass1 Operation1"&lt;&lt;endl;&#125;&#125;class ConcreteClass2: public AbstractClass&#123; public: ConcreteClass2(); ~ConcreteClass2(); protected: void Operation1() &#123;cout&lt;&lt;"ConcreteClass2 Operation1"&lt;&lt;endl;&#125; void Operation2()&#123;cout&lt;&lt;"ConcreteClass2 Operation1"&lt;&lt;endl;&#125;&#125;void main()&#123; AbstractClass * c1 = new ConcreteClass1(); AbstractClass * c2 = new ConcreteClass2(); c1-&gt;TemplateMethod(); c2-&gt;TemplateMethod(); delete c1; delete c2;&#125; 1.2.策略模式（Strategy)在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。 Strategy 与Template 模式类似，但是Strategy 是将逻辑（算法）封装到一个类中，并采取组合的方式解决。 面向对象的设计中有一条很重要的原则就是：优先使用（对象）组合，而非类继承（favorComposition Over Inheritance)。 1.3.状态模式（state）将状态与逻辑实现分离，当一个操作中要维护大量的switch case分支语句，并且这些分支依赖于对象的状态。 state 与 strategy 比较类似，但是两者的关注点不同， state 在于状态的改变， strategy 在于算法逻辑的解藕。 1.4.观察者模式（Observer)观察者模式可以说是应用最多。影响最广的模式之一。当一个对象被修改时，则会自动通知它的依赖对象。 解决问题： 建立一个一（Subject）对多（observer）的依赖关系，当“一”变化时，“多”也能同步改变。 优点： - 观察者和被观察者是抽象耦合的 - 建立一套触发机制 缺点： - 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间 - 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 我们通过在Context 中的list 或者Vector 维持一组观察者（observer），在Context 更新时，调用Notify()函数，再使用C++的多态，调用到子类的Update（）函数。 1.5.备忘录模式（Memento）备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。 应用实例： - 后悔药 - 打游戏时的存档 - Windows 里的 ctri + z - IE 中的后退 - 数据库的事务管理 缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 注： 申明Originator 为Memento类的友元类，以便可以访问Memento 的私有成员。Originator 通过Memento 类来备份还原。 1.6.中介者模式（Mediator）中介者模式是一种很有用并且很常用的类，用来降低多个对象和类之间的通信复杂性。将多对多的通信转化为一对多的通信。 Mediator 可以有解藕特性，通过Mediator，各个Colleague 就不必维护各自通信的对象和协议。 1.7. 命令模式（Command）请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 1.8. 访问者模式(Visitor)我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。 1.9. 责任链模式(Chain of Responsibility)在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 优点： - 降低耦合度,它将请求的发送者和接收者解耦 - 简化了对象。使得对象不需要知道链的结构 - 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任 缺点： - 不能保证请求一定被接收 - 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用 每个记录器消息的级别是否属于自己的级别，如果是则相应地打印出来，否则将不打印并把消息传给下一个记录器。通过SetNextLogger（）设定下一个记录器。 1.10.迭代器模式（Iterator）迭代器模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。把在元素之间游走的责任交给迭代器，而不是聚合对象。我们可以使用STL中预定义好的Iterator（Vector,set）等。 1.11.解释器模式（Interpreter）解释器模式提供了评估语言的语法或表达式的方式,对于一些固定文法构建一个解释句子的解释器。 优点： - 可扩展性比较好，灵活 - 增加了新的解释表达式的方式 缺点： - 可利用场景比较少 - 对于复杂的文法比较难维护 - 解释器模式会引起类膨胀 - 解释器模式采用递归调用方法。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design_Pattern_III]]></title>
    <url>%2F2019%2F01%2F28%2FDesign-Pattern-III%2F</url>
    <content type="text"><![CDATA[1.结构型模式1.1. 桥接模式(Bridge)桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。其实围绕的本质还是面向对象的原则：松耦合(Compling)， 高内聚（Cohesion）。 1.2. 适配器模式（Adapter）适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。通过继承或依赖（推荐）可以实现适配器模式优点： - 可以让任何两个没有关联的类一起运行 - 提高了类的复用 缺点： 过多地使用适配器，会让系统非常零乱，不易整体进行把握 1.3. 装饰器模式(Decorator)主要思想使用装饰器类中含有基类指针，我们就可以使用装饰类去修饰多个子类（面向对象的多态特性）。Decorator采用组合方式取得毕采用继承方式更好的效果。 1.4. 组合模式（Composite)Composite 模式于Decorate 模式有着类似的结构图。但是Composite模式旨在构造类（重在表示），而Decorate模式重在不生成子类即可给对象添加职责（重在修饰）。 1.5. 享元模式（Flyweight）享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。 在C++ 中使用STL Vector容器，提供共享对象的仓库。关键代码：用 HashMap 存储这些对象（JAVA）, C++ 用STL Vector。 优点：大大减少对象的创建，降低系统的内存，使效率提高。 缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。 1.6. 外观模式（Facade）外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。 关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 优点： - 减少系统相互依赖 - 提高灵活性 - 提高了安全性 - 缺点： - 不符合开闭原则，如果要改东西很麻烦，继承重写都不合适 1.7.代理模式(Proxy)在代理模式中，一个类代表另一个类的功能。为其他对象提供一种代理以控制对这个对象的访问。比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问, 我们可以在访问此对象时加上一个对此对象的访问层。使用到了C++的多态的特性。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design_Pattern_II]]></title>
    <url>%2F2019%2F01%2F28%2FDesign-Pattern-II%2F</url>
    <content type="text"><![CDATA[1. 创建模式（Creational Patterns）1.1. 工厂模式（Factory)目的：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。优点: 扩展性高，并且屏蔽具体的实现。缺点: 每增加一个产品时，都需要实现具体类和对象实现工厂。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Shape&#123; public: virtual void draw() &#123;&#125;;&#125;;class Circle: public Shape&#123; public: void draw() &#123; /* ... */ &#125;;&#125;;class Square: public Shape&#123; public: void draw() &#123; /* ... */ &#125;;&#125;;class ShapeFactory&#123; public: class Shape * GetShape(string type) &#123; if(type.compare("CIRCLE") == 0) return new Circle(); else if(type.compare("SQUARE") == 0) return new Square(); else return null; &#125;&#125;void main()&#123; class ShapeFactory shapeFactory = new ShapeFactory(); class Shape *shape1, shape2; shape1 = shapeFactory.GetShape("CIRCLE"); shape1-&gt;draw(); shape2 = shapeFactory.GetShape("SQUARE"); shape2-&gt;draw(); delete shape1; delete shape2;&#125; 1.2. 抽象工厂模式（Abstract Factory)目的：超级工厂又称为其他工厂的工厂，它提供了一种创建对象的最佳方式。 优点: 当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。缺点: 产品族扩展困难。既要在抽象的creator 里修改，又要实现具体的代码。 虚基类的感觉。 AbstrctFactory 与Factory 区别在于：AbstractFactory 模式是为了创建一组（有多类）相关或依赖的对象，Factory模式是为一类对象提供接口。 1.3. 单例模式(Singleton)意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。创建唯一的变量（对象） [Singleton mode image] 123456789101112131415class Singleton&#123; public: static Singleton * Instance() &#123; if(_instance == 0) _instance = new Singleton(); return _instance; &#125; protected: Singleton(); private: static Singleton * _instance;&#125; 注：Singleton 不可以被实例化（保证唯一一个），因此我们将它的构造函数声明为protected或private。 1.3. 建造者模式（Builder）意图：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 优点： - 建造者独立，易扩展 - 便于控制细节风险 缺点： - 产品必须有共同点，范围有限制 - 如内部变化复杂，会有很多的建造类 注：Builder 与AbstractFactory 在功能上相似，都用来创建复杂的对象。Builder 是通过的相同的创建过程获取不同的结果，而AbstractFactory 强调为多个相互依赖的对象提供一个统一的接口。另外，AbstractFactory 是立即返回，Builder是在一系列动作后返回对象。 1.4. 原型模式(Prototype)原型模式是用于创建重复的对象，同时又能保证性能。这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。优点： - 性能提高 - 逃避构造函数的约束 缺点： - 配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候 - 必须实现 clone() 接口 1234567891011121314151617181920212223class BaseA&#123; public: BaseA()&#123;&#125;; BaseA(const BaseA &amp;A) //c++ 拷贝函数，深拷贝是指重新分配类里面的指针 &#123; member = A.member; &#125; BaseA * Clone() &#123; return new BaseA(*this); &#125; private: int member;&#125;void main()&#123; BaseA *p1 = new BaseA(); BaseA *p2 = p1-&gt;Clone();&#125; C++ 拷贝构造函数(深拷贝，浅拷贝)]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大脑整理术]]></title>
    <url>%2F2018%2F11%2F26%2F%E5%A4%A7%E8%84%91%E6%95%B4%E7%90%86%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[1. 大脑重塑操作指南本书的主要是可以让我们具备：保持镇定和积极的心态的能力。 定期训练思考、感知和采取行动的能力，将会重塑你的大脑，并且使你感到内心平静和精神集中。 由于你的大脑不是“硬连接”，而是真真正正的“软连接”，所以你的人生经历在如何培养你的天性方面发挥了重要的作用。 1.1. 大脑工作原理概述人类的大脑大致结构可参见下图： 神经元在名为模块的大脑区域中聚集在一起，这些模块有：皮层（外层，包含两个半球(每个半球都有外侧裂以上的额叶、外侧裂以下的颞叶、顶枕裂后方的枕叶)）、4个叶和皮层下模块。大脑中名为胼胝体(pián zhī tǐ)的纤维束将这个半球连接在一起，同时激发两个神经元联系起来。 1.2. 神经元和神经递质简介神经元的功能部分依赖于化学作用，部分依赖于时短时续的脉冲放电激活。神经元相互之间通过发送神经递质这种化学信号，跨越突触间的间隙交流。 1.3. 神经可塑性的功能大量的证据表明突触突不是硬连接的，而是在变动之中，这就是突触可塑性或叫神经可塑性的含义。同时，他也证明了用进废退的道理，当你连接上体现某想技能的突触时，就是在强化这项技能。 不仅行为可以借助神经可塑性改变大脑结构，就算只是思考或想象某种行为也能改变大脑结构。 “给予就是获得”是脑神经的一条真理。感觉迟钝和自私自利对大脑和心里健康都是有害的，相反，同情和关爱更有益。 通过冥想和祈祷的平静和精神集中的练习将使大脑线路连接起来，有益于健康。 1.4.重塑大脑的4个步骤简称为FEED 聚精会神(Focus) 努力练习(Effort) 轻松自如(Effortlessness) 坚持不懈(Determination) 注意力和额叶在神经可塑性方面扮演着重要角色， 前额叶皮层相当于大脑的大脑。 努力练习将使注意力从感知转移到行动上，尽量使你的大脑活跃起来，从而产生新的突触连接（刻意练习，使得它变成一个新习惯）。为达到重塑大脑的目的，你必须使新行为保持足够长的时间，直到新行为变成你下意识的动作。 2. 如何赶走焦虑情绪？一般遇到警报，杏仁核给下丘脑（负责许多新陈代谢过程并涉及自主神经系统）发出信号，它又给脑垂体发出信号，脑垂体又给肾上腺发出信号，释放出肾上腺素和皮质醇（它是比肾上腺素更能让你保持长久兴奋的应激激素），这一系列使得身体系统发生波动，造成呼吸加快，心跳加速，血压升高，这就是“战或逃反应”。杏仁核，本能的天使，现实的魔鬼。 适度的焦虑有益于神经可塑性。在过度焦虑和不焦虑之间保持平衡对于学习和记忆是最好的选择，这种平衡关系呈“倒U形”曲线，也叫作”耶克斯-多德深曲线“。 深度呼吸吸入更多氧气，降低血液中二氧化碳的含量（它有维持血液中PH值，PH值越低，你的神经元越兴奋，就会越感到紧张）。 不逃避从长远看，不逃避并尽可能面对事情可以减轻焦虑。 用”暴露法”取代逃避，即直面让你感到焦虑的事情，不断地将自己暴露在宁你焦虑达的情境下，让自己习以为常，最终减弱焦虑。 3.如何摆脱负面情绪左额叶增进积极乐观的心态并促使你采取行动，而右额叶则会使你逆来顺受，加重消极的情绪。 常用促使积极心态的产生： 激发积极的情绪 多晒太阳 运动改变心情 以乐观的方式解读生活 打造积极思维 社交疗法 采取行动 常常微笑确实有帮助，它是这样发挥作用的：神经通路连接着面部肌肉、脑神经、皮层下区域和皮层。信息从大脑传向面部，也会传回大脑。例如，如果你收缩右脸的肌肉让你的左脑活跃起来，极可能产生积极的情绪。 运动可以促进血液的氧合作用，也会降低体内的酸性水平。 右脑更具全局性，也更情绪化，对主体本质和自传体记忆具有意义。但他也需要左脑，它是你生活经历的解读器，输入细节和积极的心态，帮助理解你理解你的体验。 当你被另外一个人吸引时，神经递质多巴胺被激活，产生愉悦感。积极的人际关系引发积极的情绪。 积极的情绪模式不仅代表着更多快乐，它也需要更多的实践。如果情绪是积极的，你将更倾向于思考可能性和潜在性，把迎接生活中的挑战视为活力的释放。 4. 如何增强记忆力工作记忆通常被称作短时记忆。工作记忆是一条通向长时记忆的必经之路。它想长时记忆”供给”记忆，长时记忆需要将工作记忆进行编码整理。 身体的脂肪的增加与记忆力的减退有关。 提升注意力 学会运用不用类型的记忆技巧（视觉系，听觉系） 利用联系法 使用联系法是一个特别有效的方式，就是将你想记住的东西与一个视觉影像联系起来。视觉联系之所以有效，是因为人们石峰擅长记忆非同寻常的视觉影像。 随着你开始描述事件，你会想起围绕该事件的相关记忆，激活一个完整的联想链，并重新激发了一个更叫宽广的记忆范围，这是因为记忆就是在大的神经元群之间建立突触连接。 不管你处于什么年龄段，都应该不断挑战自我。 树突分枝会刺激神经元产生更多的连接。 阅读费小说类的书籍 选修其他课程 旅游 参加由启发性的对话和辩论 练习专注于一项活动，而且时间要越来越久。不要同时做好几件事，也不要从一件事情快速跳转到另一件事上。要让自己沉寂到感兴趣的某项活动之中，而且要全身心地投入。 5.合理安排饮食氨基酸是神经递质的关键构成要素。 维生素C,E 是主要的抗氧化物。 6.改善睡眠电脑，手机的使用，会让视网膜感受光信号，大脑误认这是白天而不是夜晚，从而抑制了睡眠激素褪黑素的生成。 运动是一剂良药。运动向大脑输送了更多的氧，改善了毛细血管的健康状况。通过提高心血系统的效率，运动使血压下降。 7. 坚毅的心态心态点亮你的未来心理韧性面对逆境心存希望，竭尽所能促使转机出现，逆境变成顺境。 通过冥想来培养积极心态和乐观情绪的人，其心理韧性更强。 你培养的幽默感应当是积极向上的。 8. 提升注意力大脑需要稳定的血流，体操等伸展运动能促使健康的血液流向大脑，让人注意力更集中、精神更放松。 源于佛教的冥想被称作正念、内观或者内观禅修。 正念曾用于治疗焦虑症、抑郁。关注的是呼吸、旁观者的视角、接纳和不做批判的态度。 通过保持旁观者的视角，养成不做评判的态度。如果你在任何时间只是旁观而不是对正在发生的事情做出反应，你就会延迟对情景的反应，移植到所有的信息都被正确的看待。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴晓波：年轻人如何独立思考]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%B9%B4%E8%BD%BB%E4%BA%BA%E5%A6%82%E4%BD%95%E7%8B%AC%E7%AB%8B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[读《吴晓波：年轻人如何独立思考》笔记。 1. 积累越多的能力越强不同的行业不同的工作可能会不一样，但是有两点是一样的： 工具 数据的能力在这个逻辑里，每个人都可能需要形成自己的方法论。 时间长了就会有规律，这是一个时间轴的规律。 当第五年股票有跌掉了一个点的时候，你会告诉大家在三年前曾经跌过一次，两年前跌过一次。 任何一个人在一个行业里面，可能他是时间轴和空间轴到一个点的选择。 人和人之所以有的人很优秀，有的人不优秀，很大的原因是他们的坐标轴的时间宽度也不一样。时间宽度越长的人，积累越多的人他的能力越强。当你的时间轴空间轴建立起来以后，剩下怎么研究波动的变化，这个时候要形成自己的一种工具–解释世界到方法或者解释行业的方法。 2. 成长是拒绝诱惑的过程 我是一个很笨的人。我就养成了很好的习惯，给我认为的一些我值得关注的企业建立档案。 人的成长是一个什么过程，我认为是一个拒绝诱惑的过程。比较好的人是像我这样，天资比较中等的，没有啥诱惑你，你就干一件事，二十年时间就干一件事，我二十年时间干财经写作。 3. 人生跟赌博差不多不断训练，这个工作跟烧菜、剃头是没有任何差异的，还是你要建立自己独特性。当一个人在这个行业里面具有识别性以后，他成功的一步就存在了。 4. 人生是一场持久站靠时间熬。 年轻的太早太成功很可能是一个祸害，很可能就被自己消耗光了。 正常人走的道路应该是五年做一个规划，二十年做一个周期。二十年你在这个行业里面混不出来，也就算了，那就别混了。就是五年可以给，不断的给自己做一个职业规划，要打持久战就是最关键的，人生其实就是一场持久战。 5. 再穷也要站在富人堆里 我进大学听的第一堂演讲题目叫做《上帝死了》。尼采写过《查拉斯图拉如是说》他说上帝死了。 尼采 你的一切都是要重新建立自己的价值观，要培养自己的独立精神是很震撼的，那天对我的一生来将是个重大的转折点。 我觉得财务独立是思想独立的前提。 要理财。人生一定要规划，必须要理财。一个人必须要学会打理自己的财富，必须要知道钱在哪里。 6. 天资平凡是上帝最好的礼物人必须要知道，哪幢楼一定有很好的风景，我不能说更好的风景。人不能太花心，生活上这样，工作上也是这样。 神话只有落到地上是真实的。 7. 60-75年出生的人最幸运当年法国人定义企业家是对资产进行重组的人，这个是在任何一个职业中都可以有的。人生是资源不断配置，拿自己的才华和社会的资源进行不断配置的过程。 约瑟夫·熊彼特：企业家就是一个具有破坏的创新精神的人。我觉得任何一个行业的人，都需要有这样的破坏的创新的精神，有一种面对不确定世界冒险的精神。 8.企业家是一个冲动的动物一个人之所以他要奋斗，是因为我不满现状，我对现状不满，所以一定会有抱怨。抱怨的方式不一样，有的人可能通过放弃自我，有的人只在口头上抱怨，但有的人积极去改变，他们用解决方法去面对这些抱怨。 9. 把生命浪费在美好的事务上一句格言是我把它当作自己人生的座右铭：把生命浪费在美好的事务上。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bootloader]]></title>
    <url>%2F2018%2F08%2F25%2Fbootloader%2F</url>
    <content type="text"><![CDATA[1. BootLoader The computer first executes a relatively small program stored in read-only memory (ROM) along with a small amount of needed data, to access the nonvolatile device or devices from which the operating system programs and data can be loaded into RAM. bootloader – wiki 2. U-BootDas U-Boot – the Universal Boot Loader 其官网地址为：http://www.denx.de/wiki/U-Boot/WebHome 官网也很贴心的有指导手册 U-Boot是遵循GPL条款的开放源码项目。其源码目录、编译形式与Linux内核很相似，事实上，不少U-Boot源码就是根据相应的Linux内核源程序进行简化而形成的，尤其是一些设备的驱动程序，这从U-Boot源码的注释中能体现这一点。U-Boot不仅仅支持嵌入式Linux系统的引导，它还支持NetBSD, VxWorks, QNX, RTEMS, ARTOS, LynxOS, android嵌入式操作系统。它还具有丰富的驱动代码及文件系统支持。（UART、Ethernet、SDRAM、Flash，RTC，ext[2|3|4]、FAT，JFFS2、Squashfs、Cramfs、UBIFS等） U-Boot GitHub U-Boot的主要作用是： 初始化硬件 建立内存空间映射 2.1. Bootup StagesBootLoader的启动过程可以使单阶段(single stage)与多阶段(multi-stage)一般选择多阶段启动提供更复杂的功能，以及更好的可移植性。 2.1.1. Stage1常用汇编代码编写此段代码。例如u-boot/arch/arm/xxx/start.S。Stage1 的主要作用： 设定异常向量(exception vector) 初始化硬件（CPU速度，时钟频率，关中断，Disable I/D Cache，u-boot毕竟很简单） 初始化内存控制器 拷贝Rom或者Flash 等上的程序到Ram中（u-boot运行代码） 初始化堆栈 2.1.2. Stage2主要是C语言代码，ARM体系一般是在lib_arm/board.c中start_armboot()。Stage2 主要完成： 该阶段使用到的外围硬件初始化（Flash、SD、Ethernet等） 检测RAM 映射 拷贝Kernel 镜像至RAM 中的加载地址 设定启动参数 启动OS 2.2. U-Boot Directory 目录 特性 备注 board 平台依赖 目标板文件。Flash，Ram等驱动 cpu 平台依赖 与处理器相关 lib_arm 平台依赖 处理器体系相关 post 通用 上电自检文件目录 fs 通用 文件系统fat，jffs2,nfs,ubifs,ext[2-4]等 driver 通用 通用设备驱动 net 通用 网络 common 通用 内存检测，Nand等常用命令 2.3. U-Boot Memory MapU-Boot 的内存主要分布图如下图： 2.4. U-Boot Parameters 名称 默认值 备注 bootargs noinitrd root=/dev/mtdblock4 init=/linuxrc console=ttySAC0,115200 U-Boot 在启动内核之前的等待时间，单位：秒 bootdelay 1 与处理器相关 ethaddr 00:40:5C:26:0A:5B 网卡的MAC 地址 ipaddr 172.20.223.235 U-Boot 使用的IP 地址 loadaddr 0x40000000 下载二进制文件时的默认地址 bootcmd nand read C0008000 600000 500000; bootm C0008000 当使用boot 命令启动系统时所执行的脚本 Parameters Store globa data的RAM地址一般是存放在ARM 的R8 通用寄存器中。定义见include/asm-generial/global_data.h。 注：具体的位置可能因为U-Boot 代码的维护更新在变动，具体请参考实际的GitHub 版本 12345#define DECLARE_GLOBAL_DATA_PTR register volatile gd_t*d asm("r8")gd = (gd_t *)(_armboot_start - CONFIG_SYS_MALLOC_LEN - sizeof(gd_t));gd-&gt;bd = (bd_t *)((char*)gd - sizeof(btd_t)); 12345678910111213141516171819202122232425262728293031323334353637typedef struct global_data &#123; bd_t *bd; unsigned long flags; unsigned int baudrate; unsigned long cpu_clk; /* CPU clock in Hz! */ unsigned long bus_clk; unsigned long pci_clk; unsigned long mem_clk;#ifdef CONFIG_BOARD_TYPES unsigned long board_type;#endif unsigned long env_addr; /* Address of Environment struct */ unsigned long ram_base; /* Base address of RAM used by U-Boot */ unsigned long ram_top; /* Top address of RAM used by U-Boot */ unsigned long relocaddr; /* Start address of U-Boot in RAM */ phys_size_t ram_size; /* RAM size */ unsigned long irq_sp; /* irq stack pointer */ unsigned long start_addr_sp; /* start_addr_stackpointer */ unsigned long reloc_off; struct global_data *new_gd; /* relocated global data */ char env_buf[32]; /* buffer for env_get() before reloc. */#if CONFIG_VAL(SYS_MALLOC_F_LEN) unsigned long malloc_base; /* base address of early malloc() */ unsigned long malloc_limit; /* limit address */ unsigned long malloc_ptr; /* current address */#endif ... ...#ifdef CONFIG_BOOTSTAGE struct bootstage_data *bootstage; /* Bootstage information */ struct bootstage_data *new_bootstage; /* Relocated bootstage info */#endif&#125; gd_t; bd_t 保存于板子相关的配置参数。具体可见include/asm-generial/u-boot.h。 1234567891011121314151617181920212223242526272829303132typedef struct bd_info &#123; unsigned long bi_memstart; /* start of DRAM memory */ phys_size_t bi_memsize; /* size of DRAM memory in bytes */ unsigned long bi_flashstart; /* start of FLASH memory */ unsigned long bi_flashsize; /* size of FLASH memory */ unsigned long bi_flashoffset; /* reserved area for startup monitor */ unsigned long bi_sramstart; /* start of SRAM memory */ unsigned long bi_sramsize; /* size of SRAM memory */#ifdef CONFIG_ARM unsigned long bi_arm_freq; /* arm frequency */ unsigned long bi_dsp_freq; /* dsp core frequency */ unsigned long bi_ddr_freq; /* ddr frequency */#endif unsigned long bi_bootflags; /* boot / reboot flag (Unused) */ unsigned long bi_ip_addr; /* IP Address */ unsigned char bi_enetaddr[6]; /* OLD: see README.enetaddr */ unsigned short bi_ethspeed; /* Ethernet speed in Mbps */ unsigned long bi_intfreq; /* Internal Freq, in MHz */ unsigned long bi_busfreq; /* Bus Freq, in MHz */ ulong bi_arch_number; /* unique id for this board */ ulong bi_boot_params; /* where this board expects params */ ... ...#ifdef CONFIG_NR_DRAM_BANKS struct &#123; /* RAM configuration */ phys_addr_t start; phys_size_t size; &#125; bi_dram[CONFIG_NR_DRAM_BANKS];#endif /* CONFIG_NR_DRAM_BANKS */&#125; bd_t; 在启动之后一般使用RAM 临时存放启动参数，在使用saveenv 命令后将会将之写到类似于Flash 存储介质上。 Parameters StructureARM 采用了自己体系定义的参数结构。它的定义可以参见arch/arm/include/asm/setup.h。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748struct tag &#123; struct tag_header hdr; union &#123; struct tag_core core; struct tag_mem32 mem; struct tag_videotext videotext; struct tag_ramdisk ramdisk; struct tag_initrd initrd; struct tag_serialnr serialnr; struct tag_revision revision; struct tag_videolfb videolfb; struct tag_cmdline cmdline; /* * Acorn specific */ struct tag_acorn acorn; /* * DC21285 specific */ struct tag_memclk memclk; &#125; u;&#125;;#define tag_next(t) ((struct tag *)((u32 *)(t) + (t)-&gt;hdr.size))#define tag_size(type) ((sizeof(struct tag_header) + sizeof(struct type)) &gt;&gt; 2)/* The list ends with an ATAG_NONE node. */#define ATAG_NONE 0x00000000struct tag_header &#123; u32 size; u32 tag;&#125;;/* The list must start with an ATAG_CORE node */#define ATAG_CORE 0x54410001struct tag_core &#123; u32 flags; /* bit 0 = read-only */ u32 pagesize; u32 rootdev;&#125;;#define ATAG_MEM 0x54410002#define ATAG_VIDEOTEXT 0x54410003... ... U-Boot就是将各种启动参数串联成类似下图结构给OS。 注：必须以ATAG_CORE, ATAG_NONE开头与结尾，Kernel启动时会依据此检测参数的有效性。 2.5. Bootup OS以ARM 体系启动Kernel需满足以下几点： R0=0， R1=[机器码], R2=[Kernel启动参数起始地址] Disable I/D Cache Disable IRQ，FIQ CPU in SVC 模式 注：SVC 模式为Supervisor Control 模式，操作系统使用的保护模式，此模式下CPU能访问的数据权限更大，局限小。 Setting Parameters ReferenceBootLoader – wiki Das U-Boot – wiki U-Boot 百度百科 The DENX U-Boot and Linux Guide (DULG) for canyonlands u-boot的内存分布和全局数据结构 移植u-boot学习笔记2—–分析启动过程之内存分布 u-boot 运行时内存的分配]]></content>
      <categories>
        <category>bootloader</category>
      </categories>
      <tags>
        <tag>bootloader</tag>
        <tag>u-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux_Flash]]></title>
    <url>%2F2018%2F08%2F22%2FLinux-Flash%2F</url>
    <content type="text"><![CDATA[1. Flash闪存（Flash Memory）是非易失性长寿命存储器，是电子可擦除只读存储器（EEPROM）的变种，而闪存的大部分芯片需要块擦除。 注： N型半导体即自由电子浓度远大于空穴浓度的杂质半导体。(对于锗、硅类半导体材料，掺杂Ⅴ族元素(磷、砷等)P型半导体即空穴浓度远大于自由电子浓度的杂质半导体。在纯净的硅晶体中掺入三价元素（如硼） 常见的Flash有 NOR Flash NAND Flash NOR Flash NAND Flash 读速度 快 较快 单字节编程时间 快 慢 多字节编程时间 慢 快 寿命 十万次 百万次 I/O 端口 SRAM 接口，有足够地址引脚寻址 8个复用PIN 脚传送控制、地址、数据 功耗 高 低，需要额外RAM 应用市场 1~16MB 大容量 特点 程序可在芯片内运行 成本低，高存储密度，较快的写入和擦除速度 注：Spare Area 常常可以存储一些BBT信息。 Nand Flash 硬件特性： R/W 最小单位，Page 擦除最小单位，Block 擦除的含义是将整块都擦除为0xFF 写操作前，必须先擦除，然后再写 2. Linux MTD 常见MTD 分区为： 3. R/W FlowMTD Read Flow MTD Read Flow 4. Bad BlockNand Flash 工艺不能保证Memory Cell在其生命周期中保持性能的可靠性，使用寿命一般100万次。 坏块一般分为： 固有坏块：生产中就有（芯片原厂将每个坏块第一个Page的spare area某个字节标记为非0xFF） 使用坏块：存储寿命（program/erase 错误，将block标记为坏块） 当然，也有伪坏块。芯片在才做过程中可能由于电压不稳定等因素导致Program、Erase错误，标记的坏块也可能是好的。解决办法是，retry 一次，然后查看状态。 坏块的特性 Page Program与Block Erase操作失败，会反映到Status Register。 避免坏块策略 Wear-Leveling(损益均衡)技术 Buffer Cache类似于UBIFS 都会带有buffer cache，以及压缩，以此来尽量降低对I/O的操作。 应对坏块 为了保证数据正确性的R/W，我们使用BBT（Bad Block Table）。]]></content>
      <categories>
        <category>drivers</category>
      </categories>
      <tags>
        <tag>flash</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Better_Man]]></title>
    <url>%2F2018%2F08%2F01%2FBetter-Man%2F</url>
    <content type="text"><![CDATA[每天一碗鸡汤，强生健体 :) 曾经的你 – 网易云音乐 记录看到能给予自己Power的词句，与未来的自己干杯。 品尝在孤独中跃迁 这世界上唯一扛得住岁月摧残的东西，就是才华 – 李安 态度顺境修力，逆境修心 成功的哲学在于坚持得有多久 我相信你是世界上最富有的人之一，拥有梦想、时间和人生无数种可能性 把自己交给繁忙，得到的是踏实，却不是真实。 – 《无问西东》 吾尝终日而思矣，不如须臾之所学也；吾尝跂而望矣，不如登高之博见也。 – 荀子，《劝学》（有类似于，学而不思则罔,思而不学则怠。） 只要努力了，一定会有结果。但结果也分好坏，这个结果不一定是你想要的。尽管如此，我们也不应该放弃改变，固步自封。 别人贪婪的时候我恐惧，别人恐惧的时候我贪婪。 – 沃伦·巴菲特 唯一真正的成功，是按自己的意思過上生活。– 阮一峰 第15周分享 如果一件事，我们仅仅因为害羞不去做，那么它更值得去做。 人只是一根芦苇，是自然界最为脆弱的，但他却是一根会思考的芦苇。 – 布莱士·帕斯卡 未经审视的人生是不值得过的。 – 苏格拉底 快速走向成熟有且只有一种方法：主动进行大量有目的性的试错与学习。 不要因为没有草原，就忘记你是马。– 朴树，No Fear In My Heart 改变能改变的，接受不能改变的。 Ginga – 网易云音乐 不能羞于承认你自己。别急于求成，一切水到渠成。要练就练强大的内心。 – 《传奇的诞生》 真正的方法，往往是那些简单明了，朴素的至理名言。但我们总是视而不见，去追求那些虚无缥缈的东西。我们需要做的，是在年轻的时候，坚持学习，提升认知水平、培养分析和解决问题的能力，而不是天天琢磨出路在哪里！ 容易的道路越走越困难，困难的道路越走越容易。 一个人经常改变自己的看法，更可能得到正确的观点。世界变化太快，最聪明的人会不断修改自己对世界的理解，重新考虑哪些有定见的问题，不断用新的信息、想法挑战自己的思维方式，把自己的观点视为暂时的。 – 杰夫·贝佐斯， 亚马逊 败而坦然，胜而自然。 – 李建 知人者智，自知者明 知人者智，知己者明。胜人者有力，胜己者强。知足者富，强行者有志，不失其所者久，死而不亡者寿。 生活与其临渊羡鱼，不如退而结网 在这个世道上能活下来的要么坚强，要么坚强 明明是我们看错了世界，却说世界欺骗了我们。 – 张小娴 生活最沉重的负担不是生活，而是无聊。 – 罗曼.罗兰 生活一定要五颜六色，但绝不要乱七八糟。 带给男人快速成熟的，往往是生活不经意的意外。 哪有人天生会懂事，只不过见多了恶心的人。 言念君子，温其如玉。 – 《国风·秦风·小戎》 这世界上，绝大部分人的人生，都是八个字 – 比上不足，比下有余。没动力的时候往上看看，没希望的时候往下瞅瞅，日子就能过的很好。 人生不是走斜坡，你持续走就可以走到巅峰；人生像走阶梯，每一阶有每一阶的难点，学物理有物理的难点，学漫画有漫画的难点，你没有克服难点，再怎么努力都是原地跳。所以当你克服难点，你跳上去就不会下来了。– 《努力是没有用的》，蔡志忠 成功的人生是台阶式向上，而不是一条水平线。努力只是说明你拼命在走，跟你能不能向上走，关系不大。那些努力却没有结果的人，根本原因就在于，他一直走在平面上，没有走到更高的台阶。 垂直方向的努力更有意义，水平方向的努力意义不大。你做完这件事后，再去挑战更难的事情，就有机会学会做两件事。– 《每周分享第 21 期 》，阮一峰 痛苦是财富，这话是扯谈，痛苦就是痛苦，对痛苦的思考才是财富。 – 没必要的苦，不值得经历]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design_Pattern]]></title>
    <url>%2F2018%2F07%2F12%2FDesign-Pattern%2F</url>
    <content type="text"><![CDATA[背景设计模式(design pattern)， 是在这1994年，由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 的书提出。主要基于： 对接口编程而不是对实现编程 优先使用对象组合而不是继承 面向对象系统的分析和设计实际上追求的就是两点,一是高内聚(Cohesion),而是低耦合(Coupling)。 1. 设计模式鸟览常见设计模式有23种。大体可以分为三大类： 创建模式（Creational Patterns） 结构型模式(Structural Patterns) 行为型模式（Behavioral Patterns) 当然，还有J2EE设计模式。 模式 描述 创建模式 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 结构型模式 这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 行为型模式 这些设计模式特别关注对象之间的通信。 J2EE 模式 这些设计模式特别关注表示层。这些模式是由 Sun Java Center 鉴定的。 创建模式（Creational Patterns） 结构型模式(Structural Patterns) 行为型模式（Behavioral Patterns) J2EE设计模式 Ref.http://www.runoob.com/design-pattern/design-pattern-tutorial.html]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
        <tag>program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRTC_Congestion_Control]]></title>
    <url>%2F2018%2F06%2F22%2FWebRTC-Congestion-Control%2F</url>
    <content type="text"><![CDATA[1. Congestion Class Relationship1.1. Congestion Class 1.2. Biterate Controller 2. Congestion Control Flow2.1. Biterate Controller 2.2. Congestion Control2.2.1. Send Side 2.2.2. Receive Side]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
        <tag>biterate controller</tag>
        <tag>congestion control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRTC_Best_Relay_Network_Selection]]></title>
    <url>%2F2018%2F06%2F22%2FWebRTC-Best-Relay-Network-Selection%2F</url>
    <content type="text"><![CDATA[1. Prepare Local 端与remote 连接前，local 端会收取本地的SDP、Candidate。Candidate 其包含了一些网络信息，类似于 123456&#123; "candidate" : "candidate:3724402988 1 udp 41885695 172.28.28.24 51570 typ relay raddr 101.206.166.96 rport 23166 generation 0 ufrag 8B5q network-id 3 network-cost 50", "id" : "sdparta_0", "label" : 0, "type" : "candidate"&#125; 收集到的Candidates，会依据： IPv6 &gt; IPv4 UDP &gt; TCP 以上的准则进行自我的排序准备动作。 2. Connection 在收到remote端的candidate后，会进行如下动作： 序号 动作 1 将新收到的candidate网络与local 端的每一个candidate都创建一个connection 2 将connection 连接对，更新到预备队列中并且排序。排序的依据是：1）writable, receiving; 2) estimated latency is lowest; 3 MaybeSwitchSelectedConnection()，可能现在到达的remote candidate 是在有了选择连接之后，如果新到的remote candidate 更好，则将此candidate 替换selected_。那怎样是好的呢？1)wirtable、receiving、connected states; 2)nomination state; 3) last data received time; 4)lower cost、higher priority;5)rtt(往返时间间隔); 4 开始尝试stun ping 动作 5 从之前拍寻过的队列中选择下一个后背ping item。当然，这里也是有些策略：1)unpinged connections have priority over pinged ones; 2)select best connections from every network, the one with the earliest last-ping-sent time 3. Selection 在收到stun ping的响应之后，我们可以理解为，这条线路是通的。]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TED_Notes]]></title>
    <url>%2F2018%2F06%2F13%2FTED-Notes%2F</url>
    <content type="text"><![CDATA[TED 总是有些让你惊艳的话语。让我们去Keep it. TED: Ideas worth spreading TED 网易公开课 1. 如何有效地学习TED 视频：如何有效地学习 关闭其他影响注意力的事物，例如手机、电脑等 初始时慢，建立正确的行为 有针对性训练薄弱部分 合理计划休息、训练 2. 提高自信TED 视频： 如何提升自信 重复、重复、重复（一万小时定律，陈平安练百万拳《剑来》） 意识影响行为，自我积极暗示 适时地称赞自己认为做的好的点 远离拖自己后腿的人 自信的人对别人的反馈有一套自己的理解（乐观应对事务） 3. 提高记忆力TED 视频：如何用记忆宫殿提高记忆力 赋予意义，将需要记忆的事物与有意义的东西联系起来 每个人都有较强的视觉与空间能力 越疯狂、古怪、奇葩的影像越容易记忆 将影像放置与熟悉的空间中 不在于细节，在于“主题句”（希娜词topos） 4. 克服拖延症TED 视频：你有拖延症吗？ 每个人大脑中都有两个生物： 理性决策人 及时行乐的猴子（它活在当下，没有过去的记忆，也没有未来的概念。只关注于：简单和开心） 有一个东西可以吓跑及时行乐的猴子，慌乱怪 – Deadline。 解决方法： 人生一辈子的时间格子并不多，可能我们就过了1/3。 有战胜拖延症的信心，不要让及时行乐的猴子习惯性的获胜 计划 优先级 目标清晰，反对模糊 便于管理的小目标 行动 关键点在于：放下手里一切不重要的事情，屏蔽一切干扰，并且马上开始工作，但这是最难的一部分，及时行乐的猴子反抗最激烈。 在执行任务的时候一旦有了进展，你的成就感和自尊心都会得到增强。猴子以低自尊为动力，如果你获得了成就感，那么猴子这之后就得到了一个香蕉作为奖励，就不那么难以控制了。 你需要向自己证明自己可以做到，而不是告诉自己明天自己大概可以完成任务。直到你向自己证明了这一点，你永远都不相信自己有能力做到更好，有能力改变自己。 中文版：人为什么会拖延 - Wait But Why如何打败拖延症 - Wait But Why 英文版：Why Procrastinators Procrastinate - Wait But WhyHow to Beat Procrastination - Wait But Why 你的人生其实只有900个格子 你是怎么变得自律的–知乎]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>TED</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敏捷软件开发原则与模式及实践]]></title>
    <url>%2F2018%2F06%2F04%2F%E6%95%8F%E6%8D%B7%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E5%8E%9F%E5%88%99%E4%B8%8E%E6%A8%A1%E5%BC%8F%E5%8F%8A%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[敏捷开发(Agile Development) 是一种面临迅速变化的需求快速开发软件的能力。我们需要： 纪律和反馈的时间 保持软件灵活、可维护的设计原则 平衡这些原则的设计模式 1. 敏捷开发 人与人之间的交互是复杂的，并且其效果从来都难以预期，但确实工作中最为重要的方面。 –《人件》 人件-百度百科 原则(principle)、模式（parttern）、实践（practice）是重要的，但是人更重要。如果想要项目取得成功，就必须构建起具有合作精神的、自组织的团队。 1.1. 敏捷实践缺乏有效的实践会导致不可预测、重复的错误。 1.1.1. 敏捷联盟以下观点不是认为后面的不重要，而是前者重要性更高。 个体和交互 &gt; 过程和工具 （先构建团队，再让团队基于需求配置环境。） 可工作的软件 &gt; 面面俱到的文档 客户合作 &gt; 合同谈判 响应变化 &gt; 遵循计划 当我们构建计划时，应该确保计划是灵活的并且易于适应商务和技术方面的变化。较好的策略：为下两周做详细的计划，为下三个月做粗率的计划，再以后就做极为粗糙的计划。 1.1.2. 原则 围绕被激励起来的人构建项目，提供需要的环境和支持 工作的软件是首要的进度度量标准 最优先的是通过尽早的、持续的交互有价值的软件来是客户满意，间隔时间可以是几周到几个月 即使在开发后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势 开发周期，业务人员和开发人员天天在一起工作 面对面的交谈是最有效的传递信息方法 最后的构架、需求和设计出自于自组织的团队 不断关注优秀的技能和好的设计增强敏捷能力 周期性的在提高效率上反思，并做出调整 1.2. 极限编程概述极限编程（eXtreme Programming, 简称XP） 1.2.1. 客户成为团队成员以便知晓对方面临的问题，并共同去解决这些问题。 1.2.2. 用户素材做计划只需要了解到能估算它的程度就可以了，需求的特定细节会随时间而改变，在新版本之后是关注新需求的好时机。在XP 中，重要的是对需求细节的理解，而不是捕获细节。 1.2.3. 短交互周期用户素材用户会一直编写新的真正重要的用户元素到项目中 迭代计划 客户：选择不超过开发人员本次迭代周期的用户素材，并在迭代开始后，不在修改当次迭代用户素材的定义和优先级别。 开发人员：根据之前的迭代工作量预算本次迭代，在迭代期间自由分解用户素材为任务，并根据最具技术和商务意义的顺序开发任务。 发布计划 XP 团队通常会创建一个计划来规划随后大约6次迭代的内容。 验收测试 验收测试使用能够让他们自动并且反复运行的某种脚本语言编写，这些测试共同来验证系统是否按照用户指定行为运行。 集体所有权 如果你是专业领域有关GUI的，那么你最有可能去从事GUI 方面的任务，但是你将会被邀请去和别人结对从事有关中间件和数据库方面的任务。如果你决定学习另一们专业知识，你可以承担相关任务，并和能传授你这方面知识的专家一起工作，不会被限制在自己的专业领域。（个人认为有点偏重于理想化。） 持续集成 每个模块都可以在完成单元测试之后，合并到主线中。因而，XP 团队每天会进行多次系统构建。 可持续的开发速度 软件项目是马拉松长跑，而不是全速的短跑。团队必须要以一种可持续的速度前进，有意识的保持稳定、始终的速度。团队位于开放的空间，充满交谈的环境下。每个人都可以获知Partner 遇到的麻烦，工作状态。 简单的设计 考虑能够工作的最简单的事情（如选择平面文件而不是数据库，选择简单的socket 而不是ORB（对象请求代理），RMI（远程方法调用）），只有在有证据情况下，才去引入这些。 代码的重构，消除退化腐朽的代码 使用简单的比喻，来说明指导整个脉络流程 2. 敏捷设计敏捷团队，全局视图与软件一起演化。每次迭代中，系统设计都尽可能适用于当前系统，不会过多的预测未来的需求，更加关注于当前的系统结构。 较好的原则设计： 单一职责原则（The Single Responsibility Principle, 简称SRP） 开放-封闭原则（The Open-Close Principle, 简称OCP） Liskov 替换原则( The Liskov Substitution Principle, 简称LSP) 依赖倒置原则( The Dependency Inversion Principle， 简称DIP) 接口隔离原则（The Interface Segregation Principle 简称ISP） 2.1. 什么是敏捷设计敏捷设计师一个过程，是一个持续应用原则、模式以及实践来改进软件的结构和可读性的过程。保证系统设计在任何时间都尽可能简单、干净，杜绝代码的腐化。 遵循敏捷实践去发现问题 应用设计原则去诊断问题 应用适当的设计模式解决问题 2.2. 单一职责原则（SRP）就一个类而言，应该仅有一个引起他变化的原因。如果一个类承担的职责太多，就等于把这些职责耦合在一起，进而导致脆弱的设计。 1234567interface Modem &#123; public void dial(string pno); public void hanguo(); public void send(char c); public void recv();&#125; 接口中有两个职责：连接， 数据通信。如果应用程序的变化会影响连接函数的签名，那么这个设计就具有僵化性的臭味。在这情况下，我们分离两个职责。 12345678910111213141516interface Data_Channel&#123; public void send(char c); public void recv();&#125;interface Connection&#123; public void dial(stirng pno); public void hangup();&#125;interface Modem_middle extends Data_Channel, Connection&#123;&#125; 但是，如果程序的变化总是导致这两个职责同事变化，就不必分离他们。 2.3. 开放-封闭原则（OCP）主要特征： “对于扩展是开放的（Open for extension ）”: 对模块进行扩张，使其满足新行为。 “对于更改是封闭的（Closed for modification)”： 对模块行为扩张时，不必改动模块的源代码，模块的二进制执行版本（库、DLL，.jar文件）都无需改变。 这两点看似是矛盾的，请看如下解释。 抽象 模块依赖于某一抽象体，所以对它的更改是关闭的，通过这个抽象体的派生，扩展此模块的行为。 遵循OCP 代价是昂贵的，增加设计的复杂性，开发人员处理抽象数量有限。我们希望OCP 的应用限定在可能发生变化的上。 吊钩(hook) 在认为可能发生变化的地方放置吊钩（hook），会使软件更灵活些。 OCP 主要机制是抽象（abstraction） 和多态 (polymorphism)。 2.4. Liskov 替换原则(LSP)LSP 提供了继承层次保持OCP 的指导， 只有保持了OCP 才会保证我们软件的灵活性，可重用性。 LSP： 子类型（subtype）必须能够替换掉他们的基类型（base type）。Barbara Liskov 在1988年写下这个原则： 若对每隔类型S 的对象s, 都存在一个类型T 的对象t ,使得在所有针对T 编写的程序P 中，用s 替换t 后，程序P 的行为功能保持不变，则S 是T 的子类型。 2.5. 依赖倒置原则 (DIP)依赖倒置原则： 高层模块不应该依赖于低层模块，二者都应该依赖于抽象 抽象不应该依赖于细节，细节应该依赖于抽象 如果高层模块依赖于低层模块，那么低层模块的修改将会影响并作用于高层模块。 2.6. 接口隔离原则（ISP） 不应该强迫客户依赖于他们不用的方法。 如果强迫客户程序依赖于他们不使用的方法，那么这些客户程序就面临着由于这些未使用的方法的改变所带来的变更。 更多的策略是： 使用多重继承分离接口]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRTC 如何避免拥塞？]]></title>
    <url>%2F2018%2F06%2F03%2FWebRTC%20%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%8B%A5%E5%A1%9E%2F</url>
    <content type="text"><![CDATA[WebRTC 如何避免拥塞？1. WebRTC 网络传输背景1.1. WebRTC &amp;&amp; 多数直播大多数视频直播平台 子项 说明 传输协议 RTMP（Real Time MEssaging Protocol) 优点 使用RTMP， 其基于TCP传输，跟flash等流媒体服务支持比较好，同时CDN支持良好 缺点 直播音视频数据量大，实时性要求比较高，TCP的重传机制和拥塞机制不适用于实时传输。传输控制依赖于TCP本身协议控制机制，网络成本较大不够灵活。 音视频对网络丢包有一定程度天然容忍性（常见优酷，爱奇艺都有缓冲）。使用UDP传输是不错到选择。 webRTC 子项 说明 传输协议 RTP: 针对流媒体传输的基础协议，定义Internet上传输音视频数据包。 RTCP：负责流媒体到传输质量保证，提供流量控制和拥塞控制等机制。 优点 包括ICE、STUN、TURN等信令交互、网络大洞（P2P)，主流浏览器支持（chrome, firefox,opera, safari,edge等） 2. WebRTC 处理2.1. NACKNACK( negative acknowledge character)， 就是否定应答。与之对应的是TCP中的ACK( acknowledge character)。 在TCP中，接收端对于收到的包都要进行应答即发送ACK包，发送端通过接受ACK包，来确定发送的包已经被成功接收，以此来保证网络包的传输可靠。 RTP协议不保证传输的可靠性，所以接收端也就不会发送ACK包。如果这个包比较重要，可以给对端发送NACK包，来告诉这个包我没有收到，你如果‘还有’的话，就给我重新发送一遍（Retransmission）。 前面说到的丢包，都加了引号，这个“丢包”，有可能是真的丢了，也有可能是顺序乱了。我们知道网络包的到达，有时候不是一定严格按照包序到达的，我收到了很多较新的包了，某个旧的包还没有收到，我就认为它丢了，也没准儿一会儿它又到了。怎么判断“丢包”呢？ 我们通过： 乱序的偏移来决定发起重传 根据预计到达时间已经超过一定时间了来发起重传 (一般是等待一个rtt＋jitter的时长)。 更多丢包判断参见如下连接：WebRTC中丢包重传NACK实现分析 2.2. 前向纠错编码( FEC )FEC（Forward Error Correction，前向纠错码），通过增加冗余来增强容错性到一种方法。如果没有FEC，接受端发现丢包时，需要通过发送NACK 来发起重传，但重传会影响延时性。 FEC则是在发送端增加冗余数据，接受端在数据丢失到情况下可以重建丢失的数据。 增加FEC冗余数据占据了有效带宽 上面两点涉及到取舍，冗余的数据与减少丢包导致的延时。不过，FEC到冗余度是可以根据网络状况动态调整。 2.3. 抖动缓冲( Jitterbuffer )网络传输中总是存在着抖动，导致网络包不是均匀顺序到达，WebRTC利用一个缓冲区，进行等待与排序，这就是jitterbuffer。他能动态根据网络情况调整缓冲区的大小。 主流的实时音视频框架基本都会实现jitterbuffer功能，诸如WebRTC、doubango等。WebRTC的jitterbuffer按照功能分类的话，可以分为jitter和buffer。 jitterbuffer = jitter + buffer buffer buffer主要对丢包、乱序、延时到达等异常情况进行处理，还会和NACK、FEC（前向纠错码）、FIR(关键帧请求))等QOS（质量服务）相互配合。 buffer 主要分为如下几种type： freeframes incompleteframes decodableframes type remark freeframes 新到的数据包会根据时间戳在incompleteframes 和decodableframes 中寻找，相同放置到相应队列，否则从freeframes弹出空frame incompleteframes 至少有一个数据包，帧数据不完整 decodableframes 可解码，此队列中有decodable和complete 状态。complete 状态帧可被解码线程取出解码，完成后将buffer 重新push 到freeframes 队列。 decodable会根据decode_error_mode 有不同的规则，QOS的不同策略会设置不同的decode_error_mode ，包含kNoErrors、kSelectiveErrors以及kWithErrors。decode_error_mode 就决定了解码线程从buffer中取出来的帧是否包含错误，即当前帧是否有丢包。 jitterbuffer与QOS策略联系紧密，比如，incompleteframes和decodable队列清除一些frame之后，需要FIR（关键帧请求），根据包序号检测到丢包之后要NACK（丢包重传）等。 jitter 网络延迟带来的抖动会让音视频的播放不平稳，如音频的颤音，视频的忽快忽慢。那么如何对抗jitter呢？增加延时。 jitter主要根据当前帧的大小和延时评估出jitterdelay，再结合decode delay、render delay以及音视频同步延时，得到render time，来控制平稳的渲染视频帧。 其中: freeDelayMS: 两笔RTP1, RTP2 之间时间差 frameSizeBytes: 当前帧数据大小 incompleteFrame: 是否微完整帧 UpdateEstimate: 用卡尔曼滤波对帧间延迟进行滤波（具体算法这里不进行讨论） 在得到jitterdelay之后，通过jitterdelay+ decodedelay +renderdelay，再确保大于音视频同步的延时，加上当前系统时间得到rendertime，这样就可以控制播放时间。控制播放，也就间接控制了buffer的大小。 当然，仅仅通过动态的jitterbuffer 是无法完全解决网络拥塞的问题，根本上还是应该调整发送的码率。 2.4. 带宽自适应带宽自适应是指在音视频的收发过程中，根据网络带宽的变化，自动的来调整发送码率，来适应带宽的变化。在带宽足够的情况下，增加帧率和码率，提高音视频的质量，带来更好的通信体验。在带宽不足的情况下，主动降低码率或者帧率，保证通信的流畅性和可用性，也是带来更好的通信体验。 带宽自适应的核心：如何准确的估计带宽。WebRTC在实现带宽自适应时采用了Google提出一个称为REMB（Receiver Estimated Max Bitrate，最大接收带宽估计）的带宽估计算法。 大致算法是： 接受端维护状态机（根据丢包率或延时情况） 根据丢包率或延时情况修改remb 值 将remb 值通过RTCP 发送给发送端 发送端根据remb 值调整码率 补充：码流 / 码率 / 比特率 / 帧速率 / 分辨率 / 高清的区别 参考资源:webrtc 中到网络反馈于控制 WebRTC视频JitterBuff]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 简单介绍]]></title>
    <url>%2F2018%2F06%2F01%2FDocker%2F</url>
    <content type="text"><![CDATA[Docker1. Docker 背景 1.1. Docker 是什么Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC (LXC 其并不是一套硬件虚拟化方法 无法归属到全虚拟化、部分虚拟化和半虚拟化中的任意一个，而是一个操作系统级虚拟化方)的高级容器引擎，源代码托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。**它是目前最流行的 Linux 容器解决方案。 有人以通俗的方式说明: Docker的思想来自于集装箱，集装箱解决了什么问题？在一艘大船上，可以把货物规整的摆放起来。并且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会互相影响。那么我就不需要专门运送水果的船和专门运送化学品的船了。只要这些货物在集装箱里封装的好好的，那我就可以用一艘大船把他们都运走。 Docker就是类似的理念。现在都流行云计算了，云计算就好比大货轮。Docker就是集装箱。 1.2. Docker 的用途 快捷部署软件环境 以低效耗实现应用资源隔离 微服务架构组建（多个Docker 镜像之间组合使用） web应用的自动化打包和发布 国内有应用于Docker技术的公司DaoCloud , 云雀等 2. Docker 基础2.1. 术语 Docker镜像 镜像是Docker 容器运行时的只读模板，每一个镜像由一系列的层（layers）组成。当我们修改镜像时，新的层被创建并透明覆盖之前的层，Docker使用UnionFS 来将这些层连贯到文件系统。 Docker仓库 类似github， Docker 镜像管理库，Docker官方Docker Hub, 上面有很火镜像资源，如： Docker容器 容器都是从镜像建立的，Docker容器和文件夹类似，容器包含了应用运行所需的环境和数据等。Docker容器可以运行、开始、停止、移动和删除。镜像是只读的，当Docker 运行容器时，它会在镜像顶层添加一个可读写的层。 2.2. 组件Docker 采用的是客户端/服务端(C/S)架构模式。Docker客户端和守护进程之间通过socket或者RESTful API进行通信。 子项 说明 Docker守护进程 建立、运行、发布你的Docker容器，处理所有的Docker 请求，管理所有容器。 Docker客服端 Docker客户端，实际上是docker的二进制程序，是主要的用户与Docker交互方式。它接收用户指令并且与背后的Docker守护进程通信 2.3. 技术基础2.3.1. namespaceLXC所实现的隔离性主要是来自kernel的namespace, 其中pid, net, ipc, mnt, uts 等namespace将container的进程, 网络, 消息, 文件系统和hostname 隔离开。 NameSpace(ns) Function pid namespace 具有如下特征： 每个namespace中的pid是有自己的pid=1的进程(类似/sbin/init进程) 个namespace中的进程只能影响自己的同一个namespace或子namespace中的进程 因为/proc包含正在运行的进程，因此在container中的pseudo-filesystem的/proc目录只能看到自己namespace中的进程因为namespace允许嵌套，父namespace可以影响子namespace的进程，所以子namespace的进程可以在父namespace中看到，但是具有不同的pid net namespace 有了 pid namespace, 每个namespace中的pid能够相互隔离，但是网络端口还是共享host的端口。网络隔离是通过netnamespace实现的， 每个net namespace有独立的 network devices, IP addresses, IP routing tables, /proc/net 目录。这样每个container的网络就能隔离开来。 LXC在此基础上有5种网络类型，docker默认采用veth的方式将container中的虚拟网卡同host上的一个docker bridge连接在一起。 ipc namespace container中进程交互还是采用linux常见的进程间交互方法(interprocess communication - IPC), 包括常见的信号量、消息队列和共享内存。然而同VM不同，container 的进程间交互实际上还是host上具有相同pid namespace中的进程间交互，因此需要在IPC资源申请时加入namespace信息 - 每个IPC资源有一个唯一的 32bit ID。 mnt namespace 类似chroot，将一个进程放到一个特定的目录执行。mnt namespace允许不同namespace的进程看到的文件结构不同，这样每个 namespace 中的进程所看到的文件目录就被隔离开了。同chroot不同，每个namespace中的container在/proc/mounts的信息只包含所在namespace的mount point。 uts namespace UTS(“UNIX Time-sharing System”) namespace允许每个container拥有独立的hostname和domain name, 使其在网络上可以被视作一个独立的节点而非Host上的一个进程。 user namespace 每个container可以有不同的 user 和 group id, 也就是说可以以container内部的用户在container内部执行程序而非Host上的用户 有了以上6种namespace从进程、网络、IPC、文件系统、UTS和用户角度的隔离，一个container就可以对外展现出一个独立计算机的能力，并且不同container从OS层面实现了隔离。 然而不同namespace之间资源还是相互竞争的，仍然需要类似ulimit来管理每个container所能使用的资源 - LXC 采用的是cgroup。 2.3.2. Control Groups(cgroups)cgroups 实现了对资源的配额和度量。 cgroups 的使用非常简单，提供类似文件的接口，在 /cgroup目录下新建一个文件夹即可新建一个group，在此文件夹中新建task文件，并将pid写入该文件，即可实现对该进程的资源控制。我们主要关心cgroups可以限制哪些资源，即有哪些subsystem是我们关心。 cpu: 在cgroup中，并不能像硬件虚拟化方案一样能够定义CPU能力，但是能够定义CPU轮转的优先级，因此具有较高CPU优先级的进程会更可能得到CPU运算。 通过将参数写入cpu.shares,即可定义改cgroup的CPU优先级 - 这里是一个相对权重，而非绝对值。当然在cpu这个subsystem中还有其他可配置项，手册中有详细说明。 cpusets : cpusets 定义了有几个CPU可以被这个group使用，或者哪几个CPU可以供这个group使用。在某些场景下，单CPU绑定可以防止多核间缓存切换，从而提高效率 memory : 内存相关的限制 blkio : block IO相关的统计和限制，byte/operation统计和限制(IOPS等)，读写速度限制等，但是这里主要统计的都是同步IO net_cls， cpuacct , devices , freezer 等其他可管理项。 2.3.3. LinuX Containers(LXC)借助于namespace的隔离机制和cgroup限额功能，LXC提供了一套统一的API和工具来建立和管理container, LXC利用了如下 kernel 的features: Kernel namespaces (ipc, uts, mount, pid, network and user) Apparmor and SELinux profiles Seccomp policies Chroots (using pivot_root) Kernel capabilities Control groups (cgroups) LXC 向用户屏蔽了以上 kernel 接口的细节, 提供了如下的组件大大简化了用户的开发和使用工作: The liblxc library Several language bindings (python3, lua and Go) A set of standard tools to control the containers Container templates 2.3.4. AUFSDocker对container的使用基本是建立在LXC基础之上的，然而LXC存在的问题是难以通过标准化的模板制作、重建、复制和移动 container。VM虚拟化可以采用image和snapshot 实现复制、重建以及移动的功能。docker0.7中引入了storage driver, 支持AUFS, VFS, device mapper, 也为BTRFS以及ZFS引入提供了可能。 但除了AUFS都未经过dotcloud的线上使用。 AUFS (AnotherUnionFS) 是一种 Union FS。AUFS支持为每一个成员目录(AKA branch)设定’readonly’, ‘readwrite’ 和 ‘whiteout-able’ 权限, 典型的Linux启动到运行需要两个FS - bootfs + rootfs。 典型的Linux在启动后，首先将 rootfs 置为 readonly, 进行一系列检查, 然后将其切换为 “readwrite” 供用户使用。在docker中，起初也是将 rootfs 以readonly方式加载并检查，然而接下来利用 union mount 的将一个 readwrite 文件系统挂载在 readonly 的rootfs之上，并且允许再次将下层的 file system设定为readonly 并且向上叠加, 这样一组readonly和一个writeable的结构构成一个container的运行目录, 每一个被称作一个Layer。如下图: 得益于AUFS的特性, 每一个对readonly层文件/目录的修改都只会存在于上层的writeable层中。这样由于不存在竞争, 多个container可以共享readonly的layer。 所以docker将readonly的层称作”image“`- 对于container而言整个rootfs都是read-write的，但事实上所有的修改都写入最上层的writeable层中, image不保存用户状态，可以用于模板、重建和复制。 由此可见，采用AUFS作为docker的container的文件系统，能够提供如下好处: 节省存储空间 - 多个container可以共享base image存储 快速部署 - 如果要部署多个container，base image可以避免多次拷贝 内存更省 - 因为多个container共享base image, 以及OS的disk缓存机制，多个container中的进程命中缓存内容的几率大大增加 升级更方便 - 相比于 copy-on-write 类型的FS，base-image也是可以挂载为可writeable的，可以通过更新base image而一次性更新其之上的container 允许在不更改base-image的同时修改其目录中的文件 - 所有写操作都发生在最上层的writeable层中，这样可以大大增加base image能共享的文件内容。 参考资源:Docker 百度百科 Docker Org Docs Docker 入门教程Docker 微服务教程 一小时Docker教程 Docker Getting Start: Related Knowledge 非常详细的 Docker 学习笔记 docker 中文 Docker资源 如何通俗解释Docker是什么？]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Debug_high_cpu_loading]]></title>
    <url>%2F2018%2F05%2F26%2FDebug-high-cpu-loading%2F</url>
    <content type="text"><![CDATA[追查问题，主要是在： 浮现问题 缩小范围 猜测，修正及验证 我们这里使用如下测试代码演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;stdio.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/socket.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#define MAX_MONITOR_FILES 4void main()&#123; int e_fd, fd; struct epoll_event event, rdy_event[MAX_MONITOR_FILES]; if ((fd = socket(AF_UNIX, SOCK_STREAM, 0)) == -1) &#123; perror("socket"); goto out1; &#125; if ((e_fd = epoll_create(MAX_MONITOR_FILES)) == -1) &#123; perror("epoll_create"); goto out2; &#125; event.events = EPOLLIN; if((epoll_ctl(e_fd, EPOLL_CTL_ADD, fd, &amp;event)) == -1) &#123; perror("epoll_ctl"); goto out3; &#125; int n, j; while(1) &#123; n = epoll_wait(e_fd, rdy_event, MAX_MONITOR_FILES, 0); if(n == -1) &#123; perror("epoll_wait"); &#125;else if(n == 0) &#123; //timeout, skip &#125; for(j=0; j&lt;n; j++) &#123; //read it out &#125; &#125;out3: close(e_fd);out2: close(fd);out1: return;&#125; 进程我们通常可以使用top 命令查看到某一个进程占用了较高的CPU Loading。 线程可以通过top -H -p &lt;pid&gt; 命令具体查看&lt;pid&gt; 进程的子线程占用CPU Loading的情况。 这里是单独一个进程，是以这里只是单单出现一个。 函数在定位到某一个线程之后，我们需要继续定位到某一个函数或者命令导致了CPU 占用过高。strace -p &lt;pid&gt; 命令能帮助查找到具体的函数。pstack &lt;pid&gt;, trace -p &lt;tid&gt;等命令也能给予我们一些启示。 参考资源Linux下某个进程CPU占用率高分析方法一次服务器CPU占用率高的定位分析超全整理！Linux性能分析工具汇总合集]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[买车记录]]></title>
    <url>%2F2018%2F05%2F08%2F%E4%B9%B0%E8%BD%A6%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[买车过程记录1. 选车观念 不尽信，论坛与个人等，参数为王。 目的 不同车系，或者不同的车辆都有各自的定位与特定。常见的有： 性能性： 讲究操作性，动力 家居性：空间，省油与保养方面 商务性：big, bigger and bigger 土豪性：暂不谈~~ 个人的考虑主要是家用，偏向于考虑空间与保养，省油方面，当然还要有必要的安全性。另外，考虑在城市中行驶和之后另一半使用车辆，尽量考虑自动挡车辆。 选车 货比三家，多跑几家4s店，试驾不同车系（美系，韩系，日系，德系等），以及同一车系中同价位的车辆，如朗逸与宝来，卡罗拉与雷凌等。 来自38号车评中心的视频： 购车诉求概念一 购车诉求概念二 选车如何看品牌 选车试车购车正确流程 2. 试车空间 试驾不同车辆时，将前排调整为自己适合的开车习惯再看后排的空间表现。这是避免对比不统一。另外，空间包括： 前排的左右及头部空间，储物格等 后排的腿部空间，特别是头部空间，有很多车辆使用溜背造型 后备箱的平整度，后排能否放倒（虽然用的不多，可以放倒总是更好些） 舒适度 座椅的舒适度，包裹性，这些决定了在开长途时的疲劳程度。 试驾时，建议先试坐后排，试驾再前排，车辆的前后排的悬架可能不同。悬架可以通过减速带与凹凸路面，或者急刹车与转弯时能体现。 试驾关注点 档位 换挡的平顺性，主要是加速与收油时的表现。总结为： 稳：加速，收油低速平顺性 准：加减，转速准确，没有动力粘滞 狠：换挡快，没有空转 转向 主要是悬架的调校，以及回正度（助力） 油门，刹车 行程是否都有用（深踩），有些车辆的油门与刹车都只是前半段比较灵敏，后半段效果不同。例如，有些小排量油门前半段都有点窜，他是为了营造一种有动力的假象。 转速表 转速表不一定准，需要自己感受。另外，车辆的油耗显示也不一定准确，自己使用油枪或者APP计算。 小熊油耗排行 3. 砍价技巧与购买时间 购买时间 根据我们的初步参数比较，试驾对比，我们基本能确定2~3辆想买的。接下来，就看每个车最终的落地价了。 购买时间，参考网上的说法是：3-5月，7-9月。当然还有车展期间优惠幅度也比较大。2018年4月，韩系受萨德的影响，车辆的最终优惠大致可以达到2.3万，并没有优惠很多，只是厂家回访了2次，服务态度比较好，并不好抄底啊^_^!。 购买车辆，千万不要着急与冲动，能稳得住，汽拖之家的车系论坛还是真有些拖存在。 砍价 落地价 = 裸车价 + 购置税 + 保险 注意： 裸车价越便宜，购置税与保险也要重新计算，要尽量杀裸车价 不要在4S 店加装，尽量要求赠送，加装的东西如皮座4S 店都会外包给外面的装饰店搞定 序号 步骤 说明 1 诚意 更能表现出购买欲，销售才会透露低价给你。 提醒：关于寻找谈判的销售人员，请选择男性，男人一般容易冲动，爽快 2 销售底价 不要暴露自己的低价。4S店组织一般为三级：销售、科长（主管）、经理。 3 上级底价 谈价时销售员问你是不是今天就买或者能付定金，要是可以的话他去请示下领导，给你个最低价。这个时候你还是不要说出你的心理价，但你可以告诉他，要是价格合适可以交定金，让他去请示领导。 4 同伴作用 销售请示的低价还是有所保留的，同伴红黑脸作用得到上级真正底价 5 赠送 千万不要将砍价也要赠品混在一起谈，这要肯定会分散注意力。一个字：磨。磨赠品的时候，需要注意的就是别光看数量，要注重质量。 6 心态 买卖交易，讲究个缘分，实在谈不拢也别争个脸红脖子粗的，要保持风度 经典砍价–百度知道 TIPS: 在汽车之家与论坛上，我们往往能找到某一款车的最低价格，我们可以参考得出自己心里的价格。 4. 自己试驾记录表格下表是我试驾过或者看过的车辆 车系 车款 空间 操作 底盘 变速箱 动力 其他 德系 朗逸（2017款1.6自舒） 中上 好 完整度高 有滞缓 1.6 动力弱 中配就已经11.8万多了 韩系 领动（2016款1.6自精） 后排溜背导致头部空间不行 好 悬架偏硬 好，有点迟滞不会很明显 动力够 1.6L的发动机是2014 沃德十佳，变速箱也是自家的摩比斯，油耗表现优异。后防撞梁居然是玻璃钢！百度 领动 后防撞梁 法系 标致308（2018款1.6自豪） C4世嘉（2018款1.6自豪） 小 未注意 好 感觉比朗逸好 不连顺 试驾了1.2T 的C4世嘉，动力严重不连贯。 308 从16款到18款直接简配 日系 昂克赛拉（2017款1.5自舒） 轩逸 卡罗拉 雷凌（2017改款1.2T） 优秀 一般 一般 顺畅CVT 缘故 1.2T动力还是有劲 只试驾了雷凌。昂克赛拉后排空间小点，优惠只有8千，不要装饰1.2万。 轩逸感觉价格对标雷凌有点小贵，动力偏弱一点（自吸），但是座椅绝对是最舒服的。 卡罗拉优惠也只有1.2万样子，销售太傲气不想多讲。 5. SSSS常见销售技巧增加配置 厂家并没有此配置，4S自己加装。自己遇到的情况是：雷凌17款自精，增加倒车影像、右侧转向影像、胎压、日间行车灯、座椅仿皮。原厂自精指导价12.68万，但是增配的版本价格就提升到13.38万。这中间贵了7K去买这些东西，销售说是优惠2万 巧设收费名目 这在询问C4世嘉时遇到，当时报的裸车价比较低，优惠比较大。但是，….他GRD 有：出库费2K，贷款手续费要3~4K，检测费等，简直就是LG。 6. 结果最终购买了雷凌（2017改款185T） 项目 说明 价格 大约12.2万 裸车价 10.58万（指导价12.68万，优惠2.1万） 购置税 9.6K左右 赠送 脚垫、车窗膜、倒车影像、右车转弯影像、胎压 其他 在途虎养车上买了坐垫与360行车记录仪大概花了750块 参考38号车评中心 车评人郑刚]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员未来的考虑]]></title>
    <url>%2F2018%2F04%2F26%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%80%83%E8%99%91%2F</url>
    <content type="text"><![CDATA[大龄程序员优势 思维，开发思想 阅历 解决问题的框架 学习，自我管理 技术基础-》进阶，能抓出本质-》思维方式，知识体系 有所意识的保留自己的积累，如文章，代码库等，总结劳动成果。 看C++代码的方式：1.类用例图，简化（继承，聚合，关联，组合等）2.用例图 主副业副业不影响主业 业余时间 长线看涨 可积累性 可重复复制（每个人的时间成本相同，让一份时间的付出可以获得不止一份时间的报酬） 上班是一份时间，一份对应报酬出书，咨询，打赏是一份时间，多份对应报酬 让相同的时间创造出更多的收获 阮一峰第8周金句 如果你在很年轻的时候，就遭受到了失败，一定要把它当作老天送你的礼物。如果等到四十岁再失败，你会经受不起的。为什么年纪越大，走路越小心，因为越来越经不起跌倒了。 不要惧怕这些，不浪费时间，不停止进步。 Keep it!]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>work life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老子是癞蛤蟆]]></title>
    <url>%2F2018%2F04%2F26%2F%E8%80%81%E5%AD%90%E6%98%AF%E7%99%9E%E8%9B%A4%E8%9F%86%E4%B9%A6%E6%91%98%2F</url>
    <content type="text"><![CDATA[序读烽火的这本书《老子是癞蛤蟆》， 总是能给予自己很多的触动，他总能鼓动风雨–波澜哥：）。 1. 执念人必有所执，方能有所成。 不忘初心，方得始终。（概括自《华严经》，靡不有初，鲜克有终） 哪怕是一只癞蛤蟆，能够几十年如一日地充实自己，迟早都有跳出池塘吃上天鹅肉的一天，这个天鹅肉可以是桃李满天下，可以是抱得美人归，也可以是功成名就光耀门楣。 像一头不知疲倦的狼，肚里咽着肉，嘴里叼着肉，还要弓着腰，咬着牙去搏杀。 我看她的世界 就像是站在阴间看阳间。（陈靖） 我就是穷人的孩子，能做的除了拼命还是拼命最后他妈的还是拼命，一定要让我的孩子，成为富人的孩子。 就是被人踩得一滩烂泥，也要捏出狗尾巴花来。 2. UP Myself2.1. 个人一个上升的态度比什么都重要。 坚持去坚持。 尽人事，听天命。 生活中，所有人的角色定位都在改变，一些人在后退，一些则在前行，厉害的，则是奔跑，最牛的，当然是在冲刺的那一类。 顺境能够看一个人的先天品性，逆境能够看一个人的后天品性。品性，品行，一字之差，却悬殊千里，哪个更重，仁者见仁智者见智。 一个男人平性如何，顺境时看他如何对待以前的朋友，这些人往往无益于他如今事业；逆境时看他如何对待自己的亲人，敢不敢承担责任，能不能放弃一些东西。 熬一熬，说不定这道坎就熬过去了。 总之别把简单问题复杂化，聪明孩子就要错减法，大智慧的孩子甚至会做除法。 每逢大事有静气，就算做不到，也要假装做得到。等到习惯成自然，城府也就出来了。 为学第一功夫，是降得浮躁之气定，做人第一紧要，是有慈悲心。 下棋如做人，行错一步，不能摆在脸上，得放在心上。 做错事，成小丑或者傻瓜了，从不怨恨谁，也不会悔自己的决定。 2.2. 心态人生为棋我为卒，行动虽慢，命运多牟，可谁曾见我后退半步？ 是岐山凤雏，南阳卧龙，渭水飞熊？还是那五眼鸡，两头蛇，三脚猫？一退再退，风波恼我，我恼风波。逆水行舟，风波远我，我远风波。 – 《水仙子·讥时》，张鸣善 我不急不躁，心如磐石，若青松，八风不动，清风拂山岗，明月照大江……虽千万人，虽黑云压城，虽遍地魑魅魍魉，我往矣…… 走旁门，信左道，九次成功一次失败就败得一塌糊涂，再无东山再起。走正道，九次失败一次成功就能终生受益。 岁月是一把牛B的屠龙刀，能让某些男人飞黄腾达。但岁月也是一把贱B的杀猪刀，能让某些女人明日黄花。 人的一生只有一个终点，却有很多个起点。 对的起自己，对自己负责，才能对得起别人，自己在乎的人。一个爷们，想要爱人，必须先学会好好爱自己。 2.3. 待人学着感恩，学着理解，学着友善。有些花花草草，自小生长在营养优渥的温室环境，不知道风雨，所以不懂得感恩。 争取不要错过谁，错过的，尽量去祝福. 人下人，要把自己当人；人上人，要把别人当人。 太精明了，所以不够聪明。 被精明人占小便宜的，只要心里有数就行，被蒙一点钱无所谓，最重要的是不能蒙在鼓里，生意场上，退一小步，进几大步。 2.4. 读书多读书，是腹有诗书气自华，看人待物能多几分透彻，多识人，是以人为镜，能够多自省自知。 一个人是不是井底之蛙，自己说了不算。假如有一天你能饱览井底甚至是井上的风光，真不是井底之蛙了，心存一点谦恭，总不是坏事。 做学问要钻牛角尖，越死越好，但做人，要活络一些，不涉及原则性问题，总不是坏事。做学问做到家徒四壁，连带家人一起穷困潦倒，那不叫做学问，叫作孽。 – 国士陈平安与赵甲第对话 3. 生活社会 生活才是最荒诞的艺术。 男孩子帅不帅，要看有没有理想，女孩子漂亮不漂亮，要看善不善良。 不惮以最大恶意揣度他人，这样才能最大限度的不去失望 很多人，光看是瞧不出厉害不厉害的。听其言不够，还得观其行，再揣度其心。 就算自己不喜欢撒谎，在必须撒谎的时候，就尽量放烟幕弹打马虎眼，坚决不能做有一说一的实诚人。 再好的木料，只要小时候长歪了，就废了。 这才是真正到人生，每个人都按照惯性进步或者滑落，更多是在煮沸温水中逐渐死去的青蛙，愚昧无知到连跳出去的欲望都欠奉 很多道理，越是亲近的人苦口婆心，效果不大，反而是敌人和不相干的人，偶尔发语，才初期的振聋发聩。 世界就是这样，年轻的时候难免流亡他乡。世界就是这样，年轻的时候难免颠沛流离。（此心安处即吾乡 – &lt;&lt; 定风波 &gt;&gt;，苏轼） 贩夫走卒，市井小民，高官显贵，皇亲国戚，说到底都是一只只披着身份衣裳的阿猫阿狗，有些笨点，有些聪明点，每天喂养一下，总有物尽其用的一天。 人走茶凉是常态，可那个愿意陪冷宫的人喝冷茶的人，才会被当做朋友。 有些交情，太早粘上钱，不是好事。也许一开始看着是赚，其实是亏，会从头亏到尾。 人情这两个字，就跟倒过来的“情人”，一词一个德行，得温火慢炖“日”久见人心。 人情的火炉，是需要时不时“撩拨”一下的，不能一路冷却下去。 有些女人，是那种见到男人就拼命绽放的花朵，而有些女人，则矜持骄傲地只为一个男人娇艳摇曳。 太完美的女人都容易红颜薄命，还是有点残缺美比较让人安稳 :) 能杀得人需先能救得人，能救得人却还需能活得己。世上很多弱者，极少数是因为善良质朴，而主动选择退让。但更多的，可能是一种狡黠的处世智慧，处于劣势，却不是真的占据礼仪理义。相反，一旦有利可图，狰狞程度，可憎程度，丝毫不逊色任何人。强者未必都在为恶，弱者未必都是心善。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把时间当做朋友]]></title>
    <url>%2F2018%2F04%2F15%2F%E6%8A%8A%E6%97%B6%E9%97%B4%E5%BD%93%E5%81%9A%E6%9C%8B%E5%8F%8B%E5%90%AC%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[背景 这是晓书童喜马拉雅音频作品中李笑来《把时间当做朋友》(在线文档)的音频整理笔记。 本书的核心点：心智。 心智力量的不同，使不同的人面对相同的境遇，做出不同的解释，得到不同的结论，产生不同的选择。 1. 心智人与人之间的差异，除了看得见的相貌、身材、出身、财富的外，还有心智力量。 心智力量的不同造成不同的看法的例子：兴趣真的那么重要？往往并不是有兴趣才能做好，而是做好了才有兴趣。 大多数事情都需要熟能生巧。做得多了，自然就擅长了；擅长了，就自然做得比别人好；做得比别人好，兴趣就大起来了，而后就更喜欢做，更擅长，更……良性循环。 学习方法真的重要？ 当然，只有聪明的人才去关心方法，这没什么不对。然而，学生总是过分关心自己正在用的方法是不是正确。仅仅正确还不够。 学习上的成功，都只靠两件事：策略和坚持，而坚持本身就应该是最重要的策略之一。坚持，其实就是重复，而重复，说到底就是时间的投入。 总结 没有什么要比发现、培养、呵护、调整自己的心智的力量更重要的事情了。一旦我们的心智出现了问题，我们就会因为错误的理解而做出错误的判断，因此浪费的时间往往不仅无法估量，更可怕的是，这种错误和浪费甚至可能根本无从知晓。 2. 开启心智用我们的大脑控制我们的大脑，即开启心智，控制我们的大脑。你要明白你不应该隶属于你的大脑，而应该是你拥有你的大脑，并且应该是你可以控制你的大脑。 2.1. 大脑控制 人之为人，在于我们具有特殊的“大脑额页”正因如此，我们才具备其他动物很难具备的一种能力–“反思能力”–也许恰恰就是人与猴子之间3%不到的差异的具体体现。有了反思能力的人类，最终拥有了语言，发明了文字，形成了逻辑思考能力，最终拥有了强大的心智力量。 “即使是在极端恶劣的环境里，人们也会拥有一种最后的自由 ，那就是选择自己的态度的自由 。” – 心理学家维克托·弗兰克 2.2. 情绪控制另外，心智还能帮助我们控制情绪。 你所面临的所有尴尬，最终肯定有一部分原因是你自己造成的。所以，没必要找借口，没必要抱怨别人，没必要觉得这世界就对你一个人不公平，要记得“你并不孤独”–肯定还有别人也在不同的地方、不同的时代遭遇过同样的尴尬和痛苦。 很多人并不了解自己大脑的机制（具备遗忘痛苦机制，回顾过去的痛苦，现在能平常对待），所以，他们不由自主地被自己的感觉所控制。 “相信我，你并不孤独”，你遇见的事情总是有人遇见过，总能解决度过。 你永远都不应该在面对一些难以置信的悲剧的时候，因为自己失去信念而让他演变成第二个，甚至是第三个。我一旦吸取了教训，就不会跟过往纠缠不休，花更多的时间去后悔过去发生的事。 – 《查理芒格传》（晓书童解读） 阅读、学习、实践、反思，将有限的生命孤注于有价值的事情，等待时间的回报。 –《穷查理宝典》 (晓书童解读) 我面对过去，背靠未来，从来不去做任何的预测。 – 本杰明.格雷厄姆 查理芒格 ，伯克希尔·哈撒韦 第二大股东(CEO为沃伦·巴菲特)。查理·芒格推荐书单 例如背单词的时候，事实上，在做所有类似的必须记住大量信息的工作的时候，一定要想办法由衷地把这件事当作快乐的事情来做。 2.3. 满足感控制 要取得大的成绩就不能急功近利，不能为当前名利所诱惑 ，能按社会需要不怕挫折、坚持不懈奋斗是取得成就的重要因素。希望自己的欲望马上获得满足，是每个人的天性，我们要做的是稍加控制和改善。改善建议： 挑选自己某些方面的天性 纸笔罗列 反复审视 推迟满足感会表现出“更有耐心”，这些耐心可以被用来不动声色地承受更多的打击和挫折，坦然面对更多的威逼和诱惑。 另外，在对待自己的心智上还需要注意： 2.4. 留心成功者说的话成功者往往没有足够的时间去讲述所有的细节，并且通常会夸大遇到的问题与取得的成功。成功者们又会有意无意的美化包装他们的经验，而这一切，都在干扰你的判断。当然，只有经过仔细甄别之后，真正的成功者的真正的宝贵经验，才是无价的。 我们更应该关注“失败者” – 努力从失败者身上汲取经验。失败的原因往往很容易确定,并且失败者数量更多，更便于我们的观察。 2.5. 不要相信运气相信运气其实是缺乏自制力的表现。概率是独立于任何人存在的，因此绝对不会仅因为我的期望就发生任何变化。 好运气发生在你身上，你当然应该非常开心；坏运气降临在你身上，你应该平静接受–无论怎样你都要继续生活，当然就还要继续面对你不能控制的事物。其实，这是苏轼早就总结过的生活态度：“骤然临之而不惊， 无故加之而不怒。” 千万不要相信”机不可失，失不再来“。当你没有准备好的时候，对你来讲，不存在任何机会。机会时时刻刻都会出现在你身边，关键在于，你有没有足够努力，可以做到像诸葛亮那样，”万事俱备，只欠东风“。而当你准备好的时候，随处都有机会，而且所有的机会都是切实的，并且可以把握的机会。 2.6. 打造人脉不如打造自己整体上来看，人脉当然很重要。不过，针对某个个体来说的话，更重要的是他所拥有的资源。有些资源很难瞬间获得，比如金钱、地位、名誉，尤其在这些资源的获得更多地依赖出身和运气的现实世界里。然而有些资源却可以很容易从零开始，比如一个人的才华与学识。才华也好学识也罢，是可以通过努力必然获得的东西。 人脉之间大多存在着“交换的概念”，如果我们只是单纯的“索取方”，那给予方势必有“被抢，被夺走”东西的感觉。 生活的智慧就在于，集中精力改变那些能够改变的，而把那些不能改变的暂时忽略掉。专心打造自己，把自己打造成一个优秀的人，一个有用的人，一个独立的人，比什么都重要。打造自己，就等于打造人脉。 以下是我的几个简单的，但实践起来并不是那么容易的建议： 专心做可以提升自己的事情；学习并拥有更多更好的技能；成为一个值得交往的人； 学会独善其身，以不给他人制造麻烦为美德；用你的独立赢得尊重； 除非有特殊原因，应该尽量回避那些连在物质、精神生活上都不能独善其身的人； 真正关心一个朋友的意思是说，你情愿在他身上花费甚至浪费更多的时间； 记住，一个人的幸福程度，往往取决于他多大程度上可以脱离对外部世界的依附。 3. 与时间做朋友 时间无法管理，你要管理的是你自己。 一切的时间管理、立志行动等等说到底都离不开这两个词：积累、坚持。积累才是最有效的力量，唯有坚持才有希望，深信积累的力量，时间就是你的朋友。 从根本上，时间又是不能管理的，想要真正的掌控时间，需要的是开启心智，管理自己，掌控自我。 3.1. 精确感知时间 “管理时间”是不可能的，那么解决方法就只能是，想尽一切办法真正了解自己，真正了解时间、精确地感知时间；而后再想尽一切办法使自己以及自己的行为与时间“合拍”。 常见做法是“基于过程记录”。 以下是摘自《奇特的一生》中柳比歇夫的日志样本 事件 耗时 时间 分类昆虫学（画两张无名袋蛾的图） 三小时十五分 一九六四 年四月八日 鉴定袋蛾 二十分 一九六四 年四月八日 开始写关于袋蛾的报告 一小时五分 一九六四 年四月八日 3.2. 时间预算“To plan， or not to Plan， is a question.” 但是我们大多数都是”We do not plan to fail， we fail to plan.” 哈哈 在开始一天的活动之前，花费15至30分钟仔细制作你当天的时间预算绝对是特别划算的，磨刀不误砍柴工。在选择事情的重要性，推荐使用以下粒度，太细的划分会显得繁琐： 重要 一般 不重要 但是，在重要的事情上有：“显得重要”，“真的重要”。我们要去区分他们，其实只需要一个标准：这个任务的完成是否对你的目标达成是否确实有益。 强迫自己理智一些，就会知道，无用的事情，哪怕非常有趣都不应该去做；而有用的事情，哪怕非常无趣，你都应该做。但是，请你认真面对你自己，过去你一直是这样用理智指导你的行为的么？ 另外，在制作时间预算计划时，需要注意以下，避免时间的浪费： 目标不现实或者目前暂时尚不可行（难度大，需要细分小任务） 计划时间要比想象的更多点 越是短期的目标，越容易清晰。越是清晰的目标越容易实现 为了达到目标而制定的实施的策略 考虑到一些变化因素 计划固然重要，行动却更重要 当然，有些时候，你必须拖延你的行动。比如，当你决定买个新潮手机的时候，故意拖延三个月，会让你享受更低的价格；如果你决定买一辆你非常中意的高级轿车，故意拖延上一年，也许就会让你意识到当初的审美观其实很有问题。我个人的经验是，在所有的大额消费活动，乃至其他一切涉及到金钱的活动诸如投资之类上，“马上行动”的建议肯定不适用。 3.3. 时间审计我们现在会早上制作计划，晚上回顾时间消耗（有点类似有财务记账）。一段时间之后，固定的时间消耗不用再出现在时间预算上面，不用天真填满每一分钟。尽管总是有意外发生，时间不够用的情况，我们也不要采用消减其他时间的时间类似睡觉休息的时间，而是应该使用“多线程”的做法: 其中一件事情最好是机械的，少技术含量的 另一件事情不是特别需要脑力的 Example: 1) 跑步健身； 2）听audio book 4. 更多思考4.1. 效率 记住，你不可能百分之百地有效率，至少不可能总是百分之百地有效率。有些时候，你会非常有效率，但是，这种情况不可能永远维持；并且肯定的是，如果你竟然强迫自己一定要如此做的话，你就会像那些用100%的功率运转的机器一样，由于损耗太大而提前报废。 在做时间预算的时候，一定要留有空间。 你必须清楚肯定会有意外事件发生(意外总发生原因绝不是因为你的运气格外差，而往往只不过是因为你考虑得不够周全) 你必须用适当的方法休息、放松，以便恢复良好的状态去做更多的事情。 其实这世间的绝大多数事情都一样的–你不见得一定要做到极致才可以。有一个简单的算法：如果满分是100分，还是可以按照黄金分割定律，61.8分是恰好的。因为61.8分以上的成绩，意味着说你必须放弃很多才可以获的。 于是，在你规划你的时间的时候，你应该明白为了能够完全专注120分钟，你最终需要规划出差不多150分钟左右的时间开销。这个方法非常简单，但非常有效。而因为它简单而有效，所以会很容易体会到效果。类似于西红柿工作法 4.2. 把生活节奏调整得慢一点 凡是值得做的事情，都值得慢慢做–做很久很久。 因此，我们不用在最开始就制定“超人计划”，这样会很让你快速疲惫，进而放弃。 要想办法提前预知自己会需要怎样的技能，然后确定那是一个自己可以通过练习真正熟练掌握的技能之后，而后制定长期计划，一点一点地执行该计划。 题外话：正确的减脂跑步方式应该是慢跑。慢跑到稍微气喘的地步，就改为快走，等气匀了再改为慢跑。这样就很容易坚持到30分钟，然后，在接下来的10~15 分钟之内，如果体力允许的话（通常要经过以两个月的适应），就尽量快跑，或者至少强度比前30分钟再高一点，以便消耗更多的脂肪。(有氧运动大约20分钟之内，消耗的往往只是水分，30分钟之后才开始消耗脂肪) 4.3. 时间不一定是金钱 越是收入低的人越是不爱惜时间–因为他的时间实在是没有什么价值，每一秒钟都几乎可以忽略不计。越是收入高的人越是吝惜自己的时间，因为他的每一秒都有着确定的价值。 问问自己，“我的时间究竟可以标价多少？”–这就是一个人决心不再浪费时间的最有效的起点和动力。只有爱惜才可能产生节约的动力。 世界上有一个银行每天给你86400元当日花销，不能接受存款预支。这就是我们每日度过的时间，24 * 60 * 60 = 86400 将抽象的时间具体度量化，能帮助我们开始格外爱惜时间。 4.4. 提前准备的好处 原来现在科学家们对所谓的“潜意识”也有了更多简单明了科学解释。我们大脑中的灰质中储存的各种信息只有很少一部分（很难超过12%）是有序储存的，这部分被我们称作是“有意识的”。而更多的信息，或者信息碎片，是非有序储存的，甚至很难有意识地直接调出，这些往往就是被我们称为“无意识”或者“潜意识”的部分。梦境的存在，就是潜意识存在的最基本证据。 而随着信息输入越来越多，大脑就需要越来越多的灰质细胞。科学家们已经发现使用两种或者两种以上语言的人，有更多地灰质细胞。而颅腔的大小是有限的，于是，灰质细胞的增加，最终会导致灰质密度越来越高。于是，灰质细胞之间就越有可能由神经元连接起来。于是就有可能产生我们所说的“融会贯通”的现象 –那些原本可能貌似毫不相干的信息现在有机会被联系在一起了。所以，所谓知识渊博的人，就是那些存储于脑中的信息量超常地多的人，这些人总是可以“融会贯通”，于是，超常地充满了“智慧”。]]></content>
      <categories>
        <category>bookmarks</category>
      </categories>
      <tags>
        <tag>bookmarks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[more_coding_more_happy]]></title>
    <url>%2F2017%2F12%2F25%2Fmore-coding-more-happy%2F</url>
    <content type="text"><![CDATA[《我编程，我快乐：程序员职业规划之道》 我编程，我快乐 百度百科 0. 序言0.1. 不要害怕失败不是继续保持平庸，而是要出色，要赢。就像在赛跑中，你要总想着怎么不输，那肯定不会赢得比赛。同样，总想着怎么避免糟糕的活着，那你也不可能成为生活中的赢家。任何人都不应该时刻想着如何避免失败。(不是反对应对最坏的情况的应急措施的想法) 一个渴望成功的人肯定要比那些只是单纯完成工作的人更有可能成功。即使我们不能成为顶级专家，但确定高目标至少可以让我们不再平凡。 TIPS： 永远对生活充满乐观与热情，即使他QJ了你无数次。 0.2. 制定自己的计划审视自己的职业，不要跟在别人的计划后面跑，应该按着自己的计划发展。 软件可以看做是一门生意，雇佣软件开发人员，是因为可以创造利润。要评定自身的表现，就要看你能给公司创造多少商业价值。把职业想象成正在制作的产品的生命周期，你的技术成就了这个产品。在设计、生产及销售商品时，我们应注意： 选择市场：关注技术和商业领域 投资：知识和技术是商品的基础，要合理投资 执行：不光有技术还有产出 市场：有好的产品，也要得到行业中的认可 1. 市场分析1.1. 稳定成熟的技术还是未成熟的新技术？这与风险收益平衡概念类似。 稳定的技术 未成熟的技术 投资风险低 高风险 收益低 收益极高或极低 选择是把双刃剑，决定权还是在自己手里。但是，无论做出哪种选择，最终的目的是产生利润。 TIPS： 从行业信息，招聘信息或者论坛嗅到行业的发展方向。如当前的云计算，大数据，人工智能等 1.2. 供应和需求Core： 发现市场上的不平衡 供求关系可以预测商品和服务的价格，以及价格变化对购买的人数。 当选择专注哪种技术的时候，需要仔细考虑供给增长和价格下降对职业前景的影响。不要太在乎眼前，应该看得长远，不要太在意当前的小得失，考虑时间成本与机会成本。 TIPS: 研究当今市场需求，利用招聘网站找出哪些工作是高需求，哪些是低需求。与外包公司的需求做比较。 2. 自我提升2.1. 学习行业是如何运转的熟悉业务领域，思考技术是如何来服务业务的。只有了解了一个行业后，才能创造性地有所建树。TIPS： 阅读一本基础商业教程，例如《The Ten-Day MBA》 公司财务部门，讲解财务状况 2.2. 做团队中最差的时时保持一个谦卑学习的心态。你身边的人会对你产生很大的影响，明智地选择你的圈子。（ 即使你是那个最差的，也并不意味着你就是最差的。瘦死的骆驼比马大。） 主动性， 需要主动问，不需等着别人来告诉你。 良师或者榜样的好处： 直到亲眼见识某人突破你所熟悉的极限时，才知道一切皆有可能 学习过程形成体系，削减精力选着在哪种技术和行业领域中投资（不一定正确，但可以缩小范围） 指导自己，学会自己做自己的良师 还有，站在巨人到肩膀上。带有批判视角，从大量的现有[Good/Bad]程序中寻找模式和技巧，并以此为鉴。 当然，我们需要输出学到的东西，这样才能加深理解与记忆。检验自己是否真的学到东西，试试向别人传授这些知识。 2.3. 练习，练习，再练习一般分成几个阶段： 基础练习，例如了解各个语言的特性，go 支持高并发，python 快捷开发 练习，开源软件中可以寻找到不同的风格，不同的编程语言的软件练习 即兴编程 2.4. 学习如何失败任何事情最开始都是不完美的，伴随着失败。 每个错误的音调离正确的音调不过一步之遥。 出现问题时，才是检测工匠手艺的时候。学习如何处理是非常重要的。 TIPS： 吸取常见的错误经验 防御性的编程 出现问题后，不要企图隐瞒，越早解决负面影响越小 接受批评，能承担责任并提供解决方法 充满压力的时候是赢得忠诚的最好时机。修心，亦是修行之一。顺境修力，逆境修心，缺一不可。 2.5.推销…不仅仅是迎合 写作能力是必要的 面对面沟通高效 能用行业术语展示商业价值 个人优秀与人际关系网同样重要 网络日志，开源可增长写作技巧，扩大人际网（创建自己的商标–认知和尊重） 恐惧感使我们无法接近专业人士 2.6. 切忌孤注一掷切勿将自己的职业道路建立在一门特定的技术上，这是十分冒险的。 在选择商业与开源项目时，我们可以将开源作为一个平台，使自己对一项技术进行深度学习。同时，也不是致力于研究如何配置和部署一个商业应用程序服务器的细节（ 毕竟，任何人都可以在config中调整设置，对吗？ ），而是利用类似的开源，学习服务器内部是如何运作的，不要只局限于学习如何操作。 观点转变： 既了解实施的细节，也知道内部运作。 3. 执行3.1. 就是现在帕金森定律：“工作会自动膨胀到占满所有可用的时间。”开始行动，不要总是安于现状，要做推动者。 随时记得问问自己：“** 现在我们能做些什么？” 3.2. 读心术可以分析出潜在的功能需求–来自领导或客户。 但是，这也是有风险的： 这是额外的任务，他的价值是否足够； 可能对当前的软件架构影响，代码的模块化； Tips: 建立自己额外分析功能的列表，查看命中率。 3.3. 在工作中，将自己自动化想提高软件开发的效率： 找到工作效率更高的人 找更多的人来做 自动化工作 3.4. 每日成绩问自己“今天实现自己的价值了么？” 计划和跟踪工作成绩，对每个人都有益。常见步骤： 根据工作优先顺序，罗列计划 记录工作成绩 总结与回顾 3.5. 8小时激情燃烧在工作上，更少的工作时间可以有更高的效率。大多数项目都是一项长期工作，人们不可能按冲刺的速度跑完整个马拉松。 有限的资源更加珍贵，我们需高效的利用有限的资源，安排时间也是一样。好好规划工作时间，减少工作时间，将会收获更多。当离开工作一段时间后，才会更喜欢工作。 3.6. 今天我能把工作做到多好？在处理最无聊烦人的工作时，如果能狂热的想要把它做好，那么能为你的工作增添多少乐趣？常常遇到的问题是：我们如何挑战自己，发挥创造力来应对这些平凡的工作？试试把这些无聊的工作做到100分。 3.7. 别忘了你在为谁工作“确保你的目标和工作于你公司的目标一致。” 我们可以从小范围入手：团队。我们可以知道团队的问题和努力的方向。 3.8. 安分守己比起只专注于目标上的做法，专注于现在的工作会使你离最终的目标更近。我们将会享受日常工作中的每一个小成功。当有雄心，但不必路人皆知。 TIPS: 这有点像《白日梦想家》影片。 3.9. 一桶水中的鹅卵石不要太沉迷于自我，你的离开犹如拿起水桶中的鹅卵石并不明显。每个人都不是不可替代的，清楚知道这一点，与公司或同事保持良好的工作关系并努力工作，恰恰会让你与众不同，无意见创造更多的机会。 越是成功，就越有可能犯下重大错误。当你得到很多肯定时，你就会很少质疑自己的决定。当使用自己的方法屡试不爽时，就可能忽视可能会有更好的方法，容易产生盲点。 TIPS：不要高枕无忧，保持谦逊的心态。 3.10. 爱上维护维护也可以成为自由和创造的沃土。 身兼数职项目领导者、架构师、设计师和测试员，随心发挥创造力 可以设计更可见的改进 与客户直接进行交流，了解业务运行情况 TIPS： 在所有重要应用程序和代码中使用：评估、改进、评估。 把所有可以评估程序质量的元素列举出来。比如，响应时间，数据处理过程抛出的异常质量等，不要直接评估程序的质量。 选取测量标准，评估、改进 选取另一测量标准，评估、改进 4.自我未来规划避免职业技术的过时。研究、投资、执行、市场然后重复，在任何一个环节上花费过多的时间，都会有过时的危险。 4.1. 已经过时的技术根据摩尔定律的推断，计算机性能每隔18个月提高一倍。随着硬件的不断进步，软件技术也得到迅猛发展。必须认识到，即使你现在处于当今潮流的尖端，也极有可能已经在下一个潮流之后。向前看，清楚地知道你的技术发展方向，是盲目和有远见的区别。 职业生涯中最重要的部分不是晋升或者加薪，而是向这些发展方向努力工作的过程。 TIPS： 每周抽出2个小时的时间来研究新技术，学习相关技术并手动尝试，制作简单的应用程序。 4.2.你已经失去工作了不要自己绑定到特定的工作角色上，尝试以测试员、经理、设计师架构师鞥身份来对待自己的工作。 4.3. 要注意观察市场变化关注技术方面的新闻–不管是商业还是纯技术。并且留意技术达人，观察他们热衷于什么，我们就能大致了解到什么技术会成为热门，或者预测出两年后的热门是什么。 4.4. 给自己做一份蓝图个人的产品路线蓝图是用来判断你是否在不断向前发展的依据，并且能帮助你纵观全局。]]></content>
      <tags>
        <tag>bookmarks reading_notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++_UML]]></title>
    <url>%2F2017%2F12%2F14%2FC-UML%2F</url>
    <content type="text"><![CDATA[1. Basic1.1. VisibilityThe C++ class has three visibility. public, using “+” private, using “-“ protected, using ‘#’ See the base class examole: 1.2. Class members static members, using underline, like static int member virtual functions, using Italic font, like virtual void functions() 2. Class RelationshipThe C++ has these relationship: Assocation Dependency Aggregation Composition Inheritance Class template 2.1. Dependency可以简单的理解，就是一个类A使用到了另一个类B，而这种使用关系是具有偶然性的、、临时性的、非常弱的，但是B类的变化会影响到A；比如某人要过河，需要借用一条船，此时人与船之间的关系就是依赖。1234class B &#123; public: void display(class A* A) &#123;A-&gt;display();&#125;&#125; 2.2. Assocation他体现的是两个类、或者类与接口之间语义级别的一种强依赖关系，比如我和我的朋友；这种关系比依赖更强、不存在依赖关系的偶然性、关系也不是临时性的，一般是长期性的123456789class B&#123;public: B()&#123;&#125; void setA(A *A) &#123; ptrA_ = A;&#125;private/public: A* ptrA_; &#125; 2.3. Aggregation聚合是关联关系的一种特例，他体现的是整体与部分、拥有的关系，即has-a的关系，此时整体与部分之间是可分离的，他们可以具有各自的生命周期。12345class B &#123; public: private: vector&lt;class A*&gt; ptrclassA;&#125; 2.4. Composition组合也是关联关系的一种特例，他体现的是一种contains-a的关系，这种关系比聚合更强，也称为强聚合，但此时整体与部分是不可分的，整体的生命周期结束也就意味着部分的生命周期结束。 1234class B &#123; private: class A a;&#125; 总的来说，上述关系所表现的强弱程度依次为：组合&gt;聚合&gt;关联&gt;依赖 2.5. Inheritance1234567class A &#123; //.. &#125;;class B: public A &#123; //..&#125; 2.6. Class template123456789101112template&lt;class T&gt;class A &#123; //... private: T var;&#125;;class B &#123; //..&#125;;A&lt;B&gt; a; 参看资料继承、实现、依赖、关联、聚合、组合的联系与区别]]></content>
      <categories>
        <category>UML</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc_directory_analyze]]></title>
    <url>%2F2017%2F12%2F11%2Fwebrtc-directory-analyze%2F</url>
    <content type="text"><![CDATA[1. Structure 2. Directory Analyze Directory Remarks api native api, support for app or web browser. Note medianinterface.h and peerconnectioninterface.h pc 1.hannel manager; 2.peerconnecction, mediastream manage; 3.RTP receive/send audio audio receive/send video 1.video receive/send; 2.video encoder; 3.handle synchronize, quality common audio 1.audio converter; 2.channel buffer; 3.smoothing filter; 4.handle wav file common video 1.h264, libyuv; 2.bitrate control; 3.video frame, video render frame call provide base class for audio and video media Audio and Video will be AddStreams as track. 1.webrtc general video handle; 2.sctp.(Session Description Transport Protocol) stats reference counter modules 1.audio (coding, device, mixer, processing); 2.bitrate controller; 3.video(capture, coding) p2p 1.port, session, stun(server, port); 2.stunprober rtc_base base class. 1.bind, network, socket; 2.crc32, md5, openssl; 3.(bit, byte)buffer, memory; 4.task, thread systerm_wrapper 1.clock; 2.event; 3.rw_lock]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webRTC_Directory]]></title>
    <url>%2F2017%2F11%2F28%2FwebRTCDirectory%2F</url>
    <content type="text"><![CDATA[1.BackgroudWebRTC is a free, open project that enables web browsers with Real-Time Communications (RTC) capabilities via simple JavaScript APIs. The WebRTC components have been optimized to best serve this purpose. The WebRTC initiative is a project supported by Google, Mozilla and Opera, amongst others. This page is maintained by the Google Chrome team. And it’s source code structure like this:More detail see https://webrtc.org 2.Source code Directory Dir. Remarks api WebRTC 接口层。包括 DataChannel, MediaStream SDP相关的接口。各浏览器都是通过该接口层调用的 WebRTC。 call 存放的是 WebRTC “呼叫（Call）” 相关逻辑层的代码。 audio 存放音频网络逻辑层相关的代码。音频数据逻辑上的发送，接收等代码。 video 存放视频逻辑层及视频引擎层的相关的代码。视频数据逻辑上的发送，接收等代码。视频引擎层就是指如何控制视频采集，处理和编解码操作的逻辑。 voice_engine 存放音频引擎代码。主要是控制音频的采集，处理，编解码的操作。这个目录后面可能也会被拿掉。 sdk 存放了 Android 和 IOS 层代码。如视频的采集，渲染代码都在这里。 pc 存放一些业务逻辑层的代码。如 channel, session等。 common_audio 放一些音频的基本算法。包括环形队列，博利叶算法，滤波器等。 common_video 存放了视频算法相关的常用工具，如libyuv, sps/pps分析器，I420缓冲器等。 modules 后面单独列举 media 存放媒体相关的代码。 p2p rtc_base 存放了一些基础代码。如线程，事件，socket等相关的代码。 rtc_tools 存放了一些工具代码。如视频帧比较，I420转RGB，视频帧分析。 stats 存放各种数据统计相关的类。 libjingle 网络库。 system_wrapper 与操作系统相关的代码，如 CPU特性，原子操作，读写锁，时钟等。 Modules: Dir. Remarks audio_coding 音频编解码相关代码。 audio_conference_mixer 会议混音相关代码。 audio_device 音频采集与音频播放相关代码。 audio_mixer 混音相关代码，这部分是后加的。 audio_processing 音频前后处理的相关代码。 bitrate_controller 码率控制相关代码。 congestion_controller 流控相关的代码。 desktop_capture 桌面采集相关的代码。 media_file 播放媒体文件相关的代码。 pacing 码率探测相关的代码。 remote_bitrate_estimator 远端码率估算相关的代码。 rtp_rtcp rtp/rtcp协议相关代码。 video_capture 视频采集相关的代码。 video_coding 视频编解码相关的代码。 video_processing 视频前后处理相关的代码。]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
        <tag>Streaming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openwrt-ssh 跳过密码验证]]></title>
    <url>%2F2017%2F09%2F04%2Fopenwrt-ssh%2F</url>
    <content type="text"><![CDATA[openwrt 一般采用dropbear 作为ssh 客户端/服务端。 但一般都是使用password 的形式登录ssh. 我们使用public/private key 的形式来跳过需要password的验证。 1. 客户端使用如下命令，生成public keys1dropbearkey -y -f /etc/dropbear/dropbear_rsa_host_key 将图中pulibc key 复制到服务端。 2. 服务端dropbear 与openssh 有点区别在于，authorized_keys 文件并不在~/.ssh/authorized_keys 文件中, 而是在/etc/dropbear/authorized_keys 之后重启服务端dropbear service1/etc/init.d/dropbear restart dropbear 的配置如下： 3. 使用在客服端使用如下命令登陆服务端1ssh -i /etc/dropbear/dropbear_rsa_host_key root@172.28.52.151 -p 6350 需要使用 “-i”选项指明identify 文件， “-p 6350” 是指明端口号当然我们可以不指明-i option 指定文件，直接登录。 作如下步骤：1cp /etc/dropbear/dropbear_rsa_host_key ~/.ssh/id_dropbear 使用如下命令直接登陆：1ssh 172.28.52.151 -l root -p 6350]]></content>
      <categories>
        <category>openwrt</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>dropbear</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh_of_openwrt]]></title>
    <url>%2F2017%2F09%2F04%2Fssh-of-openwrt%2F</url>
    <content type="text"><![CDATA[openwrt 一般采用dropbear 作为ssh 客户端/服务端。 客户端使用如下命令，生成public keys1dropbearkey -y -f /etc/dropbear/dropbear_rsa_host_key 将图中pulibc key 复制到服务端。 服务端dropbear 与openssh 有点区别在于，authorized_keys 文件并不在~/.ssh/authorized_keys 文件中，如下图： 之后重启服务端dropbear service dropbear 的配置如下： 使用在客服端使用如下命令登陆服务端1ssh -i /etc/dropbear/dropbear_rsa_host_key root@172.28.52.151 -p 6350 需要使用 “-i”选项指明identify 文件， “-p 6350” 是指明端口号 或者可以不指明-i 文件1cp /etc/dropbear/dropbear_rsa_host_key ~/.ssh/id_dropbear 之后使用如下命令直接登陆：1ssh 172.28.52.151 -l root -p 6350]]></content>
      <categories>
        <category>openwrt</category>
      </categories>
      <tags>
        <tag>openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[incr.zsh]]></title>
    <url>%2F2017%2F08%2F14%2Fincr-zsh%2F</url>
    <content type="text"><![CDATA[incr.zshincr.zsh – zsh模式下自动补全指令或目录本身zsh 模式下，在我们双击Table 按键时候，会出现依次轮休的效果。但是，习惯于bash 的table 显示，个人不是很喜欢这个设定。 Enable incr.zsh 的zsh 模式效果图如下： incr.zsh 的优点： 自动补全 大小写纠正 待发掘… Enable Steps download incr.zsh enable incr.zsh download incr.zsh下载incr.zsh文件可以从incr.zsh官网获得，也可以直接复制如下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141# Incremental completion for zsh# by y.fujii &lt;y-fujii at mimosa-pudica.net&gt;, public domainautoload -U compinitzle -N self-insert self-insert-incrzle -N vi-cmd-mode-incrzle -N vi-backward-delete-char-incrzle -N backward-delete-char-incrzle -N expand-or-complete-prefix-incrcompinitbindkey -M viins '^[' vi-cmd-mode-incrbindkey -M viins '^h' vi-backward-delete-char-incrbindkey -M viins '^?' vi-backward-delete-char-incrbindkey -M viins '^i' expand-or-complete-prefix-incrbindkey -M emacs '^h' backward-delete-char-incrbindkey -M emacs '^?' backward-delete-char-incrbindkey -M emacs '^i' expand-or-complete-prefix-incrunsetopt automenucompdef -d scpcompdef -d tarcompdef -d makecompdef -d javacompdef -d svncompdef -d cvs# TODO:# cp dir/now_predict=0function limit-completion&#123; if ((compstate[nmatches] &lt;= 1)); then zle -M "" elif ((compstate[list_lines] &gt; 6)); then compstate[list]="" zle -M "too many matches." fi&#125;function correct-prediction&#123; if ((now_predict == 1)); then if [[ "$BUFFER" != "$buffer_prd" ]] || ((CURSOR != cursor_org)); then now_predict=0 fi fi&#125;function remove-prediction&#123; if ((now_predict == 1)); then BUFFER="$buffer_org" now_predict=0 fi&#125;function show-prediction&#123; # assert(now_predict == 0) if ((PENDING == 0)) &amp;&amp; ((CURSOR &gt; 1)) &amp;&amp; [[ "$PREBUFFER" == "" ]] &amp;&amp; [[ "$BUFFER[CURSOR]" != " " ]] then cursor_org="$CURSOR" buffer_org="$BUFFER" comppostfuncs=(limit-completion) zle complete-word cursor_prd="$CURSOR" buffer_prd="$BUFFER" if [[ "$buffer_org[1,cursor_org]" == "$buffer_prd[1,cursor_org]" ]]; then CURSOR="$cursor_org" if [[ "$buffer_org" != "$buffer_prd" ]] || ((cursor_org != cursor_prd)); then now_predict=1 fi else BUFFER="$buffer_org" CURSOR="$cursor_org" fi echo -n "\e[32m" else zle -M "" fi&#125;function preexec&#123; echo -n "\e[39m"&#125;function vi-cmd-mode-incr&#123; correct-prediction remove-prediction zle vi-cmd-mode&#125;function self-insert-incr&#123; correct-prediction remove-prediction if zle .self-insert; then show-prediction fi&#125;function vi-backward-delete-char-incr&#123; correct-prediction remove-prediction if zle vi-backward-delete-char; then show-prediction fi&#125;function backward-delete-char-incr&#123; correct-prediction remove-prediction if zle backward-delete-char; then show-prediction fi&#125;function expand-or-complete-prefix-incr&#123; correct-prediction if ((now_predict == 1)); then CURSOR="$cursor_prd" now_predict=0 comppostfuncs=(limit-completion) zle list-choices else remove-prediction zle expand-or-complete-prefix fi&#125; enable incr.zsh新建文件夹incr,将incr.zsh放于其中，之后将该文件夹放于~/.oh-my-zsh/plugins/ 下。确保incr.zsh 具有”x” 权限 修改.zshrc 文件， enable incr.zsh1source ~/.oh-my-zsh/plugins/incr/incr*.zsh]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[the Siege webserver performance test tool]]></title>
    <url>%2F2017%2F06%2F22%2Fthe%20Siege%20webserver%20test%20tool%2F</url>
    <content type="text"><![CDATA[1. Backgroud Siege is an open source regression test and benchmark utility. It can stress test a single URL with a user defined number of simulated users, or it can read many URLs into memory and stress them simultaneously. The program reports the total number of hits recorded, bytes transferred, response time, concurrency, and return status. Siege supports HTTP/1.0 and 1.1 protocols, the GET and POST directives, cookies, transaction logging, and basic authentication. Its features are configurable on a per user basis. Detail see https://github.com/JoeDog/siege 2. CompileDecompressing Siege source code archive, and run123./utils/bootstrap./configuremake &amp;&amp; make install Note: If we have ssl or zlib support, please point out when we make the configuration.12--with-ssl=$(SSL_include_dir) \--with-zlib=$(ZLIB_include_dir) 3. RunUse “siege -C ‘ command to see current configuration. Modify /etc/url.txt file to test accessing url. Then we use siege command to test, and press “Ctrl + C” to stop. 4. ResultAfter we stop Siege with “Ctrl + C”, we will get result:]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>webserver</tag>
        <tag>Siege</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lighttpd Support FastCGI (python) and LUCI(OpenWrt)]]></title>
    <url>%2F2017%2F06%2F20%2FLighttpd%20support%20fcgi(python)%20and%20luci%2F</url>
    <content type="text"><![CDATA[1.BackgroudWe need to use lighttpd as webserver to servive two web page: FastCGI (python bottle web micro framework) LUCI (openwrt’s cgi-bin/luci, which is CGI) 2. Support LUCIAfter we study OpenWrt wiki docs, we know how to make lighttpd support luci.Two key steps: enable lighttpd’s “mod_cgi” module tell lighttpd all requests to “cgi-bin/luci” will send to lua, lighttpd ignore them 123456789# Ensure we have to enable mod_cgi, which is in conf.d# server.modules += ( "mod_cgi" )## detail see openwrt org doc: https://wiki.openwrt.org/doc/howto/luci.on.lighttpd# # wang.kai@sunmedia.com.cn# tell lighttpd to process requests using luacgi.assign += ( "cgi-bin/luci" =&gt; "" ) Detail see OpenWrt Wiki about LuCI on lighttpd 3. Support FastCGIThe lighttpd fastcgi configuration like this: 123456789101112131415161718192021222324252627282930# Ensure mod_fastcgi mod_rewrite have been enabled, some modules will be enabled# in conf.d, BSP3's configuration will have effect on this.## Server.modules += ( # "mod_fastcgi",# "mod_rewrite",# )# wang.kai@sunmedia.com.cnvar.webapp_path = "/usr/share/httpstation"var.webapp_fcgi = "main.py"fastcgi.server = ( "/python_entry" =&gt; ( "icatchtek" =&gt; ( "bin-path" =&gt; webapp_path + "/" + webapp_fcgi, "socket" =&gt; "/tmp/httpstation-fcgi.socket", "max-procs" =&gt; 1, "check-local" =&gt; "disable", ) ),)# [Note]# Python request will send to "/python_entry" + "$1", except:# 1. document.domain + "/cgi-bin/luci"# 2. document.domain + "/luci-static"url.rewrite-once = ( "^(/(?!(cgi|luci-static)).*)" =&gt; "/python_entry" + "$1",) 3.1. fcgi serverWe need to tell lighttpd: “bin-path” : where lighttpd will startup executable file “socket” : fast cgi use socket send/receive msg “check-local” : Whether check file is existed in “server.document-root” “max-procs” : lighttpd support multiple process (optional) Lighttpd docs about FastCGI http://redmine.lighttpd.net/projects/lighttpd/wiki/Docs_ModFastCGI 3.2. URL RedirectBecause lighttpd support two web pages, we need to do something make url access ok. 3.2.1. Bottle Python RedirectIf fastcgi server work well, we need to add “/python_entry”. For example, we access “172.28.52.152/home” should be “172.28.52.152/python_entry”. We use “mod_rewrite” module to avoid this embarrassed situation. This module will pre-process URL before we really access it. 3.2.2. LUCI RedirectWe need to keep luci access like “cgi-bin/luci” and “luci-static”(which is used for js, css, etc resource files). So we use:1234567# [Note]# Python request will send to "/python_entry" + "$1", except:# 1. document.domain + "/cgi-bin/luci"# 2. document.domain + "/luci-static"url.rewrite-once = ( "^(/(?!(cgi|luci-static)).*)" =&gt; "/python_entry" + "$1",) How to represent “except xxx” ?In Reluar Expression, we use “?!“ to express except. So next regular expression is except begin with “cgi” or “luci-staic”. ^(/(?!(cgi|luci-static)).*)]]></content>
      <categories>
        <category>openwrt</category>
      </categories>
      <tags>
        <tag>webserver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F06%2F14%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
